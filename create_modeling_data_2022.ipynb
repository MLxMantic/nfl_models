{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import ascii_letters, digits\n",
    "import utils.cleaning_dicts\n",
    "#import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_w7.csv\t\t\t       notebooks\r\n",
      "chromedriver\t\t\t       other_data\r\n",
      "create_modeling_data_2022.ipynb        pfr\r\n",
      "create_modeling_data_sample_all.ipynb  README.md\r\n",
      "create_player_pools_2022.ipynb\t       scripts\r\n",
      "current_data\t\t\t       spreads_data\r\n",
      "fo_addtohist_update.csv\t\t       sumconcrollrb.csv\r\n",
      "historic_data\t\t\t       update_spreads_file.py\r\n",
      "misc_files\t\t\t       utils\r\n",
      "modeling_data\t\t\t       weather_scraper_current_year.py\r\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.path.abspath(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Users must change the week values to the current week in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_week_int = 8\n",
    "cur_week_str = str(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in, clean and process all pff position datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "                ###   Read-in and clean all passing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "passing_depth = pd.read_csv('./historic_data/pff_data/passing_depth_hist.csv')\n",
    "passing_allowed_pressure = pd.read_csv('./historic_data/pff_data/passing_allowed_pressure_hist.csv')\n",
    "passing_pressure = pd.read_csv('./historic_data/pff_data/passing_pressure_hist.csv')\n",
    "passing_concept = pd.read_csv('./historic_data/pff_data/passing_concept_hist.csv')\n",
    "time_in_pocket = pd.read_csv('./historic_data/pff_data/time_in_pocket_hist.csv')\n",
    "passing_summ_conc = pd.read_csv('./historic_data/pff_data/passing_summ_conc_hist.csv')\n",
    "\n",
    "passing_depth_new = pd.read_csv('./scripts/nfl_all/passing_depth_2022.csv')\n",
    "passing_allowed_pressure_new = pd.read_csv('./scripts/nfl_all/passing_allowed_pressure_2022.csv')\n",
    "passing_pressure_new = pd.read_csv('./scripts/nfl_all/passing_pressure_2022.csv')\n",
    "passing_concept_new = pd.read_csv('./scripts/nfl_all/passing_concept_2022.csv')\n",
    "time_in_pocket_new = pd.read_csv('./scripts/nfl_all/time_in_pocket_2022.csv')\n",
    "passing_summ_conc_new = pd.read_csv('./scripts/nfl_all/passing_summ_conc_2022.csv')\n",
    "                                 \n",
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0).reset_index(drop=True)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0).reset_index(drop=True)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0).reset_index(drop=True)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "\n",
    "def drop_non_qbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df=df[df['position'] == 'QB']\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "    \n",
    "passing_depth = drop_non_qbs(passing_depth)\n",
    "passing_allowed_pressure = drop_non_qbs(passing_allowed_pressure)\n",
    "passing_pressure = drop_non_qbs(passing_pressure)\n",
    "passing_concept = drop_non_qbs(passing_concept)\n",
    "time_in_pocket = drop_non_qbs(time_in_pocket)\n",
    "passing_summ_conc = drop_non_qbs(passing_summ_conc)\n",
    "\n",
    "\n",
    "passing_depth = passing_depth[passing_depth.columns.drop(list(passing_depth.filter(regex='left|right|center')))]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all receiving datasets ### scripts/nfl_all\n",
    "####################################################################################\n",
    "\n",
    "rec_summ_conc = pd.read_csv('./historic_data/pff_data/rec_summ_conc_hist.csv')\n",
    "receiving_concept = pd.read_csv('./historic_data/pff_data/receiving_concept_hist.csv')\n",
    "receiving_depth = pd.read_csv('./historic_data/pff_data/receiving_depth_hist.csv')\n",
    "receiving_scheme = pd.read_csv('./historic_data/pff_data/receiving_scheme_hist.csv')\n",
    "                                 \n",
    "rec_summ_conc_new = pd.read_csv('./scripts/nfl_all/rec_summ_conc_2022.csv')\n",
    "receiving_concept_new = pd.read_csv('./scripts/nfl_all/receiving_concept_2022.csv')\n",
    "receiving_depth_new = pd.read_csv('./scripts/nfl_all/receiving_depth_2022.csv')\n",
    "receiving_scheme_new = pd.read_csv('./scripts/nfl_all/receiving_scheme_2022.csv')\n",
    "                                 \n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0).reset_index(drop=True)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0).reset_index(drop=True)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0).reset_index(drop=True)                                 \n",
    "\n",
    "def drop_non_recs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|TE|HB|FB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rec_summ_conc = drop_non_recs(rec_summ_conc)\n",
    "receiving_concept = drop_non_recs(receiving_concept)\n",
    "receiving_depth = drop_non_recs(receiving_depth)\n",
    "receiving_scheme = drop_non_recs(receiving_scheme)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all rushing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "rush_summ_conc = pd.read_csv('./historic_data/pff_data/rush_summ_conc_hist.csv')\n",
    "rush_summ_conc_new = pd.read_csv('./scripts/nfl_all/rush_summ_conc_2022.csv')                                 \n",
    "                                 \n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    " \n",
    "\n",
    "def drop_non_rbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|HB|FB|QB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rush_summ_conc = drop_non_rbs(rush_summ_conc)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all blocking datasets ###\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "block_summ_conc = pd.read_csv('./historic_data/pff_data/block_summ_conc_hist.csv')\n",
    "offense_pass_blocking = pd.read_csv('./historic_data/pff_data/offense_pass_blocking_hist.csv')\n",
    "offense_run_blocking = pd.read_csv('./historic_data/pff_data/offense_run_blocking_hist.csv')\n",
    "                                 \n",
    "block_summ_conc_new = pd.read_csv('./scripts/nfl_all/block_summ_conc_2022.csv')\n",
    "offense_pass_blocking_new = pd.read_csv('./scripts/nfl_all/offense_pass_blocking_2022.csv')\n",
    "offense_run_blocking_new = pd.read_csv('./scripts/nfl_all/offense_run_blocking_2022.csv')                                 \n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0).reset_index(drop=True)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "def drop_non_ols(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df = df[df['position'].notna()]\n",
    "    df= df[df.position.str.match('T|C|G|TE')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "\n",
    "block_summ_conc\t= drop_non_ols(block_summ_conc)\n",
    "offense_pass_blocking = drop_non_ols(offense_pass_blocking)\n",
    "offense_run_blocking = drop_non_ols(offense_run_blocking)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all defensive datasets ###\n",
    "####################################################################################\n",
    "\n",
    "def_summ_conc = pd.read_csv('./historic_data/pff_data/def_summ_conc_hist.csv')\n",
    "pass_rush_summary = pd.read_csv('./historic_data/pff_data/pass_rush_summary_hist.csv')\n",
    "run_defense_summary = pd.read_csv('./historic_data/pff_data/run_defense_summary_hist.csv')\n",
    "defense_coverage_scheme = pd.read_csv('./historic_data/pff_data/defense_coverage_scheme_hist.csv')\n",
    "defense_coverage_summary = pd.read_csv('./historic_data/pff_data/defense_coverage_summary_hist.csv')\n",
    "slot_coverage = pd.read_csv('./historic_data/pff_data/slot_coverage_hist.csv')\n",
    "                                 \n",
    "def_summ_conc_new = pd.read_csv('./scripts/nfl_all/def_summ_conc_2022.csv')\n",
    "pass_rush_summary_new = pd.read_csv('./scripts/nfl_all/pass_rush_summary_2022.csv')\n",
    "run_defense_summary_new = pd.read_csv('./scripts/nfl_all/run_defense_summary_2022.csv')\n",
    "defense_coverage_scheme_new = pd.read_csv('./scripts/nfl_all/defense_coverage_scheme_2022.csv')\n",
    "defense_coverage_summary_new = pd.read_csv('./scripts/nfl_all/defense_coverage_summary_2022.csv')\n",
    "slot_coverage_new = pd.read_csv('./scripts/nfl_all/slot_coverage_2022.csv')\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0).reset_index(drop=True)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0).reset_index(drop=True)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def drop_non_def(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "def_summ_conc = drop_non_def(def_summ_conc)\n",
    "pass_rush_summary = drop_non_def(pass_rush_summary)\n",
    "run_defense_summary = drop_non_def(run_defense_summary)\n",
    "defense_coverage_scheme = drop_non_def(defense_coverage_scheme)\n",
    "defense_coverage_summary = drop_non_def(defense_coverage_summary)\n",
    "slot_coverage = drop_non_def(slot_coverage)\n",
    "\n",
    "def_summ_conc=def_summ_conc[def_summ_conc['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "pass_rush_summary=pass_rush_summary[pass_rush_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\"])]\n",
    "run_defense_summary=run_defense_summary[run_defense_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "defense_coverage_scheme=defense_coverage_scheme[defense_coverage_scheme['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "defense_coverage_summary=defense_coverage_summary[defense_coverage_summary['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "slot_coverage=slot_coverage[slot_coverage['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all special teams datasets ###\n",
    "####################################################################################\t\n",
    "\n",
    "st_kickers = pd.read_csv('./historic_data/pff_data/st_kickers_hist.csv')\n",
    "st_punters = pd.read_csv('./historic_data/pff_data/st_punters_hist.csv')\n",
    "\n",
    "st_kickers_new = pd.read_csv('./scripts/nfl_all/st_kickers_2022.csv')\n",
    "st_punters_new = pd.read_csv('./scripts/nfl_all/st_punters_2022.csv')                                 \n",
    "                                 \n",
    "                                 \n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0).reset_index(drop=True)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def clean_spec(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "st_kickers =clean_spec(st_kickers)\n",
    "st_punters = clean_spec(st_punters)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute all missing values in pff dataframe - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 251 ms, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth = impute(passing_depth)\n",
    "passing_allowed_pressure = impute(passing_allowed_pressure)\n",
    "passing_pressure = impute(passing_pressure)\n",
    "passing_concept = impute(passing_concept)\n",
    "time_in_pocket = impute(time_in_pocket)\n",
    "passing_summ_conc = impute(passing_summ_conc)\n",
    "\n",
    "rec_summ_conc = impute(rec_summ_conc)\n",
    "receiving_concept = impute(receiving_concept)\n",
    "receiving_depth = impute(receiving_depth)\n",
    "receiving_scheme = impute(receiving_scheme)\n",
    "\n",
    "rush_summ_conc = impute(rush_summ_conc)\n",
    "\n",
    "block_summ_conc = impute(block_summ_conc)\n",
    "offense_pass_blocking = impute(offense_pass_blocking)\n",
    "offense_run_blocking = impute(offense_run_blocking)\n",
    "\n",
    "def_summ_conc = impute(def_summ_conc)\n",
    "pass_rush_summary = impute(pass_rush_summary)\n",
    "run_defense_summary = impute(run_defense_summary)\n",
    "defense_coverage_scheme = impute(defense_coverage_scheme)\n",
    "defense_coverage_summary = impute(defense_coverage_summary)\n",
    "slot_coverage = impute(slot_coverage)\n",
    "\n",
    "st_kickers = impute(st_kickers)\n",
    "st_punters = impute(st_punters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prefixes to all columns.  Creating column names structured as \"source-dataset_column-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc)\n",
    "rush_summ_conc = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc)\n",
    "rec_summ_conc = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc)\n",
    "block_summ_conc = id_prefix(prefix=\"block_summary_\", df=block_summ_conc)\n",
    "def_summ_conc = id_prefix(prefix=\"def_summary_\", df=def_summ_conc)\n",
    "st_kickers = id_prefix(prefix=\"kicking_\", df=st_kickers)\n",
    "st_punters = id_prefix(prefix=\"punting_\", df=st_punters)\n",
    "\n",
    "\n",
    "passing_depth = create_prefix(prefix=\"pass_depth_\", df=passing_depth)\n",
    "passing_allowed_pressure = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure)\n",
    "passing_pressure = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure)\n",
    "passing_concept = create_prefix(prefix=\"pass_concept_\", df=passing_concept)\n",
    "time_in_pocket = create_prefix(prefix=\"pass_time_\", df=time_in_pocket)\n",
    "\n",
    "\n",
    "receiving_concept = create_prefix(prefix=\"rec_concept_\", df=receiving_concept)\n",
    "receiving_depth = create_prefix(prefix=\"rec_depth_\", df=receiving_depth)\n",
    "receiving_scheme = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme)\n",
    "\n",
    "offense_pass_blocking = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking)\n",
    "offense_run_blocking = create_prefix(prefix=\"run_block_\", df=offense_run_blocking)\n",
    "\n",
    "\n",
    "pass_rush_summary = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary)\n",
    "run_defense_summary = create_prefix(prefix=\"run_defense_\", df=run_defense_summary)\n",
    "defense_coverage_scheme = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme)\n",
    "defense_coverage_summary = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary)\n",
    "slot_coverage = create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in weather data and clean raiders name - merged onto spreads data below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in weather data###\n",
    "weather = pd.read_csv('./current_data/week_'+cur_week_str+'/weather_hist_all.csv')\n",
    "\n",
    "def raiders(df):\n",
    "    if 'oak' in str(df.away_matchup_id) and '2020' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2021' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2022' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    else:\n",
    "        return df.away_matchup_id\n",
    "weather['away_matchup_id'] = weather.apply(lambda df: raiders(df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spreads data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t###   spreads data cleaning and engineering ###\n",
    "####################################################################################\n",
    "\n",
    "spreads = pd.read_csv('./current_data/week_'+cur_week_str+'/spreadsw'+cur_week_str+'.csv')\n",
    "\n",
    "new_acc = {'oak':'lv',\n",
    "          'sd':'lac',\n",
    "          'stl':'lar'}  \n",
    "\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].map(new_acc).fillna(spreads['team_home_abb'])\n",
    "spreads['away_team_abb'] = spreads['away_team_abb'].map(new_acc).fillna(spreads['away_team_abb']) \n",
    "\n",
    "spreads = spreads[spreads['schedule_season']>=2014]\n",
    "spreads = spreads[['schedule_season','schedule_week','team_home_abb','score_home','score_away','away_team_abb','team_favorite_id','spread_favorite','over_under_line','starting_spread', 'Total Score Open',\n",
    "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement','ou_movement', 'strong_movement', 'fav_team_stronger']]\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].astype(str)\n",
    "spreads['team_favorite_id'] = spreads['team_favorite_id'].astype(str)\n",
    "spreads['over_under_line'] = spreads['over_under_line'].astype(float)\n",
    "\n",
    "\n",
    "def fav_spread(nData):\n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    else:\n",
    "        pass\n",
    "spreads['fav_spread'] = spreads.apply(lambda nData: fav_spread(nData), axis=1)\n",
    "\n",
    "def nonfav_spread(nData):\n",
    "    if nData['team_home_abb'] != nData['team_favorite_id']:\n",
    "        return nData['team_home_abb']\n",
    "    elif nData['away_team_abb'] != nData['team_favorite_id']:\n",
    "        return nData['away_team_abb']\n",
    "    else:\n",
    "        pass\n",
    "spreads['team_notfav_id'] = spreads.apply(lambda nData: nonfav_spread(nData), axis=1)\n",
    "\n",
    "def cover_or_not(nData):    \n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        if ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] > 0:\n",
    "            return 'Cover'\n",
    "        elif ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'       \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:        \n",
    "        if ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] > 0:            \n",
    "            return 'Cover'        \n",
    "        elif ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'        \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "spreads['fav_cover'] = spreads.apply(lambda nData: cover_or_not(nData), axis=1)\n",
    "\n",
    "def OU_or_not(nData):    \n",
    "    if (nData['score_home']+nData['score_away']) > nData['over_under_line']:        \n",
    "        return 'Over'    \n",
    "    elif (nData['score_home']-nData['score_away']) == nData['over_under_line']:        \n",
    "        return 'Push'    \n",
    "    else:        \n",
    "        return 'Under'\n",
    "spreads['over_under_result'] = spreads.apply(lambda nData: OU_or_not(nData), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "spreads['schedule_season'] = spreads['schedule_season'].apply(int)    \n",
    "spreads['schedule_week'] = spreads['schedule_week'].apply(int)  \n",
    "data = spreads.sort_values(by=[\"team_home_abb\",\"schedule_season\",\"schedule_week\"], ascending=[True, True, True])\n",
    "\n",
    "def clean_spreads(df):\n",
    "    ##  basic scrubbing to clean data ##    \n",
    "    df['schedule_season'] = df['schedule_season'].apply(str)    \n",
    "    df['schedule_week'] = df['schedule_week'].apply(str)        \n",
    "    df=df.apply(lambda x: x.astype(str).str.lower())    \n",
    "    #df['schedule_week']=df['schedule_week'].astype(str).str[:-2].astype(object)    \n",
    "    #df['schedule_season'] = df['schedule_season'].astype(str).str[:-2].astype(object)  \n",
    "    df['team_home_abb'] = df['team_home_abb'].map(new_acc).fillna(df['team_home_abb'])\n",
    "    df['away_team_abb'] = df['away_team_abb'].map(new_acc).fillna(df['away_team_abb'])\n",
    "    \n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"home_matchup_id\", (df['team_home_abb']+'vs'+df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(1, \"away_matchup_id\", (df['away_team_abb']+'@'+df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(2, \"home_id\", (df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(3, \"away_id\", (df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    return df\n",
    "    \n",
    "data = clean_spreads(data)\n",
    "\n",
    "data = pd.merge(data, weather, on='away_matchup_id', how='left')\n",
    "\n",
    "\n",
    "sh = data\n",
    "sa = data\n",
    "\n",
    "sh = sh.rename(columns={'home_id':'team_id'})\n",
    "sh.drop('away_id', axis=1, inplace=True)\n",
    "\n",
    "sa = sa.rename(columns={'away_id':'team_id'})\n",
    "sa.drop('home_id', axis=1, inplace=True)\n",
    "\n",
    "spread_comb = pd.concat([sh, sa], axis=0)\n",
    "spread_comb['team_abb'] = spread_comb['team_id'].astype(str).str[:3]\n",
    "spread_comb['team_abb'] = spread_comb['team_abb'].str.replace(\"_\",\"\")\n",
    "\n",
    "def hora1(nData):\n",
    "    if nData['team_favorite_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    elif nData['team_notfav_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['homeoraway'] = spread_comb.apply(lambda nData: hora1(nData), axis=1)\n",
    "\n",
    "def hora(nData):\n",
    "    if nData['team_favorite_id'] == nData['away_team_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['fav_homeoraway'] = spread_comb.apply(lambda nData: hora(nData), axis=1)\n",
    "#sh['fav_homeoraway'] = sh.apply(lambda nData: hora(nData), axis=1)\n",
    "\n",
    "def ws(nData):\n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ls(nData):    \n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "spread_comb['ats_w'] = spread_comb.apply(lambda nData: ws(nData), axis=1)\n",
    "spread_comb['ats_l'] = spread_comb.apply(lambda nData: ls(nData), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Football Outsiders rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rolling_fo(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    #data=data.fillna(data.mean())\n",
    "    num_cols = ['total_dvoa', 'off_dvoa','off_pass_dvoa', 'off_rush_dvoa', 'def_dvoa', 'def_pass_dvoa','def_rush_dvoa', 'special_teams_dvoa']\n",
    "    ids = data[['team_id', 'year', 'team', 'week', 'opp']].reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in historic weekly football outsiders data and create the current week rows for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_id</th>\n",
       "      <td>sea_2022_8</td>\n",
       "      <td>sf_2022_8</td>\n",
       "      <td>tb_2022_8</td>\n",
       "      <td>ten_2022_8</td>\n",
       "      <td>was_2022_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>sea</td>\n",
       "      <td>sf</td>\n",
       "      <td>tb</td>\n",
       "      <td>ten</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           218        219        220         221         222\n",
       "team_id             sea_2022_8  sf_2022_8  tb_2022_8  ten_2022_8  was_2022_8\n",
       "year                      2022       2022       2022        2022        2022\n",
       "team                       sea         sf         tb         ten         was\n",
       "week                         8          8          8           8           8\n",
       "opp                        NaN        NaN        NaN         NaN         NaN\n",
       "total_dvoa                 NaN        NaN        NaN         NaN         NaN\n",
       "off_dvoa                   NaN        NaN        NaN         NaN         NaN\n",
       "off_pass_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "off_rush_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "def_dvoa                   NaN        NaN        NaN         NaN         NaN\n",
       "def_pass_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "def_rush_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "special_teams_dvoa         NaN        NaN        NaN         NaN         NaN"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t##Create the current weeks fo team_ids/rows to roll into##\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "fo_data_new = fo_data[~fo_data['week'].isnull()]\n",
    "fo_data_new=fo_data_new.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "fo_data_new['team_id']=fo_data_new['team_id'].str.replace(\"2022_\"+str(cur_week_int-1), str(\"2022_\"+cur_week_str))\n",
    "\n",
    "fo_data_new = fo_data_new.sort_values(by=[\"team\",\"week\"], ascending=[True, False])\n",
    "fo_data_new[fo_data_new.columns[4:]] = np.nan\n",
    "fo_data_new.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in the historic FO data and concat all of them together for our rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_team_id</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2014_2</td>\n",
       "      <td>ari_2014_3</td>\n",
       "      <td>ari_2014_5</td>\n",
       "      <td>ari_2014_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>lac</td>\n",
       "      <td>nyg</td>\n",
       "      <td>sf</td>\n",
       "      <td>den</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>21.65</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>-2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.05</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-14.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.3</td>\n",
       "      <td>41.45</td>\n",
       "      <td>31.866667</td>\n",
       "      <td>18.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1           2           3           4\n",
       "unique_team_id      ari_2014_1  ari_2014_2  ari_2014_3  ari_2014_5  ari_2014_6\n",
       "year                      2014        2014        2014        2014        2014\n",
       "team                       ari         ari         ari         ari         ari\n",
       "week                         1           2           3           5           6\n",
       "opp                        lac         nyg          sf         den         was\n",
       "total_dvoa                 NaN        0.59       0.625    0.613333        0.56\n",
       "off_dvoa                   NaN        0.53       0.505        0.55    0.533333\n",
       "off_pass_dvoa              NaN        0.53        0.45    0.516667    0.486667\n",
       "off_rush_dvoa              NaN        0.51        0.57        0.55        0.56\n",
       "def_dvoa                   NaN        29.8       21.65   10.433333        -2.8\n",
       "def_pass_dvoa              NaN        14.2        8.05        -1.8  -14.066667\n",
       "def_rush_dvoa              NaN        51.3       41.45   31.866667   18.866667\n",
       "special_teams_dvoa         NaN        0.35        0.61        0.61    0.636667"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo_data_2022 = pd.read_csv(\"./historic_data/fo_data/fo_weekly_hist.csv\")\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "\n",
    "fo = pd.concat([fo_data_2022, fo_data, fo_data_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "fo['team'] = fo['team'].map(new_acc).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(new_acc).fillna(fo['opp']) \n",
    "\n",
    "fo['team'] = fo['team'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['opp'])\n",
    "\n",
    "##combine our current season fo data with the new week 4 rows we just made##\n",
    "fo_roll = rolling_fo(data=fo, roll_value=3, roll_type='mean')\n",
    "fo_roll = fo_roll.rename(columns={'team_id': 'unique_team_id'})\n",
    "\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('sd_','lac_')\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('oak_','lv_')\n",
    "#fo_roll.drop(['year','team','week','opp'], axis=1, inplace=True)\n",
    "\n",
    "fo_roll.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFF team_game_summaries (tgs) clean and create current week rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_new_week = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "\n",
    "tgs_new_week = tgs_new_week[~tgs_new_week['week'].isnull()]\n",
    "tgs_new_week=tgs_new_week.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "\n",
    "tgs_new_week['team_name'] = tgs_new_week['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs_new_week['team'])\n",
    "tgs_new_week['opponent_name'] = tgs_new_week['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs_new_week['opponent'])\n",
    "\n",
    "tgs_new_week['home_or_away']=tgs_new_week['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs_new_week['home_team'] = tgs_new_week.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs_new_week['away_team'] = tgs_new_week.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "tgs_new_week = clean_pff_team_summ(tgs_new_week)\n",
    "tgs_new_week['wl_int'] = ''\n",
    "tgs_new_week = tgs_new_week.sort_values(by=[\"team_name\",\"week\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in historic tgs data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_data_2022 = pd.read_csv(\"./historic_data/pff_data/team_game_summaries_historic.csv\")\n",
    "tgs_data_cur = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "tgs = pd.concat([tgs_data_2022, tgs_data_cur], axis=0)\n",
    "\n",
    "tgs = tgs[tgs['year'] >= 2014]\n",
    "\n",
    "\n",
    "tgs['team_name'] = tgs['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs['team'])\n",
    "tgs['opponent_name'] = tgs['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs['opponent'])\n",
    "\n",
    "##adding just incase accronyms have changed\n",
    "tgs['team_name'] = tgs['team_name'].map(new_acc).fillna(tgs['team_name'])\n",
    "tgs['opponent_name'] = tgs['opponent_name'].map(new_acc).fillna(tgs['opponent_name']) \n",
    "\n",
    "tgs['home_or_away']=tgs['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs['home_team'] = tgs.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs['away_team'] = tgs.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    ##Impute missing special teams data added after 2014##\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_name'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "   \n",
    "    return df\n",
    "\n",
    "\n",
    "   \n",
    "tgs_clean = clean_pff_team_summ(tgs)\n",
    "\n",
    "\n",
    "tgs_clean = pd.concat([tgs_clean, tgs_new_week], axis=0).reset_index(drop=True)\n",
    "tgs_clean['year']=tgs_clean['year'].apply(int)\n",
    "tgs_clean['week']=tgs_clean['week'].apply(int)\n",
    "tgs_clean['special_teams']=tgs_clean['special_teams'].apply(float)\n",
    "tgs_clean = tgs_clean.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "\n",
    "tgs_clean = tgs_clean[['unique_team_id','team_id_impute', 'home_matchup_id','opponent_id','wl','pf','pa','team_name','opponent_name','year','week','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>opponent_id</th>\n",
       "      <th>wl</th>\n",
       "      <th>pf</th>\n",
       "      <th>pa</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>pass_blocking</th>\n",
       "      <th>receiving</th>\n",
       "      <th>rushing</th>\n",
       "      <th>run_blocking</th>\n",
       "      <th>defense</th>\n",
       "      <th>rush_defense</th>\n",
       "      <th>tackling</th>\n",
       "      <th>pass_rush</th>\n",
       "      <th>coverage</th>\n",
       "      <th>special_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>was_2022_4</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>dalvswas_2022_4</td>\n",
       "      <td>dal_2022_4</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>was</td>\n",
       "      <td>dal</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>60.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>70.3</td>\n",
       "      <td>72.9</td>\n",
       "      <td>71.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>66.8</td>\n",
       "      <td>68.1</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>was_2022_5</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsten_2022_5</td>\n",
       "      <td>ten_2022_5</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>ten</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>67.8</td>\n",
       "      <td>61.4</td>\n",
       "      <td>42.9</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>70.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>64.6</td>\n",
       "      <td>43.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>was_2022_6</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>chivswas_2022_6</td>\n",
       "      <td>chi_2022_6</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>was</td>\n",
       "      <td>chi</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>75.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>60.4</td>\n",
       "      <td>72.1</td>\n",
       "      <td>72.1</td>\n",
       "      <td>48.4</td>\n",
       "      <td>39.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>71.9</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>was_2022_7</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsgb_2022_7</td>\n",
       "      <td>gb_2022_7</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>gb</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>65.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>was_2022_8</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsgb_2022_8</td>\n",
       "      <td>gb_2022_8</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>gb</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>65.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id team_id_impute  home_matchup_id opponent_id wl  pf  pa  \\\n",
       "4340     was_2022_4       was_2022  dalvswas_2022_4  dal_2022_4  L  10  25   \n",
       "4341     was_2022_5       was_2022  wasvsten_2022_5  ten_2022_5  L  17  21   \n",
       "4342     was_2022_6       was_2022  chivswas_2022_6  chi_2022_6  W  12   7   \n",
       "4343     was_2022_7       was_2022   wasvsgb_2022_7   gb_2022_7  W  23  21   \n",
       "4375     was_2022_8       was_2022   wasvsgb_2022_8   gb_2022_8  W  23  21   \n",
       "\n",
       "     team_name opponent_name  year  ...  pass_blocking  receiving  rushing  \\\n",
       "4340       was           dal  2022  ...           60.3       63.1     70.3   \n",
       "4341       was           ten  2022  ...           52.9       67.8     61.4   \n",
       "4342       was           chi  2022  ...           75.6       49.9     60.4   \n",
       "4343       was            gb  2022  ...           42.1       71.7     65.6   \n",
       "4375       was            gb  2022  ...           42.1       71.7     65.6   \n",
       "\n",
       "      run_blocking  defense  rush_defense  tackling  pass_rush  coverage  \\\n",
       "4340          72.9     71.9          72.0      68.8       66.8      68.1   \n",
       "4341          42.9     67.0          64.3      70.7       74.2      64.6   \n",
       "4342          72.1     72.1          48.4      39.6       88.6      71.9   \n",
       "4343          50.0     59.0          71.9      55.0       53.8      59.0   \n",
       "4375          50.0     59.0          71.9      55.0       53.8      59.0   \n",
       "\n",
       "      special_teams  \n",
       "4340           79.9  \n",
       "4341           43.9  \n",
       "4342           84.9  \n",
       "4343           66.9  \n",
       "4375           66.9  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tgs rolling mean function and combine all tgs datasets together and pass through the rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_tgs(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "        \n",
    "tgs_roll = rolling_tgs(data=tgs_clean, roll_value=3, roll_type='mean')\n",
    "\n",
    "tgs_roll = tgs_roll[['unique_team_id','wl','pf','pa','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_roll = tgs_roll.rename(columns={c: c+'_tgs' for c in tgs_roll.columns if c not in ['unique_team_id','wl','pf','pa']})\n",
    "\n",
    "tgs_roll.rename(columns={'unique_team_id_tgs_pff':'unique_team_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all the pff current week datasets and prep for rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth_new = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/passing_depth_new_pp_w\"+cur_week_str+\".csv\")\n",
    "passing_allowed_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_allowed_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_concept_new_pp_w'+cur_week_str+\".csv\")\n",
    "time_in_pocket_new = pd.read_csv('./current_data/week_'+cur_week_str+'/time_in_pocket_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_summ_conc_new_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "rec_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rec_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_concept_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_depth_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_depth_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "rush_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rush_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "block_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/block_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "offense_pass_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_pass_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "offense_run_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_run_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "def_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/def_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "pass_rush_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/pass_rush_summary_pp_w'+cur_week_str+\".csv\")\n",
    "run_defense_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/run_defense_summary_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_summary_pp_w'+cur_week_str+\".csv\")\n",
    "slot_coverage_new = pd.read_csv('./current_data/week_'+cur_week_str+'/slot_coverage_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "st_kickers_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_kickers_pp_w'+cur_week_str+\".csv\")\n",
    "st_punters_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_punters_no_inj_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "passing_depth_new['week'] = cur_week_str \n",
    "passing_allowed_pressure_new['week'] = cur_week_str \n",
    "passing_pressure_new['week'] = cur_week_str \n",
    "passing_concept_new['week'] = cur_week_str \n",
    "time_in_pocket_new['week'] = cur_week_str \n",
    "passing_summ_conc_new['week'] = cur_week_str \n",
    "rec_summ_conc_new['week'] = cur_week_str \n",
    "receiving_concept_new['week'] = cur_week_str\n",
    "receiving_depth_new['week'] = cur_week_str \n",
    "receiving_scheme_new['week'] = cur_week_str \n",
    "rush_summ_conc_new['week'] = cur_week_str\n",
    "block_summ_conc_new['week'] = cur_week_str \n",
    "offense_pass_blocking_new['week'] = cur_week_str \n",
    "offense_run_blocking_new['week'] = cur_week_str \n",
    "def_summ_conc_new['week'] = cur_week_str \n",
    "pass_rush_summary_new['week'] = cur_week_str \n",
    "run_defense_summary_new['week'] = cur_week_str \n",
    "defense_coverage_scheme_new['week'] = cur_week_str \n",
    "defense_coverage_summary_new['week'] = cur_week_str \n",
    "slot_coverage_new['week'] = cur_week_str \n",
    "st_kickers_new['week'] = cur_week_str \n",
    "st_punters_new['week'] = cur_week_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>player</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>player_game_count</th>\n",
       "      <th>assists</th>\n",
       "      <th>...</th>\n",
       "      <th>tackles</th>\n",
       "      <th>targets</th>\n",
       "      <th>total_pressures</th>\n",
       "      <th>touchdowns</th>\n",
       "      <th>yards</th>\n",
       "      <th>yards_after_catch</th>\n",
       "      <th>yards_per_reception</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>plyr_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>perrionwinfrey_cle_2022_8</td>\n",
       "      <td>cle_2022_8</td>\n",
       "      <td>perrionwinfrey_cle_2022</td>\n",
       "      <td>cle_2022</td>\n",
       "      <td>perrionwinfrey</td>\n",
       "      <td>122952</td>\n",
       "      <td>di</td>\n",
       "      <td>cle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>jaylenwatson_kc_2022_8</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>samroberts_ne_2022_8</td>\n",
       "      <td>ne_2022_8</td>\n",
       "      <td>samroberts_ne_2022</td>\n",
       "      <td>ne_2022</td>\n",
       "      <td>samroberts</td>\n",
       "      <td>156069</td>\n",
       "      <td>di</td>\n",
       "      <td>ne</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>joshuawilliams_kc_2022_8</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>christianmatthew_ari_2022_8</td>\n",
       "      <td>ari_2022_8</td>\n",
       "      <td>christianmatthew_ari_2022</td>\n",
       "      <td>ari_2022</td>\n",
       "      <td>christianmatthew</td>\n",
       "      <td>156140</td>\n",
       "      <td>cb</td>\n",
       "      <td>ari</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p_id unique_team_id             player_team_id  \\\n",
       "647    perrionwinfrey_cle_2022_8     cle_2022_8    perrionwinfrey_cle_2022   \n",
       "648       jaylenwatson_kc_2022_8      kc_2022_8       jaylenwatson_kc_2022   \n",
       "649         samroberts_ne_2022_8      ne_2022_8         samroberts_ne_2022   \n",
       "650     joshuawilliams_kc_2022_8      kc_2022_8     joshuawilliams_kc_2022   \n",
       "651  christianmatthew_ari_2022_8     ari_2022_8  christianmatthew_ari_2022   \n",
       "\n",
       "    team_id_impute            player  numeric_id position team_name  \\\n",
       "647       cle_2022    perrionwinfrey      122952       di       cle   \n",
       "648        kc_2022      jaylenwatson      131960       cb        kc   \n",
       "649        ne_2022        samroberts      156069       di        ne   \n",
       "650        kc_2022    joshuawilliams      156083       cb        kc   \n",
       "651       ari_2022  christianmatthew      156140       cb       ari   \n",
       "\n",
       "     player_game_count  assists  ...  tackles  targets  total_pressures  \\\n",
       "647                  1        0  ...        0        0                0   \n",
       "648                  1        3  ...        0        0                0   \n",
       "649                  1        0  ...        0        0                0   \n",
       "650                  1        1  ...        0        0                0   \n",
       "651                  1        0  ...        0        0                0   \n",
       "\n",
       "     touchdowns  yards  yards_after_catch  yards_per_reception  week  year  \\\n",
       "647           0      0                  0                    0     8  2022   \n",
       "648           0      0                  0                    0     8  2022   \n",
       "649           0      0                  0                    0     8  2022   \n",
       "650           0      0                  0                    0     8  2022   \n",
       "651           0      0                  0                    0     8  2022   \n",
       "\n",
       "     plyr_number  \n",
       "647            8  \n",
       "648            8  \n",
       "649            8  \n",
       "650            8  \n",
       "651            8  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the prefixes like we did for the pff datasets above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','team_id_impute','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc_new = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc_new)\n",
    "rush_summ_conc_new  = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc_new)\n",
    "rec_summ_conc_new  = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc_new)\n",
    "block_summ_conc_new  = id_prefix(prefix=\"block_summary_\", df=block_summ_conc_new)\n",
    "def_summ_conc_new  = id_prefix(prefix=\"def_summary_\", df=def_summ_conc_new)\n",
    "st_kickers_new  = id_prefix(prefix=\"kicking_\", df=st_kickers_new)\n",
    "st_punters_new  = id_prefix(prefix=\"punting_\", df=st_punters_new)\n",
    "\n",
    "\n",
    "passing_depth_new = create_prefix(prefix=\"pass_depth_\", df=passing_depth_new)\n",
    "passing_allowed_pressure_new = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure_new)\n",
    "passing_pressure_new = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure_new)\n",
    "passing_concept_new = create_prefix(prefix=\"pass_concept_\", df=passing_concept_new)\n",
    "time_in_pocket_new = create_prefix(prefix=\"pass_time_\", df=time_in_pocket_new)\n",
    "\n",
    "\n",
    "receiving_concept_new = create_prefix(prefix=\"rec_concept_\", df=receiving_concept_new)\n",
    "receiving_depth_new = create_prefix(prefix=\"rec_depth_\", df=receiving_depth_new)\n",
    "receiving_scheme_new = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme_new)\n",
    "\n",
    "offense_pass_blocking_new = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking_new)\n",
    "offense_run_blocking_new = create_prefix(prefix=\"run_block_\", df=offense_run_blocking_new)\n",
    "\n",
    "\n",
    "pass_rush_summary_new = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary_new)\n",
    "run_defense_summary_new = create_prefix(prefix=\"run_defense_\", df=run_defense_summary_new)\n",
    "defense_coverage_scheme_new = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme_new)\n",
    "defense_coverage_summary_new = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary_new)\n",
    "slot_coverage_new= create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>player</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense</th>\n",
       "      <th>def_summary_snap_counts_slot</th>\n",
       "      <th>def_summary_stops</th>\n",
       "      <th>def_summary_tackles</th>\n",
       "      <th>def_summary_targets</th>\n",
       "      <th>def_summary_total_pressures</th>\n",
       "      <th>def_summary_touchdowns</th>\n",
       "      <th>def_summary_yards</th>\n",
       "      <th>def_summary_yards_after_catch</th>\n",
       "      <th>def_summary_yards_per_reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>perrionwinfrey_cle_2022_8</td>\n",
       "      <td>perrionwinfrey</td>\n",
       "      <td>perrionwinfrey_cle_2022</td>\n",
       "      <td>cle_2022_8</td>\n",
       "      <td>cle_2022</td>\n",
       "      <td>122952</td>\n",
       "      <td>di</td>\n",
       "      <td>cle</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>jaylenwatson_kc_2022_8</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>samroberts_ne_2022_8</td>\n",
       "      <td>samroberts</td>\n",
       "      <td>samroberts_ne_2022</td>\n",
       "      <td>ne_2022_8</td>\n",
       "      <td>ne_2022</td>\n",
       "      <td>156069</td>\n",
       "      <td>di</td>\n",
       "      <td>ne</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>joshuawilliams_kc_2022_8</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>christianmatthew_ari_2022_8</td>\n",
       "      <td>christianmatthew</td>\n",
       "      <td>christianmatthew_ari_2022</td>\n",
       "      <td>ari_2022_8</td>\n",
       "      <td>ari_2022</td>\n",
       "      <td>156140</td>\n",
       "      <td>cb</td>\n",
       "      <td>ari</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p_id            player             player_team_id  \\\n",
       "647    perrionwinfrey_cle_2022_8    perrionwinfrey    perrionwinfrey_cle_2022   \n",
       "648       jaylenwatson_kc_2022_8      jaylenwatson       jaylenwatson_kc_2022   \n",
       "649         samroberts_ne_2022_8        samroberts         samroberts_ne_2022   \n",
       "650     joshuawilliams_kc_2022_8    joshuawilliams     joshuawilliams_kc_2022   \n",
       "651  christianmatthew_ari_2022_8  christianmatthew  christianmatthew_ari_2022   \n",
       "\n",
       "    unique_team_id team_id_impute  numeric_id position team_name  year week  \\\n",
       "647     cle_2022_8       cle_2022      122952       di       cle  2022    8   \n",
       "648      kc_2022_8        kc_2022      131960       cb        kc  2022    8   \n",
       "649      ne_2022_8        ne_2022      156069       di        ne  2022    8   \n",
       "650      kc_2022_8        kc_2022      156083       cb        kc  2022    8   \n",
       "651     ari_2022_8       ari_2022      156140       cb       ari  2022    8   \n",
       "\n",
       "     ...  def_summary_snap_counts_run_defense  def_summary_snap_counts_slot  \\\n",
       "647  ...                                    0                             0   \n",
       "648  ...                                    0                             0   \n",
       "649  ...                                    0                             0   \n",
       "650  ...                                    0                             0   \n",
       "651  ...                                    0                             0   \n",
       "\n",
       "     def_summary_stops  def_summary_tackles  def_summary_targets  \\\n",
       "647                  0                    0                    0   \n",
       "648                  0                    0                    0   \n",
       "649                  0                    0                    0   \n",
       "650                  0                    0                    0   \n",
       "651                  0                    0                    0   \n",
       "\n",
       "     def_summary_total_pressures  def_summary_touchdowns  def_summary_yards  \\\n",
       "647                            0                       0                  0   \n",
       "648                            0                       0                  0   \n",
       "649                            0                       0                  0   \n",
       "650                            0                       0                  0   \n",
       "651                            0                       0                  0   \n",
       "\n",
       "     def_summary_yards_after_catch  def_summary_yards_per_reception  \n",
       "647                              0                                0  \n",
       "648                              0                                0  \n",
       "649                              0                                0  \n",
       "650                              0                                0  \n",
       "651                              0                                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring the historic and new player pool data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0)\n",
    "\n",
    "\n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0)\n",
    "\n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0)\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0)\n",
    "\n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0)\n",
    "\n",
    "\n",
    "### after the concat cell ###\n",
    "passing_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_allowed_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "time_in_pocket.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "\n",
    "rec_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "rush_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "block_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_pass_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_run_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "def_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "pass_rush_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "run_defense_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "slot_coverage.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "st_kickers.drop_duplicates(subset='p_id', inplace=True)\n",
    "st_punters.drop_duplicates(subset='p_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rolling function and pass pff datasets through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 20s, sys: 422 ms, total: 8min 20s\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def rolling(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"player\",\"team_name\",\"year\",\"week\"], ascending=[True, True, True, True])\n",
    "    data['week']=data['week'].apply(str)\n",
    "    data['year']=data['year'].apply(str)\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        #roll5 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        #roll4 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll3 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "   \n",
    "passing_depth_roll = rolling(data=passing_depth, roll_value=3, roll_type='mean')\n",
    "passing_allowed_pressure_roll = rolling(data=passing_allowed_pressure, roll_value=3, roll_type='mean')\n",
    "passing_pressure_roll = rolling(data=passing_pressure, roll_value=3, roll_type='mean')\n",
    "passing_concept_roll = rolling(data=passing_concept, roll_value=3, roll_type='mean')\n",
    "time_in_pocket_roll = rolling(data=time_in_pocket, roll_value=3, roll_type='mean')\n",
    "passing_summ_conc_roll = rolling(data=passing_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "\n",
    "rec_summ_conc_roll = rolling(data=rec_summ_conc, roll_value=3, roll_type='mean')\n",
    "receiving_concept_roll =rolling(data=receiving_concept, roll_value=3, roll_type='mean')\n",
    "receiving_depth_roll = rolling(data=receiving_depth, roll_value=3, roll_type='mean')\n",
    "receiving_scheme_roll = rolling(data=receiving_scheme, roll_value=3, roll_type='mean')\n",
    "\n",
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "block_summ_conc_roll = rolling(data=block_summ_conc, roll_value=3, roll_type='mean')\n",
    "offense_pass_blocking_roll = rolling(data=offense_pass_blocking, roll_value=3, roll_type='mean')\n",
    "offense_run_blocking_roll = rolling(data=offense_run_blocking, roll_value=3, roll_type='mean')\n",
    "\n",
    "def_summ_conc_roll = rolling(data=def_summ_conc, roll_value=3, roll_type='mean')\n",
    "pass_rush_summary_roll = rolling(data=pass_rush_summary, roll_value=3, roll_type='mean')\n",
    "run_defense_summary_roll = rolling(data=run_defense_summary, roll_value=3, roll_type='mean')\n",
    "defense_coverage_scheme_roll = rolling(data=defense_coverage_scheme, roll_value=3, roll_type='mean')\n",
    "defense_coverage_summary_roll = rolling(data=defense_coverage_summary, roll_value=3, roll_type='mean')\n",
    "slot_coverage_roll = rolling(data=slot_coverage, roll_value=3, roll_type='mean')\n",
    "\n",
    "st_kickers_roll = rolling(data=st_kickers, roll_value=3, roll_type='mean')\n",
    "st_punters_roll = rolling(data=st_punters, roll_value=3, roll_type='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Create better imputation function before weighting team_position_group functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter_fillna(df=None, position=None, min_Var=None):\n",
    "    sub= df[df['position'].str.match(position)]\n",
    "    sub_limit = sub[(sub[min_Var] <=5) & (sub[min_Var] >=1)]\n",
    "    buckup_df = pd.DataFrame(sub_limit.median()).T\n",
    "    num_cols = sub.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    msk = sub.isnull()\n",
    "    tmp = sub[num_cols].mask(msk, buckup_df[num_cols])\n",
    "    tmp = np.where(msk[num_cols], buckup_df[num_cols], tmp[num_cols])\n",
    "    tmp = pd.DataFrame(tmp, columns=buckup_df.columns)\n",
    "    ids = pd.DataFrame(sub.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "    mrg = pd.concat([ids, tmp], axis=1)\n",
    "    return mrg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.1 s, sys: 184 ms, total: 51.2 s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.median()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth_roll = impute(passing_depth_roll)\n",
    "passing_allowed_pressure_roll = impute(passing_allowed_pressure_roll)\n",
    "passing_pressure_roll = impute(passing_pressure_roll)\n",
    "passing_concept_roll = impute(passing_concept_roll)\n",
    "time_in_pocket_roll = impute(time_in_pocket_roll)\n",
    "passing_summ_conc_roll = impute(passing_summ_conc_roll)\n",
    "\n",
    "rec_summ_conc_roll = impute(rec_summ_conc_roll)\n",
    "receiving_concept_roll = impute(receiving_concept_roll)\n",
    "receiving_depth_roll = impute(receiving_depth_roll)\n",
    "receiving_scheme_roll = impute(receiving_scheme_roll)\n",
    "\n",
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)\n",
    "\n",
    "block_summ_conc_roll = impute(block_summ_conc_roll)\n",
    "offense_pass_blocking_roll = impute(offense_pass_blocking_roll)\n",
    "offense_run_blocking_roll = impute(offense_run_blocking_roll)\n",
    "\n",
    "def_summ_conc_roll = impute(def_summ_conc_roll)\n",
    "pass_rush_summary_roll = impute(pass_rush_summary_roll)\n",
    "run_defense_summary_roll = impute(run_defense_summary_roll)\n",
    "defense_coverage_scheme_roll = impute(defense_coverage_scheme_roll)\n",
    "defense_coverage_summary_roll = impute(defense_coverage_summary_roll)\n",
    "slot_coverage_roll = impute(slot_coverage_roll)\n",
    "\n",
    "st_kickers_roll = impute(st_kickers_roll)\n",
    "st_punters_roll = impute(st_punters_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>positionclean</th>\n",
       "      <th>height_clean</th>\n",
       "      <th>weight_clean</th>\n",
       "      <th>speed_clean</th>\n",
       "      <th>hand_size</th>\n",
       "      <th>arm_length</th>\n",
       "      <th>bench</th>\n",
       "      <th>vertical</th>\n",
       "      <th>broad_jump</th>\n",
       "      <th>shuttle</th>\n",
       "      <th>3cone</th>\n",
       "      <th>explosive</th>\n",
       "      <th>size_speed</th>\n",
       "      <th>draft_yr</th>\n",
       "      <th>round</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17487</th>\n",
       "      <td>aaronbrooks_oak_2006</td>\n",
       "      <td>qb</td>\n",
       "      <td>75.5</td>\n",
       "      <td>203</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24.000001</td>\n",
       "      <td>35.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>7.52</td>\n",
       "      <td>20.795279</td>\n",
       "      <td>0.250141</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17488</th>\n",
       "      <td>aaronbrooks_oak_2007</td>\n",
       "      <td>qb</td>\n",
       "      <td>75.5</td>\n",
       "      <td>203</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>35.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>7.52</td>\n",
       "      <td>20.795279</td>\n",
       "      <td>0.250141</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>aaronrodgers_gb_2006</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>23.999998</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17490</th>\n",
       "      <td>aaronrodgers_gb_2007</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17491</th>\n",
       "      <td>aaronrodgers_gb_2008</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  unique_id positionclean  height_clean  weight_clean  \\\n",
       "17487  aaronbrooks_oak_2006            qb          75.5           203   \n",
       "17488  aaronbrooks_oak_2007            qb          75.5           203   \n",
       "17489  aaronrodgers_gb_2006            qb          74.0           223   \n",
       "17490  aaronrodgers_gb_2007            qb          74.0           223   \n",
       "17491  aaronrodgers_gb_2008            qb          74.0           223   \n",
       "\n",
       "       speed_clean  hand_size  arm_length      bench  vertical  broad_jump  \\\n",
       "17487         4.59       9.50       32.00  24.000001      35.5       118.0   \n",
       "17488         4.59       9.50       32.00  24.000000      35.5       118.0   \n",
       "17489         4.75      10.13       32.25  23.999998      34.5       110.0   \n",
       "17490         4.75      10.13       32.25  24.000000      34.5       110.0   \n",
       "17491         4.75      10.13       32.25  24.000000      34.5       110.0   \n",
       "\n",
       "       shuttle  3cone  explosive  size_speed  draft_yr  round  selection  \n",
       "17487     4.29   7.52  20.795279    0.250141      1999      4        131  \n",
       "17488     4.29   7.52  20.795279    0.250141      1999      4        131  \n",
       "17489     4.32   7.38  21.887624    0.262899      2005      1         24  \n",
       "17490     4.32   7.38  21.887624    0.262899      2005      1         24  \n",
       "17491     4.32   7.38  21.887624    0.262899      2005      1         24  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometrics = pd.read_csv('./other_data/2022_imputed_combine.csv'); biometrics.columns\n",
    "\n",
    "biometrics=biometrics[['unique_id','positionclean','height_clean',\n",
    "       'weight_clean', 'speed_clean', 'hand_size', 'arm_length', 'bench',\n",
    "       'vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed',\n",
    "       'draft_yr', 'round', 'selection']]\n",
    "\n",
    "biometrics['positionclean']=biometrics['positionclean'].apply(str)\n",
    "\n",
    "qb_bio = biometrics[biometrics['positionclean'].isin(['qb'])]\n",
    "rb_bio = biometrics[biometrics['positionclean'].isin(['rb','qb','fb','wr'])]\n",
    "rec_bio = biometrics[biometrics['positionclean'].isin(['wr','te','rb'])]\n",
    "ol_bio = biometrics[biometrics['positionclean'].isin(['ol','te'])]\n",
    "def_bio = biometrics[biometrics['positionclean'].isin(['dl','db','lb'])]\n",
    "st_bio = biometrics[biometrics['positionclean'].isin(['st'])]\n",
    "qb_bio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>positionclean</th>\n",
       "      <th>height_clean</th>\n",
       "      <th>weight_clean</th>\n",
       "      <th>speed_clean</th>\n",
       "      <th>hand_size</th>\n",
       "      <th>arm_length</th>\n",
       "      <th>bench</th>\n",
       "      <th>vertical</th>\n",
       "      <th>broad_jump</th>\n",
       "      <th>shuttle</th>\n",
       "      <th>3cone</th>\n",
       "      <th>explosive</th>\n",
       "      <th>size_speed</th>\n",
       "      <th>draft_yr</th>\n",
       "      <th>round</th>\n",
       "      <th>selection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17487</th>\n",
       "      <td>aaronbrooks_oak_2006</td>\n",
       "      <td>qb</td>\n",
       "      <td>75.5</td>\n",
       "      <td>203</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24.000001</td>\n",
       "      <td>35.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>7.52</td>\n",
       "      <td>20.795279</td>\n",
       "      <td>0.250141</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17488</th>\n",
       "      <td>aaronbrooks_oak_2007</td>\n",
       "      <td>qb</td>\n",
       "      <td>75.5</td>\n",
       "      <td>203</td>\n",
       "      <td>4.59</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>35.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>7.52</td>\n",
       "      <td>20.795279</td>\n",
       "      <td>0.250141</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>aaronrodgers_gb_2006</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>23.999998</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17490</th>\n",
       "      <td>aaronrodgers_gb_2007</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17491</th>\n",
       "      <td>aaronrodgers_gb_2008</td>\n",
       "      <td>qb</td>\n",
       "      <td>74.0</td>\n",
       "      <td>223</td>\n",
       "      <td>4.75</td>\n",
       "      <td>10.13</td>\n",
       "      <td>32.25</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>7.38</td>\n",
       "      <td>21.887624</td>\n",
       "      <td>0.262899</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  unique_id positionclean  height_clean  weight_clean  \\\n",
       "17487  aaronbrooks_oak_2006            qb          75.5           203   \n",
       "17488  aaronbrooks_oak_2007            qb          75.5           203   \n",
       "17489  aaronrodgers_gb_2006            qb          74.0           223   \n",
       "17490  aaronrodgers_gb_2007            qb          74.0           223   \n",
       "17491  aaronrodgers_gb_2008            qb          74.0           223   \n",
       "\n",
       "       speed_clean  hand_size  arm_length      bench  vertical  broad_jump  \\\n",
       "17487         4.59       9.50       32.00  24.000001      35.5       118.0   \n",
       "17488         4.59       9.50       32.00  24.000000      35.5       118.0   \n",
       "17489         4.75      10.13       32.25  23.999998      34.5       110.0   \n",
       "17490         4.75      10.13       32.25  24.000000      34.5       110.0   \n",
       "17491         4.75      10.13       32.25  24.000000      34.5       110.0   \n",
       "\n",
       "       shuttle  3cone  explosive  size_speed  draft_yr  round  selection  \n",
       "17487     4.29   7.52  20.795279    0.250141      1999      4        131  \n",
       "17488     4.29   7.52  20.795279    0.250141      1999      4        131  \n",
       "17489     4.32   7.38  21.887624    0.262899      2005      1         24  \n",
       "17490     4.32   7.38  21.887624    0.262899      2005      1         24  \n",
       "17491     4.32   7.38  21.887624    0.262899      2005      1         24  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_bio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = rb_bio.groupby(['positionclean']).median().reset_index()\n",
    "imp = imp.rename(columns={'positionclean': 'position'})\n",
    "\n",
    "imp['position'] = imp['position'].str.replace('rb','hb')\n",
    "rush_summ_conc_roll['position'] = rush_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "\n",
    "temp = pd.merge(rush_summ_conc_roll, imp, on='position', how='left')\n",
    "\n",
    "rush_summ_conc_roll_mrg = pd.merge(rush_summ_conc_roll, rb_bio, left_on='player_team_id', right_on='unique_id', how='left')\n",
    "rush_summ_conc_roll_mrg.drop(['unique_id','positionclean'], axis=1, inplace=True)\n",
    "\n",
    "#rush_summ_conc_roll_mrg[rush_summ_conc_roll_mrg.isnull()] = temp\n",
    "#df_test = rush_summ_conc_roll_mrg.combine_first(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_id', 'player', 'player_team_id', 'unique_team_id', 'team_id_impute',\n",
       "       'position', 'team_name', 'year', 'week', 'numeric_id',\n",
       "       'rush_summary_player_game_count', 'rush_summary_attempts',\n",
       "       'rush_summary_avoided_tackles', 'rush_summary_breakaway_attempts',\n",
       "       'rush_summary_breakaway_percent', 'rush_summary_breakaway_yards',\n",
       "       'rush_summary_declined_penalties', 'rush_summary_designed_yards',\n",
       "       'rush_summary_drops', 'rush_summary_elu_recv_mtf',\n",
       "       'rush_summary_elu_rush_mtf', 'rush_summary_elu_yco',\n",
       "       'rush_summary_elusive_rating', 'rush_summary_explosive',\n",
       "       'rush_summary_first_downs', 'rush_summary_franchise_id',\n",
       "       'rush_summary_fumbles', 'rush_summary_gap_attempts',\n",
       "       'rush_summary_grades_hands_fumble', 'rush_summary_grades_offense',\n",
       "       'rush_summary_grades_offense_penalty', 'rush_summary_grades_pass',\n",
       "       'rush_summary_grades_pass_block', 'rush_summary_grades_pass_route',\n",
       "       'rush_summary_grades_run', 'rush_summary_grades_run_block',\n",
       "       'rush_summary_longest', 'rush_summary_penalties',\n",
       "       'rush_summary_rec_yards', 'rush_summary_receptions',\n",
       "       'rush_summary_routes', 'rush_summary_run_plays',\n",
       "       'rush_summary_scramble_yards', 'rush_summary_scrambles',\n",
       "       'rush_summary_targets', 'rush_summary_total_touches',\n",
       "       'rush_summary_touchdowns', 'rush_summary_yards',\n",
       "       'rush_summary_yards_after_contact', 'rush_summary_yco_attempt',\n",
       "       'rush_summary_ypa', 'rush_summary_yprr', 'rush_summary_zone_attempts',\n",
       "       'height_clean', 'weight_clean', 'speed_clean', 'hand_size',\n",
       "       'arm_length', 'bench', 'vertical', 'broad_jump', 'shuttle', '3cone',\n",
       "       'explosive', 'size_speed', 'draft_yr', 'round', 'selection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rush_summ_conc_roll_mrg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mrg[df_mrg.isnull()] = temp\n",
    "\n",
    "df_test = df_mrg.combine_first(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_bio.columns = [str(col) + '_rbs' for col in rb_bio.columns]\n",
    "rush_summ_conc_roll = pd.merge(rush_summ_conc_roll, rb_bio, left_on='player_team_id', right_on='unique_id_rbs', how='left')\n",
    "rush_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "rush_summ_conc_roll.to_csv('sumconcrollrb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine players for each dataset into team_year_week groupings\n",
    "\n",
    "### These next few cells will compute weighted averages based on average snaps played.  The first function will default snaps to 1 if snap value is 0.  The rest of the functions are dataset specific and will compute the weighted averages based on rollup aaverages and snaps played.\n",
    "\n",
    "#### For example: Washington had 5 rbs player in the last 3 games.  It doesn't make sense to weight all the players stats into a single average if 3 of those backs only averaged 2 snaps and rushed for 2 yards whereas B. Robinson averages 18 snaps and rushes for 65 yards and Gibson averages 10 snaps for 40 yards.  Therefore we weight each players rolling average based on their rolling snaps played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rushing weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>rush_summary_attempts</th>\n",
       "      <th>rush_summary_avoided_tackles</th>\n",
       "      <th>rush_summary_breakaway_attempts</th>\n",
       "      <th>rush_summary_breakaway_percent</th>\n",
       "      <th>rush_summary_breakaway_yards</th>\n",
       "      <th>rush_summary_declined_penalties</th>\n",
       "      <th>rush_summary_designed_yards</th>\n",
       "      <th>rush_summary_drops</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_rbs</th>\n",
       "      <th>vertical_rbs</th>\n",
       "      <th>broad_jump_rbs</th>\n",
       "      <th>shuttle_rbs</th>\n",
       "      <th>3cone_rbs</th>\n",
       "      <th>explosive_rbs</th>\n",
       "      <th>size_speed_rbs</th>\n",
       "      <th>draft_yr_rbs</th>\n",
       "      <th>round_rbs</th>\n",
       "      <th>selection_rbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>was_2021_7</td>\n",
       "      <td>54944.238806</td>\n",
       "      <td>11.159204</td>\n",
       "      <td>0.452736</td>\n",
       "      <td>0.437811</td>\n",
       "      <td>13.309453</td>\n",
       "      <td>6.786070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.808458</td>\n",
       "      <td>0.218905</td>\n",
       "      <td>...</td>\n",
       "      <td>16.641965</td>\n",
       "      <td>35.029851</td>\n",
       "      <td>118.835821</td>\n",
       "      <td>4.252987</td>\n",
       "      <td>7.122550</td>\n",
       "      <td>24.227904</td>\n",
       "      <td>0.247183</td>\n",
       "      <td>2018.283582</td>\n",
       "      <td>3.626866</td>\n",
       "      <td>90.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>was_2021_8</td>\n",
       "      <td>52388.646341</td>\n",
       "      <td>9.552846</td>\n",
       "      <td>0.711382</td>\n",
       "      <td>0.357724</td>\n",
       "      <td>10.874797</td>\n",
       "      <td>5.544715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.796748</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>...</td>\n",
       "      <td>16.837635</td>\n",
       "      <td>35.237805</td>\n",
       "      <td>119.585366</td>\n",
       "      <td>4.253782</td>\n",
       "      <td>7.115254</td>\n",
       "      <td>24.204689</td>\n",
       "      <td>0.246086</td>\n",
       "      <td>2018.268293</td>\n",
       "      <td>3.426829</td>\n",
       "      <td>85.573171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>was_2022_1</td>\n",
       "      <td>9443.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.045870</td>\n",
       "      <td>34.532510</td>\n",
       "      <td>117.630686</td>\n",
       "      <td>4.270644</td>\n",
       "      <td>7.125022</td>\n",
       "      <td>22.147680</td>\n",
       "      <td>0.246470</td>\n",
       "      <td>2018.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>84.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>was_2022_2</td>\n",
       "      <td>44382.178571</td>\n",
       "      <td>8.785714</td>\n",
       "      <td>2.345238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.404762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.321429</td>\n",
       "      <td>35.070988</td>\n",
       "      <td>118.516439</td>\n",
       "      <td>4.255744</td>\n",
       "      <td>7.118268</td>\n",
       "      <td>23.934558</td>\n",
       "      <td>0.246118</td>\n",
       "      <td>2018.571429</td>\n",
       "      <td>3.392857</td>\n",
       "      <td>81.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>was_2022_3</td>\n",
       "      <td>48362.180000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>2.286667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.553333</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.560000</td>\n",
       "      <td>34.669506</td>\n",
       "      <td>118.038411</td>\n",
       "      <td>4.280034</td>\n",
       "      <td>7.129060</td>\n",
       "      <td>24.022610</td>\n",
       "      <td>0.249851</td>\n",
       "      <td>2018.340000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>102.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>was_2022_4</td>\n",
       "      <td>59740.018182</td>\n",
       "      <td>10.296970</td>\n",
       "      <td>1.806061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.715152</td>\n",
       "      <td>0.593939</td>\n",
       "      <td>...</td>\n",
       "      <td>16.272727</td>\n",
       "      <td>34.562963</td>\n",
       "      <td>117.261470</td>\n",
       "      <td>4.275135</td>\n",
       "      <td>7.165351</td>\n",
       "      <td>24.199711</td>\n",
       "      <td>0.249042</td>\n",
       "      <td>2018.909091</td>\n",
       "      <td>4.145455</td>\n",
       "      <td>105.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>was_2022_5</td>\n",
       "      <td>59058.777778</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.314815</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>...</td>\n",
       "      <td>17.111111</td>\n",
       "      <td>34.638889</td>\n",
       "      <td>118.222222</td>\n",
       "      <td>4.268377</td>\n",
       "      <td>7.139800</td>\n",
       "      <td>24.246625</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>2018.666667</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>65.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>was_2022_6</td>\n",
       "      <td>54118.573333</td>\n",
       "      <td>7.675556</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>2.053333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.346667</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>...</td>\n",
       "      <td>17.293333</td>\n",
       "      <td>34.583676</td>\n",
       "      <td>117.548641</td>\n",
       "      <td>4.264289</td>\n",
       "      <td>7.115773</td>\n",
       "      <td>23.360079</td>\n",
       "      <td>0.251793</td>\n",
       "      <td>2017.253333</td>\n",
       "      <td>4.226667</td>\n",
       "      <td>112.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>was_2022_7</td>\n",
       "      <td>45355.021505</td>\n",
       "      <td>8.383513</td>\n",
       "      <td>0.922939</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>23.215233</td>\n",
       "      <td>8.025090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.706093</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>...</td>\n",
       "      <td>17.677419</td>\n",
       "      <td>34.780787</td>\n",
       "      <td>117.817146</td>\n",
       "      <td>4.274745</td>\n",
       "      <td>7.096207</td>\n",
       "      <td>23.145824</td>\n",
       "      <td>0.251805</td>\n",
       "      <td>2016.440860</td>\n",
       "      <td>3.892473</td>\n",
       "      <td>104.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>was_2022_8</td>\n",
       "      <td>49254.759563</td>\n",
       "      <td>9.731330</td>\n",
       "      <td>1.209472</td>\n",
       "      <td>0.644809</td>\n",
       "      <td>31.087796</td>\n",
       "      <td>12.863388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.641166</td>\n",
       "      <td>0.130237</td>\n",
       "      <td>...</td>\n",
       "      <td>17.781421</td>\n",
       "      <td>34.951236</td>\n",
       "      <td>118.275276</td>\n",
       "      <td>4.269028</td>\n",
       "      <td>7.087835</td>\n",
       "      <td>23.212661</td>\n",
       "      <td>0.250474</td>\n",
       "      <td>2016.497268</td>\n",
       "      <td>3.743169</td>\n",
       "      <td>100.098361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id    numeric_id  rush_summary_attempts  \\\n",
       "4366     was_2021_7  54944.238806              11.159204   \n",
       "4367     was_2021_8  52388.646341               9.552846   \n",
       "4368     was_2022_1   9443.000000               4.000000   \n",
       "4369     was_2022_2  44382.178571               8.785714   \n",
       "4370     was_2022_3  48362.180000               9.180000   \n",
       "4371     was_2022_4  59740.018182              10.296970   \n",
       "4372     was_2022_5  59058.777778              10.333333   \n",
       "4373     was_2022_6  54118.573333               7.675556   \n",
       "4374     was_2022_7  45355.021505               8.383513   \n",
       "4375     was_2022_8  49254.759563               9.731330   \n",
       "\n",
       "      rush_summary_avoided_tackles  rush_summary_breakaway_attempts  \\\n",
       "4366                      0.452736                         0.437811   \n",
       "4367                      0.711382                         0.357724   \n",
       "4368                      0.666667                         0.000000   \n",
       "4369                      2.345238                         0.000000   \n",
       "4370                      2.286667                         0.050000   \n",
       "4371                      1.806061                         0.000000   \n",
       "4372                      1.185185                         0.000000   \n",
       "4373                      0.213333                         0.062222   \n",
       "4374                      0.922939                         0.435484   \n",
       "4375                      1.209472                         0.644809   \n",
       "\n",
       "      rush_summary_breakaway_percent  rush_summary_breakaway_yards  \\\n",
       "4366                       13.309453                      6.786070   \n",
       "4367                       10.874797                      5.544715   \n",
       "4368                        0.000000                      0.000000   \n",
       "4369                        0.000000                      0.000000   \n",
       "4370                        5.000000                      1.050000   \n",
       "4371                        0.000000                      0.000000   \n",
       "4372                        0.000000                      0.000000   \n",
       "4373                        5.133333                      2.053333   \n",
       "4374                       23.215233                      8.025090   \n",
       "4375                       31.087796                     12.863388   \n",
       "\n",
       "      rush_summary_declined_penalties  rush_summary_designed_yards  \\\n",
       "4366                              0.0                    41.808458   \n",
       "4367                              0.0                    34.796748   \n",
       "4368                              0.0                    16.333333   \n",
       "4369                              0.0                    34.404762   \n",
       "4370                              0.0                    29.553333   \n",
       "4371                              0.0                    31.715152   \n",
       "4372                              0.0                    31.314815   \n",
       "4373                              0.0                    23.346667   \n",
       "4374                              0.0                    30.706093   \n",
       "4375                              0.0                    37.641166   \n",
       "\n",
       "      rush_summary_drops  ...  bench_rbs  vertical_rbs  broad_jump_rbs  \\\n",
       "4366            0.218905  ...  16.641965     35.029851      118.835821   \n",
       "4367            0.235772  ...  16.837635     35.237805      119.585366   \n",
       "4368            0.000000  ...  18.045870     34.532510      117.630686   \n",
       "4369            0.000000  ...  17.321429     35.070988      118.516439   \n",
       "4370            0.560000  ...  16.560000     34.669506      118.038411   \n",
       "4371            0.593939  ...  16.272727     34.562963      117.261470   \n",
       "4372            0.481481  ...  17.111111     34.638889      118.222222   \n",
       "4373            0.288889  ...  17.293333     34.583676      117.548641   \n",
       "4374            0.215054  ...  17.677419     34.780787      117.817146   \n",
       "4375            0.130237  ...  17.781421     34.951236      118.275276   \n",
       "\n",
       "      shuttle_rbs  3cone_rbs  explosive_rbs  size_speed_rbs  draft_yr_rbs  \\\n",
       "4366     4.252987   7.122550      24.227904        0.247183   2018.283582   \n",
       "4367     4.253782   7.115254      24.204689        0.246086   2018.268293   \n",
       "4368     4.270644   7.125022      22.147680        0.246470   2018.200000   \n",
       "4369     4.255744   7.118268      23.934558        0.246118   2018.571429   \n",
       "4370     4.280034   7.129060      24.022610        0.249851   2018.340000   \n",
       "4371     4.275135   7.165351      24.199711        0.249042   2018.909091   \n",
       "4372     4.268377   7.139800      24.246625        0.249603   2018.666667   \n",
       "4373     4.264289   7.115773      23.360079        0.251793   2017.253333   \n",
       "4374     4.274745   7.096207      23.145824        0.251805   2016.440860   \n",
       "4375     4.269028   7.087835      23.212661        0.250474   2016.497268   \n",
       "\n",
       "      round_rbs  selection_rbs  \n",
       "4366   3.626866      90.761194  \n",
       "4367   3.426829      85.573171  \n",
       "4368   3.400000      84.800000  \n",
       "4369   3.392857      81.928571  \n",
       "4370   3.940000     102.040000  \n",
       "4371   4.145455     105.709091  \n",
       "4372   2.888889      65.777778  \n",
       "4373   4.226667     112.920000  \n",
       "4374   3.892473     104.698925  \n",
       "4375   3.743169     100.098361  \n",
       "\n",
       "[10 rows x 59 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_bio.columns = [str(col) + '_rbs' for col in rb_bio.columns]\n",
    "rush_summ_conc_roll = pd.merge(rush_summ_conc_roll, rb_bio, left_on='player_team_id', right_on='unique_id_rbs', how='left')\n",
    "rush_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rush_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rush_summ_conc_roll['rush_summary_attempts'] = rush_summ_conc_roll.apply(lambda df: rush_att(df, var='rush_summary_attempts'), axis=1)   \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rush_summary_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "\n",
    "rb_stats = rush_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "rb_stats.tail(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Passing weight average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_bio.columns = [str(col) + '_qbs' for col in qb_bio.columns]\n",
    "passing_summ_conc_roll = pd.merge(passing_summ_conc_roll, qb_bio, left_on='player_team_id', right_on='unique_id_qbs', how='left')\n",
    "passing_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "passing_summ_conc_roll = impute(passing_summ_conc_roll)\n",
    "\n",
    "def pass_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "passing_summ_conc_roll['pass_summary_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_summary_dropbacks'), axis=1)\n",
    "passing_depth_roll['pass_depth_base_dropbacks'] = passing_depth_roll.apply(lambda df: pass_att(df, var='pass_depth_base_dropbacks'), axis=1)  \n",
    "passing_pressure_roll['pass_under_pressure_base_dropbacks'] = passing_pressure_roll.apply(lambda df: pass_att(df, var='pass_under_pressure_base_dropbacks'), axis=1)  \n",
    "passing_allowed_pressure_roll['pressure_source_allowed_pressure_dropbacks'] = passing_allowed_pressure_roll.apply(lambda df: pass_att(df, var='pressure_source_allowed_pressure_dropbacks'), axis=1)  \n",
    "#passing_concept_roll['pass_concept_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_concept_dropbacks'), axis=1)  \n",
    "time_in_pocket_roll['pass_time_dropbacks'] = time_in_pocket_roll.apply(lambda df: pass_att(df, var='pass_time_dropbacks'), axis=1)     \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_summary_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "qb_stats = passing_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_depth_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_depth_stats = passing_depth_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pressure_source_allowed_pressure_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_allowed_pressure_stats = passing_allowed_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_under_pressure_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_pressure_stats = passing_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_concept_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_concept_stats = passing_concept_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_time_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "time_in_pocke_stats = time_in_pocket_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute receiver weighted average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_bio.columns = [str(col) + '_wrs' for col in rec_bio.columns]\n",
    "rec_summ_conc_roll = pd.merge(rec_summ_conc_roll, rec_bio, left_on='player_team_id', right_on='unique_id_wrs', how='left')\n",
    "rec_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "rec_summ_conc_roll = impute(rec_summ_conc_roll)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rec_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rec_summ_conc_roll['rec_summary_targets'] = rec_summ_conc_roll.apply(lambda df: rec_att(df, var='rec_summary_targets'), axis=1)   \n",
    "receiving_concept_roll['rec_concept_base_targets'] = receiving_concept_roll.apply(lambda df: rec_att(df, var='rec_concept_base_targets'), axis=1) \n",
    "receiving_depth_roll['rec_depth_base_targets'] = receiving_depth_roll.apply(lambda df: rec_att(df, var='rec_depth_base_targets'), axis=1) \n",
    "receiving_scheme_roll['rec_scheme_base_targets'] = receiving_scheme_roll.apply(lambda df: rec_att(df, var='rec_scheme_base_targets'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_summary_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "rec_stats = rec_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_concept_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_concept = receiving_concept.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_depth_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_depth = receiving_depth.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_scheme_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_scheme = receiving_scheme.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute OL weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_bio.columns = [str(col) + '_ols' for col in ol_bio.columns]\n",
    "block_summ_conc_roll = pd.merge(block_summ_conc_roll, ol_bio, left_on='player_team_id', right_on='unique_id_ols', how='left')\n",
    "block_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "block_summ_conc_roll = impute(block_summ_conc_roll)\n",
    "\n",
    "def snap_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "block_summ_conc_roll['block_summary_snap_counts_offense'] = block_summ_conc_roll.apply(lambda df: snap_fix(df, var='block_summary_snap_counts_offense'), axis=1)\n",
    "offense_pass_blocking_roll['pass_block_snap_counts_pass_block'] = offense_pass_blocking_roll.apply(lambda df: snap_fix(df, var='pass_block_snap_counts_pass_block'), axis=1) \n",
    "offense_run_blocking_roll['run_block_snap_counts_run_block'] = offense_run_blocking_roll.apply(lambda df: snap_fix(df, var='run_block_snap_counts_run_block'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='block_summary_snap_counts_offense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "ol_stats = block_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_block_snap_counts_pass_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_pass_blocking_roll = offense_pass_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='run_block_snap_counts_run_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_run_blocking_roll = offense_run_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute defensive weighted averages datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>def_summary_assists</th>\n",
       "      <th>def_summary_batted_passes</th>\n",
       "      <th>def_summary_catch_rate</th>\n",
       "      <th>def_summary_declined_penalties</th>\n",
       "      <th>def_summary_forced_fumbles</th>\n",
       "      <th>def_summary_franchise_id</th>\n",
       "      <th>def_summary_grades_coverage_defense</th>\n",
       "      <th>def_summary_grades_defense</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_defs</th>\n",
       "      <th>vertical_defs</th>\n",
       "      <th>broad_jump_defs</th>\n",
       "      <th>shuttle_defs</th>\n",
       "      <th>3cone_defs</th>\n",
       "      <th>explosive_defs</th>\n",
       "      <th>size_speed_defs</th>\n",
       "      <th>draft_yr_defs</th>\n",
       "      <th>round_defs</th>\n",
       "      <th>selection_defs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9074.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.226821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.584477</td>\n",
       "      <td>61.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.210526</td>\n",
       "      <td>32.776271</td>\n",
       "      <td>115.778812</td>\n",
       "      <td>4.411314</td>\n",
       "      <td>7.242630</td>\n",
       "      <td>22.841669</td>\n",
       "      <td>0.282246</td>\n",
       "      <td>2010.157895</td>\n",
       "      <td>3.631579</td>\n",
       "      <td>104.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>5453.149401</td>\n",
       "      <td>0.380565</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>73.237718</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.770461</td>\n",
       "      <td>64.293564</td>\n",
       "      <td>...</td>\n",
       "      <td>18.858733</td>\n",
       "      <td>33.144971</td>\n",
       "      <td>116.685233</td>\n",
       "      <td>4.331833</td>\n",
       "      <td>7.161912</td>\n",
       "      <td>22.533098</td>\n",
       "      <td>0.275249</td>\n",
       "      <td>2009.447774</td>\n",
       "      <td>3.556507</td>\n",
       "      <td>101.102312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>5259.055969</td>\n",
       "      <td>0.356216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.635314</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.691524</td>\n",
       "      <td>64.336686</td>\n",
       "      <td>...</td>\n",
       "      <td>18.245300</td>\n",
       "      <td>33.443009</td>\n",
       "      <td>117.542952</td>\n",
       "      <td>4.302931</td>\n",
       "      <td>7.106221</td>\n",
       "      <td>22.560918</td>\n",
       "      <td>0.270711</td>\n",
       "      <td>2009.178400</td>\n",
       "      <td>3.360297</td>\n",
       "      <td>94.331876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>5376.940635</td>\n",
       "      <td>0.350820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.261585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030531</td>\n",
       "      <td>1.857766</td>\n",
       "      <td>63.717993</td>\n",
       "      <td>66.110585</td>\n",
       "      <td>...</td>\n",
       "      <td>18.394475</td>\n",
       "      <td>33.400880</td>\n",
       "      <td>117.210515</td>\n",
       "      <td>4.320045</td>\n",
       "      <td>7.123781</td>\n",
       "      <td>22.624919</td>\n",
       "      <td>0.272260</td>\n",
       "      <td>2009.342622</td>\n",
       "      <td>3.527502</td>\n",
       "      <td>99.279864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>5505.065511</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>72.629271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>1.852601</td>\n",
       "      <td>62.197780</td>\n",
       "      <td>65.108462</td>\n",
       "      <td>...</td>\n",
       "      <td>19.007707</td>\n",
       "      <td>33.473970</td>\n",
       "      <td>117.331735</td>\n",
       "      <td>4.312366</td>\n",
       "      <td>7.117551</td>\n",
       "      <td>22.672571</td>\n",
       "      <td>0.271194</td>\n",
       "      <td>2009.492775</td>\n",
       "      <td>3.810694</td>\n",
       "      <td>108.049133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id   numeric_id  def_summary_assists  def_summary_batted_passes  \\\n",
       "0     ari_2014_1  9074.000000             0.333333                   0.000000   \n",
       "1    ari_2014_10  5453.149401             0.380565                   0.021261   \n",
       "2    ari_2014_11  5259.055969             0.356216                   0.000000   \n",
       "3    ari_2014_12  5376.940635             0.350820                   0.000000   \n",
       "4    ari_2014_13  5505.065511             0.474310                   0.056840   \n",
       "\n",
       "   def_summary_catch_rate  def_summary_declined_penalties  \\\n",
       "0               70.226821                        0.000000   \n",
       "1               73.237718                        0.040382   \n",
       "2               70.635314                        0.022154   \n",
       "3               69.261585                        0.000000   \n",
       "4               72.629271                        0.000000   \n",
       "\n",
       "   def_summary_forced_fumbles  def_summary_franchise_id  \\\n",
       "0                    0.000000                 16.000000   \n",
       "1                    0.012700                  1.000000   \n",
       "2                    0.019968                  1.000000   \n",
       "3                    0.030531                  1.857766   \n",
       "4                    0.029383                  1.852601   \n",
       "\n",
       "   def_summary_grades_coverage_defense  def_summary_grades_defense  ...  \\\n",
       "0                            60.584477                   61.850000  ...   \n",
       "1                            63.770461                   64.293564  ...   \n",
       "2                            63.691524                   64.336686  ...   \n",
       "3                            63.717993                   66.110585  ...   \n",
       "4                            62.197780                   65.108462  ...   \n",
       "\n",
       "   bench_defs  vertical_defs  broad_jump_defs  shuttle_defs  3cone_defs  \\\n",
       "0   21.210526      32.776271       115.778812      4.411314    7.242630   \n",
       "1   18.858733      33.144971       116.685233      4.331833    7.161912   \n",
       "2   18.245300      33.443009       117.542952      4.302931    7.106221   \n",
       "3   18.394475      33.400880       117.210515      4.320045    7.123781   \n",
       "4   19.007707      33.473970       117.331735      4.312366    7.117551   \n",
       "\n",
       "   explosive_defs  size_speed_defs  draft_yr_defs  round_defs  selection_defs  \n",
       "0       22.841669         0.282246    2010.157895    3.631579      104.315789  \n",
       "1       22.533098         0.275249    2009.447774    3.556507      101.102312  \n",
       "2       22.560918         0.270711    2009.178400    3.360297       94.331876  \n",
       "3       22.624919         0.272260    2009.342622    3.527502       99.279864  \n",
       "4       22.672571         0.271194    2009.492775    3.810694      108.049133  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_bio.columns = [str(col) + '_defs' for col in def_bio.columns]\n",
    "def_summ_conc_roll = pd.merge(def_summ_conc_roll, def_bio, left_on='player_team_id', right_on='unique_id_defs', how='left')\n",
    "def_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "def_summ_conc_roll = impute(def_summ_conc_roll)\n",
    "\n",
    "\n",
    "def snap_fixs(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "def_summ_conc_roll['def_summary_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_run_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_run_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_pass_rush'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_pass_rush'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_coverage'), axis=1) \n",
    "\n",
    "\n",
    "# pass_rush_summary_roll['pass_rush_snap_counts_pass_play'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='pass_rush_snap_counts_pass_play'), axis=1)\n",
    "# run_defense_summary_roll['run_defense_snap_counts_run'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='run_defense_snap_counts_run'), axis=1)\n",
    "# defense_coverage_scheme_roll['def_coverage_scheme_base_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_scheme_base_snap_counts_coverage'), axis=1)\n",
    "# defense_coverage_summary_roll['def_coverage_summary_coverage_snaps_per_target'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_summary_coverage_snaps_per_target'), axis=1)\n",
    "# slot_coverage_roll['def_slot_coverage_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_slot_coverage_snap_counts_defense'), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Subset into defense positional groups ##\n",
    "def_rundef = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['ed','di','lb'])]\n",
    "def_passrush = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','ed','di'])]\n",
    "def_cov = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','cb','s'])]\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_stats = def_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_run_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_rundef = def_rundef.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_pass_rush'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_passrush = def_passrush.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_cov = def_cov.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def weighted(nData, snap_Var='pass_rush_snap_counts_pass_play'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# pass_rush_stats = pass_rush_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='run_defense_snap_counts_run'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# run_defense_stats = run_defense_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_coverage_summary_coverage_snaps_per_target'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# defense_coverage_summary_stats = defense_coverage_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_coverage_scheme_base_snap_counts_coverage'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# defense_coverage_scheme_stats = defense_coverage_scheme_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_slot_coverage_snap_counts_defense'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# slot_coverage_stats = slot_coverage_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "#def_stats = pd.merge(def_stats, def_rundef, on='unique_team_id', how='inner').merge(def_passrush, on='unique_team_id', how='inner').merge(def_cov, on='unique_team_id', how='inner')\n",
    "\n",
    "\n",
    "def_stats.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute special teams weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_bio.columns = [str(col) + '_st' for col in st_bio.columns]\n",
    "st_kickers_roll = pd.merge(st_kickers_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "st_kickers_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def kicks_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_kickers_roll['kicks'] = st_kickers_roll['kicking_pat_attempts']+st_kickers_roll['kicking_total_attempts']\n",
    "st_kickers_roll ['kicks'] = st_kickers_roll .apply(lambda df: snap_fixs(df, var='kicks'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='kicks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_kickers = st_kickers_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_punters_roll = pd.merge(st_punters_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "st_punters_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def punts_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_punters_roll['punting_attempts'] = st_punters_roll.apply(lambda df: snap_fixs(df, var='punting_attempts'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='punting_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_punters = st_punters_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling File and write out to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_vars = spread_comb[spread_comb['schedule_week'] != '1']\n",
    "\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "\n",
    "dfs_list = [spread_ids,\n",
    "            tgs_roll,\n",
    "            fo_roll,\n",
    "            qb_stats,\n",
    "            rb_stats,\n",
    "            rec_stats,\n",
    "            ol_stats,\n",
    "           def_stats,\n",
    "           def_rundef,\n",
    "           def_cov,\n",
    "           def_passrush,\n",
    "           st_punters,\n",
    "           st_kickers]\n",
    "\n",
    "dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'],\n",
    "                                            how='left'), dfs_list)\n",
    "\n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "\n",
    "\n",
    "favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "dfs_team = dfs_team.rename(columns={c: c+'_fav' for c in dfs_team.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "not_fav_df = not_fav_df.rename(columns={c: c+'_dog' for c in not_fav_df.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "\n",
    "favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge files and write to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDER CONSTRUCTION: Creating function to create modeling file by user selected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "\n",
    "sample=[spread_vars,tgs_clean,fo_roll,qb_stats,rb_stats,rec_stats,ol_stats,def_stats,def_rundef,def_cov,def_passrush,st_punters,st_kickers]\n",
    "           \n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "def build_model_dataset(data_list=None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data_list: User provides a list of dataframes in format - [df1, df2, df3...] to be used to create modeling dataset.\n",
    "        \n",
    "        Options: \n",
    "        Football Outsiders\n",
    "        fo_roll - \n",
    "        \n",
    "        PFF\n",
    "        -Team Game Summaries -\n",
    "        tgs_roll -\n",
    "\n",
    "        -Passing:\n",
    "        qb_stats -\n",
    "        passing_depth_stats -\n",
    "        passing_pressure_stats -\n",
    "        passing_allowed_pressure_stats -\n",
    "        passing_concept_stats -\n",
    "        time_in_pocket_stats -\n",
    "        \n",
    "        -Receiving:\n",
    "        rec_stats -\n",
    "        receiving_concept -\n",
    "        receiving_depth -\n",
    "        receiving_scheme -\n",
    "        \n",
    "        -Blocking:\n",
    "        ol_stats -\n",
    "        offense_pass_blocking_roll -\n",
    "        offense_run_blocking_roll -\n",
    "        \n",
    "        -Defense:\n",
    "        def_stats -\n",
    "        def_rundef -\n",
    "        def_passrush -\n",
    "        def_cov -\n",
    "        pass_rush_stats -\n",
    "        defense_coverage_summary_stats -\n",
    "        run_defense_stats -\n",
    "        defense_coverage_scheme_stats -\n",
    "        slot_coverage_stats -\n",
    "        \n",
    "        -Special Teams:\n",
    "        st_kickers -\n",
    "        st_punters - \n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_list = [spread_ids]+data_list\n",
    "    dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'], how='left'), dataset_list)\n",
    "    spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "    favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "    not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "    not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "    favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    return pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "\n",
    "fin_df=build_model_dataset(data_list=sample)\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "#fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
