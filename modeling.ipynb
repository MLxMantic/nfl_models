{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d54ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomb/anaconda3/envs/cloak/lib/python3.7/site-packages/ipykernel_launcher.py:46: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor  #GBM algorithm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost.sklearn import XGBRegressor, XGBClassifier\n",
    "\n",
    "\n",
    "#from vars_utils import create_vars\n",
    "df = pd.read_csv('./modeling_data/tgs_models.csv')\n",
    "\n",
    "cutoff_week = 4 \n",
    "cur_week = 18 \n",
    "begin_year=2014, \n",
    "val_year_cutoff = 2021, \n",
    "targ='fav_cover'\n",
    "#df = pd.read_csv(df, error_bad_lines=True)\n",
    "df=df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "df = df.dropna(thresh=df.shape[1]-60)\n",
    "df = df[df['fav_cover'] != 'push']\n",
    "df['fav_cover'] = df['fav_cover'].apply(str)\n",
    "\n",
    "\n",
    "\n",
    "df.replace(np.nan, 0.01, inplace=True)\n",
    "df.fillna(df.median(), inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "118241d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fav_cover']=df['fav_cover'].replace(to_replace = ['cover','no cover'],value = [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7cd1834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomb/anaconda3/envs/cloak/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "df.replace(np.inf, .01, inplace=True)\n",
    "df.replace(-np.inf, -.01, inplace=True)\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "df=df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df = df[df['year'] >= begin_year]\n",
    "df = df[df['week'] >= cutoff_week]\n",
    "test = df[(df['year'] >= val_year_cutoff)|(df['year'] >= 2020)]\n",
    "test_10 = test[(test['year'] == 2020) & (test['week'] == cur_week)]\n",
    "test=test[~test.index.isin(test_10.index)]\n",
    "\n",
    "y_test = test[targ]\n",
    "\n",
    "data_Model = df[~df.index.isin(test.index)]\n",
    "data_Model = data_Model[~data_Model.index.isin(test_10.index)]\n",
    "data_Model = data_Model[(data_Model['week'] >= 4)|(df['year'] < 2020)]\n",
    "y_train = data_Model[targ]\n",
    "\n",
    "#y_reg_train = data_Model['spread_favorite']\n",
    "\n",
    "\n",
    "plyr_game_cols =[x for x in data_Model.columns[data_Model.columns.str.contains('player_game')]]\n",
    "week_game_cols =[x for x in data_Model.columns[data_Model.columns.str.contains('week_rank')]]\n",
    "pred_cols = [x for x in data_Model.columns if x not in ['team_id','team_favorite_id','fav_cover', 'home_matchup_id','home_team', 'away_team','team_conference_x','team_conference_y','team_division_x','team_division_y','fav_homeoraway_y','pf_x','pf_y','WLT','outlier','wl_x','wl_y','OU_result','pf','opponent_id_overall_pff_x','opponent_id_overall_pff_y', 'opponent_id_x','opponent_id_overall_pff','wl','WL','home_matchup_id_x','home_matchup_id_y','opponent_id_overall_pff_x','over_under_result','def_pff_prush_x','unique_team_id_x','unique_team_id_y','home_matchup_id']+plyr_game_cols+week_game_cols]\n",
    "\n",
    "\n",
    "X_train = data_Model[pred_cols]\n",
    "X_test = test[pred_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bebf852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 420)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e951fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scl', MinMaxScaler()), ('pca', PCA(n_components=49)),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=0.1, penalty='l1', random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "Pipeline(steps=[('clf',\n",
      "                 LogisticRegression(C=0.1, random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "Pipeline(steps=[('scl', MinMaxScaler()),\n",
      "                ('clf',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=500, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=42, reg_alpha=None, reg_lambda=None, ...))])\n",
      "Pipeline(steps=[('clf',\n",
      "                 RandomForestClassifier(n_estimators=700, n_jobs=4,\n",
      "                                        random_state=42))])\n",
      "Pipeline(steps=[('clf',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=500, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=42, reg_alpha=None, reg_lambda=None, ...))])\n",
      "Pipeline(steps=[('clf',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            n_estimators=500,\n",
      "                                            random_state=42))])\n",
      "LR pipeline test accuracy: 0.579\n",
      "lr2 pipeline test accuracy: 0.574\n",
      "xgb pipeline test accuracy: 0.662\n",
      "rForest pipeline test accuracy: 0.621\n",
      "gbm pipeline test accuracy: 0.662\n",
      "gbm2 pipeline test accuracy: 0.645\n",
      "Classifier with best accuracy: xgb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_lr = Pipeline([('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "('pca', PCA(n_components=X_train.shape[1]-1)),\n",
    "('clf', LogisticRegression(penalty='l1', C=.1, solver='liblinear',random_state=42))])\n",
    "\n",
    "pipe_lr2 = Pipeline([#('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "#('pca', PCA(n_components=X_train.shape[1]-1)),\n",
    "('clf', LogisticRegression(penalty='l2', C=.1, solver='liblinear',random_state=42))])\n",
    "\n",
    "pipe_xgb = Pipeline([('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", C=.1, dual=False))),\n",
    "#('pca', PCA(n_components=X_train.shape[1]-20)),\n",
    "('clf', XGBClassifier(n_estimators=500, random_state=42))])\n",
    "\n",
    "pipe_rf= Pipeline([#('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", C=1, dual=False))),\n",
    "#('pca', PCA(n_components=X_train.shape[1]-50)),\n",
    "#('clf', svm.SVC(probability=True, C=50, gamma=.1, kernel='rbf', random_state=42))])\n",
    "('clf', RandomForestClassifier(n_estimators=700, n_jobs=4, random_state=42))])\n",
    "\n",
    "pipe_gbm= Pipeline([#('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", C=.01, dual=False))),\n",
    "('clf', XGBClassifier(n_estimators=500, random_state=42))])\n",
    "\n",
    "pipe_gbm2= Pipeline([#('scl', MinMaxScaler()),\n",
    "#('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", C=.1, dual=False))),\n",
    "#('pca', PCA(n_components=X_train.shape[1]-25)),\n",
    "('clf', GradientBoostingClassifier(n_estimators=500, learning_rate=.01, random_state=42))])\n",
    "\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "pipelines = [pipe_lr, pipe_lr2, pipe_xgb, pipe_rf, pipe_gbm, pipe_gbm2]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0:'LR', 1:'lr2', 2:'xgb', 3:'rForest', 4:'gbm', 5:'gbm2'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    print(pipe)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Identify the most accurate model on test data\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "    if val.score(X_test, y_test) > best_acc:\n",
    "        best_acc = val.score(X_test, y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = idx\n",
    "\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6d154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0dd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ecfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
