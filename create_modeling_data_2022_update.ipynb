{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import ascii_letters, digits\n",
    "import utils.cleaning_dicts\n",
    "#import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_modeling_file.py\t\t       model_subset_feats.py\r\n",
      "chromedriver\t\t\t       notebooks\r\n",
      "covers_scrape.py\t\t       other_data\r\n",
      "create_modeling_data_2022-Copy1.ipynb  pfr\r\n",
      "create_modeling_data_2022.ipynb        pfr_injuries.py\r\n",
      "create_modeling_data_sample_all.ipynb  README.md\r\n",
      "create_player_pools_2022.ipynb\t       scripts\r\n",
      "current_data\t\t\t       spreads_data\r\n",
      "feat_sel.py\t\t\t       sumconcrollrb.csv\r\n",
      "historic_data\t\t\t       test.csv\r\n",
      "injhist.csv\t\t\t       update_spreads_file.py\r\n",
      "misc_files\t\t\t       utils\r\n",
      "modeling_data\t\t\t       weather_scraper_current_year.py\r\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.path.abspath(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Users must change the week values to the current week in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_week_int = 12\n",
    "cur_week_str = str(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in, clean and process all pff position datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "                ###   Read-in and clean all passing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "passing_depth = pd.read_csv('./historic_data/pff_data/passing_depth_hist.csv')\n",
    "passing_allowed_pressure = pd.read_csv('./historic_data/pff_data/passing_allowed_pressure_hist.csv')\n",
    "passing_pressure = pd.read_csv('./historic_data/pff_data/passing_pressure_hist.csv')\n",
    "passing_concept = pd.read_csv('./historic_data/pff_data/passing_concept_hist.csv')\n",
    "time_in_pocket = pd.read_csv('./historic_data/pff_data/time_in_pocket_hist.csv')\n",
    "passing_summ_conc = pd.read_csv('./historic_data/pff_data/passing_summ_conc_hist.csv')\n",
    "\n",
    "passing_depth_new = pd.read_csv('./scripts/nfl_all/passing_depth_2022.csv')\n",
    "passing_allowed_pressure_new = pd.read_csv('./scripts/nfl_all/passing_allowed_pressure_2022.csv')\n",
    "passing_pressure_new = pd.read_csv('./scripts/nfl_all/passing_pressure_2022.csv')\n",
    "passing_concept_new = pd.read_csv('./scripts/nfl_all/passing_concept_2022.csv')\n",
    "time_in_pocket_new = pd.read_csv('./scripts/nfl_all/time_in_pocket_2022.csv')\n",
    "passing_summ_conc_new = pd.read_csv('./scripts/nfl_all/passing_summ_conc_2022.csv')\n",
    "                                 \n",
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0).reset_index(drop=True)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0).reset_index(drop=True)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0).reset_index(drop=True)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "\n",
    "def drop_non_qbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df=df[df['position'] == 'QB']\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "    \n",
    "passing_depth = drop_non_qbs(passing_depth)\n",
    "passing_allowed_pressure = drop_non_qbs(passing_allowed_pressure)\n",
    "passing_pressure = drop_non_qbs(passing_pressure)\n",
    "passing_concept = drop_non_qbs(passing_concept)\n",
    "time_in_pocket = drop_non_qbs(time_in_pocket)\n",
    "passing_summ_conc = drop_non_qbs(passing_summ_conc)\n",
    "\n",
    "\n",
    "passing_depth = passing_depth[passing_depth.columns.drop(list(passing_depth.filter(regex='left|right|center')))]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all receiving datasets ### scripts/nfl_all\n",
    "####################################################################################\n",
    "\n",
    "rec_summ_conc = pd.read_csv('./historic_data/pff_data/rec_summ_conc_hist.csv')\n",
    "receiving_concept = pd.read_csv('./historic_data/pff_data/receiving_concept_hist.csv')\n",
    "receiving_depth = pd.read_csv('./historic_data/pff_data/receiving_depth_hist.csv')\n",
    "receiving_scheme = pd.read_csv('./historic_data/pff_data/receiving_scheme_hist.csv')\n",
    "                                 \n",
    "rec_summ_conc_new = pd.read_csv('./scripts/nfl_all/rec_summ_conc_2022.csv')\n",
    "receiving_concept_new = pd.read_csv('./scripts/nfl_all/receiving_concept_2022.csv')\n",
    "receiving_depth_new = pd.read_csv('./scripts/nfl_all/receiving_depth_2022.csv')\n",
    "receiving_scheme_new = pd.read_csv('./scripts/nfl_all/receiving_scheme_2022.csv')\n",
    "                                 \n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0).reset_index(drop=True)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0).reset_index(drop=True)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0).reset_index(drop=True)                                 \n",
    "\n",
    "def drop_non_recs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|TE|HB|FB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rec_summ_conc = drop_non_recs(rec_summ_conc)\n",
    "receiving_concept = drop_non_recs(receiving_concept)\n",
    "receiving_depth = drop_non_recs(receiving_depth)\n",
    "receiving_scheme = drop_non_recs(receiving_scheme)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all rushing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "rush_summ_conc = pd.read_csv('./historic_data/pff_data/rush_summ_conc_hist.csv')\n",
    "rush_summ_conc_new = pd.read_csv('./scripts/nfl_all/rush_summ_conc_2022.csv')                                 \n",
    "                                 \n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    " \n",
    "\n",
    "def drop_non_rbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|HB|FB|QB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rush_summ_conc = drop_non_rbs(rush_summ_conc)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all blocking datasets ###\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "block_summ_conc = pd.read_csv('./historic_data/pff_data/block_summ_conc_hist.csv')\n",
    "offense_pass_blocking = pd.read_csv('./historic_data/pff_data/offense_pass_blocking_hist.csv')\n",
    "offense_run_blocking = pd.read_csv('./historic_data/pff_data/offense_run_blocking_hist.csv')\n",
    "                                 \n",
    "block_summ_conc_new = pd.read_csv('./scripts/nfl_all/block_summ_conc_2022.csv')\n",
    "offense_pass_blocking_new = pd.read_csv('./scripts/nfl_all/offense_pass_blocking_2022.csv')\n",
    "offense_run_blocking_new = pd.read_csv('./scripts/nfl_all/offense_run_blocking_2022.csv')                                 \n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0).reset_index(drop=True)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "def drop_non_ols(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df = df[df['position'].notna()]\n",
    "    df= df[df.position.str.match('T|C|G|TE')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "\n",
    "block_summ_conc\t= drop_non_ols(block_summ_conc)\n",
    "offense_pass_blocking = drop_non_ols(offense_pass_blocking)\n",
    "offense_run_blocking = drop_non_ols(offense_run_blocking)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all defensive datasets ###\n",
    "####################################################################################\n",
    "\n",
    "def_summ_conc = pd.read_csv('./historic_data/pff_data/def_summ_conc_hist.csv')\n",
    "pass_rush_summary = pd.read_csv('./historic_data/pff_data/pass_rush_summary_hist.csv')\n",
    "run_defense_summary = pd.read_csv('./historic_data/pff_data/run_defense_summary_hist.csv')\n",
    "defense_coverage_scheme = pd.read_csv('./historic_data/pff_data/defense_coverage_scheme_hist.csv')\n",
    "defense_coverage_summary = pd.read_csv('./historic_data/pff_data/defense_coverage_summary_hist.csv')\n",
    "slot_coverage = pd.read_csv('./historic_data/pff_data/slot_coverage_hist.csv')\n",
    "                                 \n",
    "def_summ_conc_new = pd.read_csv('./scripts/nfl_all/def_summ_conc_2022.csv')\n",
    "pass_rush_summary_new = pd.read_csv('./scripts/nfl_all/pass_rush_summary_2022.csv')\n",
    "run_defense_summary_new = pd.read_csv('./scripts/nfl_all/run_defense_summary_2022.csv')\n",
    "defense_coverage_scheme_new = pd.read_csv('./scripts/nfl_all/defense_coverage_scheme_2022.csv')\n",
    "defense_coverage_summary_new = pd.read_csv('./scripts/nfl_all/defense_coverage_summary_2022.csv')\n",
    "slot_coverage_new = pd.read_csv('./scripts/nfl_all/slot_coverage_2022.csv')\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0).reset_index(drop=True)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0).reset_index(drop=True)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def drop_non_def(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "def_summ_conc = drop_non_def(def_summ_conc)\n",
    "pass_rush_summary = drop_non_def(pass_rush_summary)\n",
    "run_defense_summary = drop_non_def(run_defense_summary)\n",
    "defense_coverage_scheme = drop_non_def(defense_coverage_scheme)\n",
    "defense_coverage_summary = drop_non_def(defense_coverage_summary)\n",
    "slot_coverage = drop_non_def(slot_coverage)\n",
    "\n",
    "def_summ_conc=def_summ_conc[def_summ_conc['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "pass_rush_summary=pass_rush_summary[pass_rush_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\"])]\n",
    "run_defense_summary=run_defense_summary[run_defense_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "defense_coverage_scheme=defense_coverage_scheme[defense_coverage_scheme['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "defense_coverage_summary=defense_coverage_summary[defense_coverage_summary['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "slot_coverage=slot_coverage[slot_coverage['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all special teams datasets ###\n",
    "####################################################################################\t\n",
    "\n",
    "st_kickers = pd.read_csv('./historic_data/pff_data/st_kickers_hist.csv')\n",
    "st_punters = pd.read_csv('./historic_data/pff_data/st_punters_hist.csv')\n",
    "\n",
    "st_kickers_new = pd.read_csv('./scripts/nfl_all/st_kickers_2022.csv')\n",
    "st_punters_new = pd.read_csv('./scripts/nfl_all/st_punters_2022.csv')                                 \n",
    "                                 \n",
    "                                 \n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0).reset_index(drop=True)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def clean_spec(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "st_kickers =clean_spec(st_kickers)\n",
    "st_punters = clean_spec(st_punters)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute all missing values in pff dataframe - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 276 ms, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth = impute(passing_depth)\n",
    "passing_allowed_pressure = impute(passing_allowed_pressure)\n",
    "passing_pressure = impute(passing_pressure)\n",
    "passing_concept = impute(passing_concept)\n",
    "time_in_pocket = impute(time_in_pocket)\n",
    "passing_summ_conc = impute(passing_summ_conc)\n",
    "\n",
    "rec_summ_conc = impute(rec_summ_conc)\n",
    "receiving_concept = impute(receiving_concept)\n",
    "receiving_depth = impute(receiving_depth)\n",
    "receiving_scheme = impute(receiving_scheme)\n",
    "\n",
    "rush_summ_conc = impute(rush_summ_conc)\n",
    "\n",
    "block_summ_conc = impute(block_summ_conc)\n",
    "offense_pass_blocking = impute(offense_pass_blocking)\n",
    "offense_run_blocking = impute(offense_run_blocking)\n",
    "\n",
    "def_summ_conc = impute(def_summ_conc)\n",
    "pass_rush_summary = impute(pass_rush_summary)\n",
    "run_defense_summary = impute(run_defense_summary)\n",
    "defense_coverage_scheme = impute(defense_coverage_scheme)\n",
    "defense_coverage_summary = impute(defense_coverage_summary)\n",
    "slot_coverage = impute(slot_coverage)\n",
    "\n",
    "st_kickers = impute(st_kickers)\n",
    "st_punters = impute(st_punters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prefixes to all columns.  Creating column names structured as \"source-dataset_column-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc)\n",
    "rush_summ_conc = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc)\n",
    "rec_summ_conc = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc)\n",
    "block_summ_conc = id_prefix(prefix=\"block_summary_\", df=block_summ_conc)\n",
    "def_summ_conc = id_prefix(prefix=\"def_summary_\", df=def_summ_conc)\n",
    "st_kickers = id_prefix(prefix=\"kicking_\", df=st_kickers)\n",
    "st_punters = id_prefix(prefix=\"punting_\", df=st_punters)\n",
    "\n",
    "\n",
    "passing_depth = create_prefix(prefix=\"pass_depth_\", df=passing_depth)\n",
    "passing_allowed_pressure = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure)\n",
    "passing_pressure = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure)\n",
    "passing_concept = create_prefix(prefix=\"pass_concept_\", df=passing_concept)\n",
    "time_in_pocket = create_prefix(prefix=\"pass_time_\", df=time_in_pocket)\n",
    "\n",
    "\n",
    "receiving_concept = create_prefix(prefix=\"rec_concept_\", df=receiving_concept)\n",
    "receiving_depth = create_prefix(prefix=\"rec_depth_\", df=receiving_depth)\n",
    "receiving_scheme = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme)\n",
    "\n",
    "offense_pass_blocking = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking)\n",
    "offense_run_blocking = create_prefix(prefix=\"run_block_\", df=offense_run_blocking)\n",
    "\n",
    "\n",
    "pass_rush_summary = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary)\n",
    "run_defense_summary = create_prefix(prefix=\"run_defense_\", df=run_defense_summary)\n",
    "defense_coverage_scheme = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme)\n",
    "defense_coverage_summary = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary)\n",
    "slot_coverage = create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in weather data and clean raiders name - merged onto spreads data below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in weather data###\n",
    "weather = pd.read_csv('./current_data/week_'+cur_week_str+'/weather_hist_all.csv')\n",
    "\n",
    "def raiders(df):\n",
    "    if 'oak' in str(df.away_matchup_id) and '2020' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2021' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2022' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    else:\n",
    "        return df.away_matchup_id\n",
    "weather['away_matchup_id'] = weather.apply(lambda df: raiders(df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spreads data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t###   spreads data cleaning and engineering ###\n",
    "####################################################################################\n",
    "\n",
    "spreads = pd.read_csv('./current_data/week_'+cur_week_str+'/spreadsw'+cur_week_str+'.csv')\n",
    "\n",
    "new_acc = {'oak':'lv',\n",
    "          'sd':'lac',\n",
    "          'stl':'lar'}  \n",
    "\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].map(new_acc).fillna(spreads['team_home_abb'])\n",
    "spreads['away_team_abb'] = spreads['away_team_abb'].map(new_acc).fillna(spreads['away_team_abb']) \n",
    "\n",
    "spreads = spreads[spreads['schedule_season']>=2014]\n",
    "spreads = spreads[['schedule_season','schedule_week','team_home_abb','score_home','score_away','away_team_abb','team_favorite_id','spread_favorite','over_under_line','starting_spread', 'Total Score Open',\n",
    "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement','ou_movement', 'strong_movement', 'fav_team_stronger',\n",
    "                  'home_days','away_days']]\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].astype(str)\n",
    "spreads['team_favorite_id'] = spreads['team_favorite_id'].astype(str)\n",
    "spreads['over_under_line'] = spreads['over_under_line'].astype(float)\n",
    "\n",
    "\n",
    "def fav_spread(nData):\n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    else:\n",
    "        pass\n",
    "spreads['fav_spread'] = spreads.apply(lambda nData: fav_spread(nData), axis=1)\n",
    "\n",
    "def nonfav_spread(nData):\n",
    "    if nData['team_home_abb'] != nData['team_favorite_id']:\n",
    "        return nData['team_home_abb']\n",
    "    elif nData['away_team_abb'] != nData['team_favorite_id']:\n",
    "        return nData['away_team_abb']\n",
    "    else:\n",
    "        pass\n",
    "spreads['team_notfav_id'] = spreads.apply(lambda nData: nonfav_spread(nData), axis=1)\n",
    "\n",
    "def cover_or_not(nData):    \n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        if ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] > 0:\n",
    "            return 'Cover'\n",
    "        elif ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'       \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:        \n",
    "        if ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] > 0:            \n",
    "            return 'Cover'        \n",
    "        elif ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'        \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "spreads['fav_cover'] = spreads.apply(lambda nData: cover_or_not(nData), axis=1)\n",
    "\n",
    "def OU_or_not(nData):    \n",
    "    if (nData['score_home']+nData['score_away']) > nData['over_under_line']:        \n",
    "        return 'Over'    \n",
    "    elif (nData['score_home']-nData['score_away']) == nData['over_under_line']:        \n",
    "        return 'Push'    \n",
    "    else:        \n",
    "        return 'Under'\n",
    "spreads['over_under_result'] = spreads.apply(lambda nData: OU_or_not(nData), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "spreads['schedule_season'] = spreads['schedule_season'].apply(int)    \n",
    "spreads['schedule_week'] = spreads['schedule_week'].apply(int)  \n",
    "data = spreads.sort_values(by=[\"team_home_abb\",\"schedule_season\",\"schedule_week\"], ascending=[True, True, True])\n",
    "\n",
    "def clean_spreads(df):\n",
    "    ##  basic scrubbing to clean data ##    \n",
    "    df['schedule_season'] = df['schedule_season'].apply(str)    \n",
    "    df['schedule_week'] = df['schedule_week'].apply(str)        \n",
    "    df=df.apply(lambda x: x.astype(str).str.lower())    \n",
    "    #df['schedule_week']=df['schedule_week'].astype(str).str[:-2].astype(object)    \n",
    "    #df['schedule_season'] = df['schedule_season'].astype(str).str[:-2].astype(object)  \n",
    "    df['team_home_abb'] = df['team_home_abb'].map(new_acc).fillna(df['team_home_abb'])\n",
    "    df['away_team_abb'] = df['away_team_abb'].map(new_acc).fillna(df['away_team_abb'])\n",
    "    \n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"home_matchup_id\", (df['team_home_abb']+'vs'+df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(1, \"away_matchup_id\", (df['away_team_abb']+'@'+df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(2, \"home_id\", (df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(3, \"away_id\", (df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    return df\n",
    "    \n",
    "data = clean_spreads(data)\n",
    "\n",
    "data = pd.merge(data, weather, on='away_matchup_id', how='left')\n",
    "\n",
    "\n",
    "sh = data\n",
    "sa = data\n",
    "\n",
    "sh = sh.rename(columns={'home_id':'team_id'})\n",
    "sh.drop('away_id', axis=1, inplace=True)\n",
    "\n",
    "sa = sa.rename(columns={'away_id':'team_id'})\n",
    "sa.drop('home_id', axis=1, inplace=True)\n",
    "\n",
    "spread_comb = pd.concat([sh, sa], axis=0).reset_index(drop=True)\n",
    "spread_comb['team_abb'] = spread_comb['team_id'].astype(str).str[:3]\n",
    "spread_comb['team_abb'] = spread_comb['team_abb'].str.replace(\"_\",\"\")\n",
    "\n",
    "def hora1(nData):\n",
    "    if nData['team_favorite_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    elif nData['team_notfav_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['homeoraway'] = spread_comb.apply(lambda nData: hora1(nData), axis=1)\n",
    "\n",
    "def hora(nData):\n",
    "    if nData['team_favorite_id'] == nData['away_team_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['fav_homeoraway'] = spread_comb.apply(lambda nData: hora(nData), axis=1)\n",
    "#sh['fav_homeoraway'] = sh.apply(lambda nData: hora(nData), axis=1)\n",
    "\n",
    "def ws(nData):\n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ls(nData):    \n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def days(nData):\n",
    "    if nData['team_favorite_id'] == nData['team_home_abb']:\n",
    "        return nData['home_days']\n",
    "    elif nData['team_notfav_id'] == nData['team_home_abb']:\n",
    "        return nData['home_days']\n",
    "    else:\n",
    "        return nData['away_days']\n",
    "spread_comb['days_last_played'] = spread_comb.apply(lambda nData: days(nData), axis=1)\n",
    "\n",
    "spread_comb['ats_w'] = spread_comb.apply(lambda nData: ws(nData), axis=1)\n",
    "spread_comb['ats_l'] = spread_comb.apply(lambda nData: ls(nData), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>away_matchup_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>schedule_season</th>\n",
       "      <th>schedule_week</th>\n",
       "      <th>team_home_abb</th>\n",
       "      <th>score_home</th>\n",
       "      <th>score_away</th>\n",
       "      <th>away_team_abb</th>\n",
       "      <th>team_favorite_id</th>\n",
       "      <th>...</th>\n",
       "      <th>precip</th>\n",
       "      <th>dome</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>team_abb</th>\n",
       "      <th>homeoraway</th>\n",
       "      <th>fav_homeoraway</th>\n",
       "      <th>days_last_played</th>\n",
       "      <th>ats_w</th>\n",
       "      <th>ats_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>wasvsphi_2022_3</td>\n",
       "      <td>phi@was_2022_3</td>\n",
       "      <td>phi_2022_3</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>phi</td>\n",
       "      <td>phi</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>phi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>wasvsten_2022_5</td>\n",
       "      <td>ten@was_2022_5</td>\n",
       "      <td>ten_2022_5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>was</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>ten</td>\n",
       "      <td>ten</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ten</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>wasvsgb_2022_7</td>\n",
       "      <td>gb@was_2022_7</td>\n",
       "      <td>gb_2022_7</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>was</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>gb</td>\n",
       "      <td>gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>gb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>wasvsmin_2022_9</td>\n",
       "      <td>min@was_2022_9</td>\n",
       "      <td>min_2022_9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>was</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>wasvsatl_2022_12</td>\n",
       "      <td>atl@was_2022_12</td>\n",
       "      <td>atl_2022_12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>was</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>atl</td>\n",
       "      <td>was</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>atl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       home_matchup_id  away_matchup_id      team_id schedule_season  \\\n",
       "4817   wasvsphi_2022_3   phi@was_2022_3   phi_2022_3            2022   \n",
       "4818   wasvsten_2022_5   ten@was_2022_5   ten_2022_5            2022   \n",
       "4819    wasvsgb_2022_7    gb@was_2022_7    gb_2022_7            2022   \n",
       "4820   wasvsmin_2022_9   min@was_2022_9   min_2022_9            2022   \n",
       "4821  wasvsatl_2022_12  atl@was_2022_12  atl_2022_12            2022   \n",
       "\n",
       "     schedule_week team_home_abb score_home score_away away_team_abb  \\\n",
       "4817             3           was        8.0       24.0           phi   \n",
       "4818             5           was       17.0       21.0           ten   \n",
       "4819             7           was       23.0       21.0            gb   \n",
       "4820             9           was       17.0       20.0           min   \n",
       "4821            12           was        nan        nan           atl   \n",
       "\n",
       "     team_favorite_id  ... precip dome temperature wind_mph team_abb  \\\n",
       "4817              phi  ...    1.0  0.0        75.0      9.0      phi   \n",
       "4818              ten  ...    0.0  0.0        62.0      7.0      ten   \n",
       "4819               gb  ...    1.0  0.0        62.0      7.0       gb   \n",
       "4820              min  ...    0.0  0.0        74.0      9.0      min   \n",
       "4821              was  ...    1.0  0.0        56.0     12.0      atl   \n",
       "\n",
       "     homeoraway fav_homeoraway days_last_played ats_w ats_l  \n",
       "4817          1              1              7.0     0     1  \n",
       "4818          1              1              7.0     0     1  \n",
       "4819          1              1             10.0     1     0  \n",
       "4820          1              1              7.0     0     0  \n",
       "4821          1              0              7.0     0     1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread_comb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Football Outsiders rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rolling_fo(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    #data=data.fillna(data.mean())\n",
    "    num_cols = ['total_dvoa', 'off_dvoa','off_pass_dvoa', 'off_rush_dvoa', 'def_dvoa', 'def_pass_dvoa','def_rush_dvoa', 'special_teams_dvoa']\n",
    "    ids = data[['team_id', 'year', 'team', 'week', 'opp']].reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in historic weekly football outsiders data and create the current week rows for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>51</th>\n",
       "      <th>327</th>\n",
       "      <th>173</th>\n",
       "      <th>122</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_id</th>\n",
       "      <td>ari_2022_121</td>\n",
       "      <td>atl_2022_121</td>\n",
       "      <td>bal_2022_121</td>\n",
       "      <td>buf_2022_121</td>\n",
       "      <td>car_2022_121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>ari</td>\n",
       "      <td>atl</td>\n",
       "      <td>bal</td>\n",
       "      <td>buf</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             51            327           173           122  \\\n",
       "team_id             ari_2022_121  atl_2022_121  bal_2022_121  buf_2022_121   \n",
       "year                        2022          2022          2022          2022   \n",
       "team                         ari           atl           bal           buf   \n",
       "week                          12            12            12            12   \n",
       "opp                          NaN           NaN           NaN           NaN   \n",
       "total_dvoa                   NaN           NaN           NaN           NaN   \n",
       "off_dvoa                     NaN           NaN           NaN           NaN   \n",
       "off_pass_dvoa                NaN           NaN           NaN           NaN   \n",
       "off_rush_dvoa                NaN           NaN           NaN           NaN   \n",
       "def_dvoa                     NaN           NaN           NaN           NaN   \n",
       "def_pass_dvoa                NaN           NaN           NaN           NaN   \n",
       "def_rush_dvoa                NaN           NaN           NaN           NaN   \n",
       "special_teams_dvoa           NaN           NaN           NaN           NaN   \n",
       "\n",
       "                             10   \n",
       "team_id             car_2022_121  \n",
       "year                        2022  \n",
       "team                         car  \n",
       "week                          12  \n",
       "opp                          NaN  \n",
       "total_dvoa                   NaN  \n",
       "off_dvoa                     NaN  \n",
       "off_pass_dvoa                NaN  \n",
       "off_rush_dvoa                NaN  \n",
       "def_dvoa                     NaN  \n",
       "def_pass_dvoa                NaN  \n",
       "def_rush_dvoa                NaN  \n",
       "special_teams_dvoa           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t##Create the current weeks fo team_ids/rows to roll into##\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "fo_data_new = fo_data[~fo_data['week'].isnull()]\n",
    "fo_data_new=fo_data_new.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "fo_data_new['team_id'] = fo_data_new['team_id'].str[:-1]\n",
    "fo_data_new['team_id']=fo_data_new['team_id'].str.replace(\"2022_\", str(\"2022_\"+cur_week_str))\n",
    "\n",
    "\n",
    "fo_data_new = fo_data_new.sort_values(by=[\"team\",\"week\"], ascending=[True, False])\n",
    "fo_data_new[fo_data_new.columns[4:]] = np.nan\n",
    "fo_data_new.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in the historic FO data and concat all of them together for our rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_team_id</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2014_2</td>\n",
       "      <td>ari_2014_3</td>\n",
       "      <td>ari_2014_5</td>\n",
       "      <td>ari_2014_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1           2           3           4\n",
       "unique_team_id      ari_2014_1  ari_2014_2  ari_2014_3  ari_2014_5  ari_2014_6\n",
       "total_dvoa                 NaN        0.59       0.625    0.613333        0.56\n",
       "off_dvoa                   NaN        0.53       0.505        0.55    0.533333\n",
       "off_pass_dvoa              NaN        0.53        0.45    0.516667    0.486667\n",
       "off_rush_dvoa              NaN        0.51        0.57        0.55        0.56\n",
       "def_dvoa                   NaN        0.61        0.56        0.49    0.406667\n",
       "def_pass_dvoa              NaN        0.59        0.57        0.53    0.483333\n",
       "def_rush_dvoa              NaN        0.52        0.47        0.42    0.353333\n",
       "special_teams_dvoa         NaN        0.35        0.61        0.61    0.636667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo_data_2022 = pd.read_csv(\"./historic_data/fo_data/fo_weekly_hist.csv\")\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "\n",
    "fo = pd.concat([fo_data_2022, fo_data, fo_data_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "fo['team'] = fo['team'].map(new_acc).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(new_acc).fillna(fo['opp']) \n",
    "\n",
    "fo['team'] = fo['team'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['opp'])\n",
    "\n",
    "##combine our current season fo data with the new week 4 rows we just made##\n",
    "fo_roll = rolling_fo(data=fo, roll_value=3, roll_type='mean')\n",
    "fo_roll = fo_roll.rename(columns={'team_id': 'unique_team_id'})\n",
    "\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('sd_','lac_')\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('oak_','lv_')\n",
    "fo_roll.drop(['year','team','week','opp'], axis=1, inplace=True)\n",
    "\n",
    "fo_roll.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFF team_game_summaries (tgs) clean and create current week rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_new_week = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "\n",
    "tgs_new_week = tgs_new_week[~tgs_new_week['week'].isnull()]\n",
    "tgs_new_week=tgs_new_week.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "\n",
    "tgs_new_week['team_name'] = tgs_new_week['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs_new_week['team'])\n",
    "tgs_new_week['opponent_name'] = tgs_new_week['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs_new_week['opponent'])\n",
    "\n",
    "tgs_new_week['home_or_away']=tgs_new_week['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs_new_week['home_team'] = tgs_new_week.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs_new_week['away_team'] = tgs_new_week.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "tgs_new_week = clean_pff_team_summ(tgs_new_week)\n",
    "tgs_new_week['wl_int'] = ''\n",
    "tgs_new_week = tgs_new_week.sort_values(by=[\"team_name\",\"week\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in historic tgs data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_data_2022 = pd.read_csv(\"./historic_data/pff_data/team_game_summaries_historic.csv\")\n",
    "tgs_data_cur = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "tgs = pd.concat([tgs_data_2022, tgs_data_cur], axis=0)\n",
    "\n",
    "tgs = tgs[tgs['year'] >= 2014]\n",
    "\n",
    "\n",
    "tgs['team_name'] = tgs['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs['team'])\n",
    "tgs['opponent_name'] = tgs['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs['opponent'])\n",
    "\n",
    "##adding just incase accronyms have changed\n",
    "tgs['team_name'] = tgs['team_name'].map(new_acc).fillna(tgs['team_name'])\n",
    "tgs['opponent_name'] = tgs['opponent_name'].map(new_acc).fillna(tgs['opponent_name']) \n",
    "\n",
    "tgs['home_or_away']=tgs['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs['home_team'] = tgs.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs['away_team'] = tgs.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    ##Impute missing special teams data added after 2014##\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_name'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "   \n",
    "    return df\n",
    "\n",
    "\n",
    "   \n",
    "tgs_clean = clean_pff_team_summ(tgs)\n",
    "\n",
    "\n",
    "tgs_clean = pd.concat([tgs_clean, tgs_new_week], axis=0).reset_index(drop=True)\n",
    "tgs_clean['year']=tgs_clean['year'].apply(int)\n",
    "tgs_clean['week']=tgs_clean['week'].apply(int)\n",
    "tgs_clean['special_teams']=tgs_clean['special_teams'].apply(float)\n",
    "tgs_clean = tgs_clean.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "\n",
    "tgs_clean = tgs_clean[['unique_team_id','team_id_impute', 'home_matchup_id','opponent_id','wl','pf','pa','team_name','opponent_name','year','week','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>opponent_id</th>\n",
       "      <th>wl</th>\n",
       "      <th>pf</th>\n",
       "      <th>pa</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>pass_blocking</th>\n",
       "      <th>receiving</th>\n",
       "      <th>rushing</th>\n",
       "      <th>run_blocking</th>\n",
       "      <th>defense</th>\n",
       "      <th>rush_defense</th>\n",
       "      <th>tackling</th>\n",
       "      <th>pass_rush</th>\n",
       "      <th>coverage</th>\n",
       "      <th>special_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>was_2022_8</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>indvswas_2022_8</td>\n",
       "      <td>ind_2022_8</td>\n",
       "      <td>W</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>was</td>\n",
       "      <td>ind</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>71.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>74.2</td>\n",
       "      <td>64.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>was_2022_9</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsmin_2022_9</td>\n",
       "      <td>min_2022_9</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>was</td>\n",
       "      <td>min</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>63.9</td>\n",
       "      <td>64.4</td>\n",
       "      <td>70.3</td>\n",
       "      <td>58.4</td>\n",
       "      <td>69.3</td>\n",
       "      <td>58.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>78.8</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>was_2022_10</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>phivswas_2022_10</td>\n",
       "      <td>phi_2022_10</td>\n",
       "      <td>W</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>phi</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>39.8</td>\n",
       "      <td>71.7</td>\n",
       "      <td>75.1</td>\n",
       "      <td>56.1</td>\n",
       "      <td>65.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>66.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>76.3</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>was_2022_11</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>houvswas_2022_11</td>\n",
       "      <td>hou_2022_11</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>was</td>\n",
       "      <td>hou</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>54.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>89.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>79.9</td>\n",
       "      <td>74.4</td>\n",
       "      <td>85.9</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>was_2022_12</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>houvswas_2022_12</td>\n",
       "      <td>hou_2022_12</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>was</td>\n",
       "      <td>hou</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>54.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>89.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>79.9</td>\n",
       "      <td>74.4</td>\n",
       "      <td>85.9</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id team_id_impute   home_matchup_id  opponent_id wl  pf  pa  \\\n",
       "4442     was_2022_8       was_2022   indvswas_2022_8   ind_2022_8  W  17  16   \n",
       "4443     was_2022_9       was_2022   wasvsmin_2022_9   min_2022_9  L  17  20   \n",
       "4444    was_2022_10       was_2022  phivswas_2022_10  phi_2022_10  W  32  21   \n",
       "4445    was_2022_11       was_2022  houvswas_2022_11  hou_2022_11  W  23  10   \n",
       "4476    was_2022_12       was_2022  houvswas_2022_12  hou_2022_12  W  23  10   \n",
       "\n",
       "     team_name opponent_name  year  ...  pass_blocking  receiving  rushing  \\\n",
       "4442       was           ind  2022  ...           61.0       72.9     71.1   \n",
       "4443       was           min  2022  ...           63.9       64.4     70.3   \n",
       "4444       was           phi  2022  ...           39.8       71.7     75.1   \n",
       "4445       was           hou  2022  ...           54.5       73.2     73.4   \n",
       "4476       was           hou  2022  ...           54.5       73.2     73.4   \n",
       "\n",
       "      run_blocking  defense  rush_defense  tackling  pass_rush  coverage  \\\n",
       "4442          66.9     72.1          74.2      64.2       63.6      67.0   \n",
       "4443          58.4     69.3          58.6      77.3       78.8      62.0   \n",
       "4444          56.1     65.2          46.6      66.0       58.5      76.3   \n",
       "4445          67.0     89.2          82.3      79.9       74.4      85.9   \n",
       "4476          67.0     89.2          82.3      79.9       74.4      85.9   \n",
       "\n",
       "      special_teams  \n",
       "4442           68.0  \n",
       "4443           70.4  \n",
       "4444           82.7  \n",
       "4445           58.4  \n",
       "4476           58.4  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tgs rolling mean function and combine all tgs datasets together and pass through the rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_tgs(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "        \n",
    "tgs_roll = rolling_tgs(data=tgs_clean, roll_value=3, roll_type='mean')\n",
    "\n",
    "tgs_roll = tgs_roll[['unique_team_id','wl','pf','pa','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_roll = tgs_roll.rename(columns={c: c+'_tgs' for c in tgs_roll.columns if c not in ['unique_team_id','wl','pf','pa']})\n",
    "\n",
    "tgs_roll.rename(columns={'unique_team_id_tgs_pff':'unique_team_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all the pff current week datasets and prep for rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth_new = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/passing_depth_new_pp_w\"+cur_week_str+\".csv\")\n",
    "passing_allowed_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_allowed_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_concept_new_pp_w'+cur_week_str+\".csv\")\n",
    "time_in_pocket_new = pd.read_csv('./current_data/week_'+cur_week_str+'/time_in_pocket_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_summ_conc_new_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "rec_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rec_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_concept_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_depth_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_depth_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "rush_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rush_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "block_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/block_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "offense_pass_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_pass_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "offense_run_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_run_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "def_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/def_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "pass_rush_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/pass_rush_summary_pp_w'+cur_week_str+\".csv\")\n",
    "run_defense_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/run_defense_summary_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_summary_pp_w'+cur_week_str+\".csv\")\n",
    "slot_coverage_new = pd.read_csv('./current_data/week_'+cur_week_str+'/slot_coverage_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "st_kickers_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_kickers_pp_w'+cur_week_str+\".csv\")\n",
    "st_punters_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_punters_no_inj_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "passing_depth_new['week'] = cur_week_str \n",
    "passing_allowed_pressure_new['week'] = cur_week_str \n",
    "passing_pressure_new['week'] = cur_week_str \n",
    "passing_concept_new['week'] = cur_week_str \n",
    "time_in_pocket_new['week'] = cur_week_str \n",
    "passing_summ_conc_new['week'] = cur_week_str \n",
    "rec_summ_conc_new['week'] = cur_week_str \n",
    "receiving_concept_new['week'] = cur_week_str\n",
    "receiving_depth_new['week'] = cur_week_str \n",
    "receiving_scheme_new['week'] = cur_week_str \n",
    "rush_summ_conc_new['week'] = cur_week_str\n",
    "block_summ_conc_new['week'] = cur_week_str \n",
    "offense_pass_blocking_new['week'] = cur_week_str \n",
    "offense_run_blocking_new['week'] = cur_week_str \n",
    "def_summ_conc_new['week'] = cur_week_str \n",
    "pass_rush_summary_new['week'] = cur_week_str \n",
    "run_defense_summary_new['week'] = cur_week_str \n",
    "defense_coverage_scheme_new['week'] = cur_week_str \n",
    "defense_coverage_summary_new['week'] = cur_week_str \n",
    "slot_coverage_new['week'] = cur_week_str \n",
    "st_kickers_new['week'] = cur_week_str \n",
    "st_punters_new['week'] = cur_week_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>player</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>player_game_count</th>\n",
       "      <th>assists</th>\n",
       "      <th>...</th>\n",
       "      <th>tackles</th>\n",
       "      <th>targets</th>\n",
       "      <th>total_pressures</th>\n",
       "      <th>touchdowns</th>\n",
       "      <th>yards</th>\n",
       "      <th>yards_after_catch</th>\n",
       "      <th>yards_per_reception</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>plyr_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>michaelhoecht_lar_2022_12</td>\n",
       "      <td>lar_2022_12</td>\n",
       "      <td>michaelhoecht_lar_2022</td>\n",
       "      <td>lar_2022</td>\n",
       "      <td>michaelhoecht</td>\n",
       "      <td>108840</td>\n",
       "      <td>di</td>\n",
       "      <td>lar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>deealford_atl_2022_12</td>\n",
       "      <td>atl_2022_12</td>\n",
       "      <td>deealford_atl_2022</td>\n",
       "      <td>atl_2022</td>\n",
       "      <td>deealford</td>\n",
       "      <td>110542</td>\n",
       "      <td>cb</td>\n",
       "      <td>atl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>jaylenwatson_kc_2022_12</td>\n",
       "      <td>kc_2022_12</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>samwebb_lv_2022_12</td>\n",
       "      <td>lv_2022_12</td>\n",
       "      <td>samwebb_lv_2022</td>\n",
       "      <td>lv_2022</td>\n",
       "      <td>samwebb</td>\n",
       "      <td>134606</td>\n",
       "      <td>cb</td>\n",
       "      <td>lv</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>joshuawilliams_kc_2022_12</td>\n",
       "      <td>kc_2022_12</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p_id unique_team_id          player_team_id  \\\n",
       "645  michaelhoecht_lar_2022_12    lar_2022_12  michaelhoecht_lar_2022   \n",
       "646      deealford_atl_2022_12    atl_2022_12      deealford_atl_2022   \n",
       "647    jaylenwatson_kc_2022_12     kc_2022_12    jaylenwatson_kc_2022   \n",
       "648         samwebb_lv_2022_12     lv_2022_12         samwebb_lv_2022   \n",
       "649  joshuawilliams_kc_2022_12     kc_2022_12  joshuawilliams_kc_2022   \n",
       "\n",
       "    team_id_impute          player  numeric_id position team_name  \\\n",
       "645       lar_2022   michaelhoecht      108840       di       lar   \n",
       "646       atl_2022       deealford      110542       cb       atl   \n",
       "647        kc_2022    jaylenwatson      131960       cb        kc   \n",
       "648        lv_2022         samwebb      134606       cb        lv   \n",
       "649        kc_2022  joshuawilliams      156083       cb        kc   \n",
       "\n",
       "     player_game_count  assists  ...  tackles  targets  total_pressures  \\\n",
       "645                  1        0  ...        0        0                0   \n",
       "646                  1        0  ...        0        0                0   \n",
       "647                  1        0  ...        0        0                0   \n",
       "648                  1        0  ...        0        0                0   \n",
       "649                  1        2  ...        0        0                0   \n",
       "\n",
       "     touchdowns  yards  yards_after_catch  yards_per_reception  week  year  \\\n",
       "645           0      0                  0                    0    12  2022   \n",
       "646           0      0                  0                    0    12  2022   \n",
       "647           0      0                  0                    0    12  2022   \n",
       "648           0      0                  0                    0    12  2022   \n",
       "649           0      0                  0                    0    12  2022   \n",
       "\n",
       "     plyr_number  \n",
       "645           12  \n",
       "646           12  \n",
       "647           12  \n",
       "648           12  \n",
       "649           12  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the prefixes like we did for the pff datasets above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','team_id_impute','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc_new = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc_new)\n",
    "rush_summ_conc_new  = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc_new)\n",
    "rec_summ_conc_new  = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc_new)\n",
    "block_summ_conc_new  = id_prefix(prefix=\"block_summary_\", df=block_summ_conc_new)\n",
    "def_summ_conc_new  = id_prefix(prefix=\"def_summary_\", df=def_summ_conc_new)\n",
    "st_kickers_new  = id_prefix(prefix=\"kicking_\", df=st_kickers_new)\n",
    "st_punters_new  = id_prefix(prefix=\"punting_\", df=st_punters_new)\n",
    "\n",
    "\n",
    "passing_depth_new = create_prefix(prefix=\"pass_depth_\", df=passing_depth_new)\n",
    "passing_allowed_pressure_new = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure_new)\n",
    "passing_pressure_new = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure_new)\n",
    "passing_concept_new = create_prefix(prefix=\"pass_concept_\", df=passing_concept_new)\n",
    "time_in_pocket_new = create_prefix(prefix=\"pass_time_\", df=time_in_pocket_new)\n",
    "\n",
    "\n",
    "receiving_concept_new = create_prefix(prefix=\"rec_concept_\", df=receiving_concept_new)\n",
    "receiving_depth_new = create_prefix(prefix=\"rec_depth_\", df=receiving_depth_new)\n",
    "receiving_scheme_new = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme_new)\n",
    "\n",
    "offense_pass_blocking_new = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking_new)\n",
    "offense_run_blocking_new = create_prefix(prefix=\"run_block_\", df=offense_run_blocking_new)\n",
    "\n",
    "\n",
    "pass_rush_summary_new = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary_new)\n",
    "run_defense_summary_new = create_prefix(prefix=\"run_defense_\", df=run_defense_summary_new)\n",
    "defense_coverage_scheme_new = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme_new)\n",
    "defense_coverage_summary_new = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary_new)\n",
    "slot_coverage_new= create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>player</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense</th>\n",
       "      <th>def_summary_snap_counts_slot</th>\n",
       "      <th>def_summary_stops</th>\n",
       "      <th>def_summary_tackles</th>\n",
       "      <th>def_summary_targets</th>\n",
       "      <th>def_summary_total_pressures</th>\n",
       "      <th>def_summary_touchdowns</th>\n",
       "      <th>def_summary_yards</th>\n",
       "      <th>def_summary_yards_after_catch</th>\n",
       "      <th>def_summary_yards_per_reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>michaelhoecht_lar_2022_12</td>\n",
       "      <td>michaelhoecht</td>\n",
       "      <td>michaelhoecht_lar_2022</td>\n",
       "      <td>lar_2022_12</td>\n",
       "      <td>lar_2022</td>\n",
       "      <td>108840</td>\n",
       "      <td>di</td>\n",
       "      <td>lar</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>deealford_atl_2022_12</td>\n",
       "      <td>deealford</td>\n",
       "      <td>deealford_atl_2022</td>\n",
       "      <td>atl_2022_12</td>\n",
       "      <td>atl_2022</td>\n",
       "      <td>110542</td>\n",
       "      <td>cb</td>\n",
       "      <td>atl</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>jaylenwatson_kc_2022_12</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022_12</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>samwebb_lv_2022_12</td>\n",
       "      <td>samwebb</td>\n",
       "      <td>samwebb_lv_2022</td>\n",
       "      <td>lv_2022_12</td>\n",
       "      <td>lv_2022</td>\n",
       "      <td>134606</td>\n",
       "      <td>cb</td>\n",
       "      <td>lv</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>joshuawilliams_kc_2022_12</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022_12</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p_id          player          player_team_id  \\\n",
       "645  michaelhoecht_lar_2022_12   michaelhoecht  michaelhoecht_lar_2022   \n",
       "646      deealford_atl_2022_12       deealford      deealford_atl_2022   \n",
       "647    jaylenwatson_kc_2022_12    jaylenwatson    jaylenwatson_kc_2022   \n",
       "648         samwebb_lv_2022_12         samwebb         samwebb_lv_2022   \n",
       "649  joshuawilliams_kc_2022_12  joshuawilliams  joshuawilliams_kc_2022   \n",
       "\n",
       "    unique_team_id team_id_impute  numeric_id position team_name  year week  \\\n",
       "645    lar_2022_12       lar_2022      108840       di       lar  2022   12   \n",
       "646    atl_2022_12       atl_2022      110542       cb       atl  2022   12   \n",
       "647     kc_2022_12        kc_2022      131960       cb        kc  2022   12   \n",
       "648     lv_2022_12        lv_2022      134606       cb        lv  2022   12   \n",
       "649     kc_2022_12        kc_2022      156083       cb        kc  2022   12   \n",
       "\n",
       "     ...  def_summary_snap_counts_run_defense  def_summary_snap_counts_slot  \\\n",
       "645  ...                                    0                             0   \n",
       "646  ...                                    0                             0   \n",
       "647  ...                                    0                             0   \n",
       "648  ...                                    0                             0   \n",
       "649  ...                                    0                             0   \n",
       "\n",
       "     def_summary_stops  def_summary_tackles  def_summary_targets  \\\n",
       "645                  0                    0                    0   \n",
       "646                  0                    0                    0   \n",
       "647                  0                    0                    0   \n",
       "648                  0                    0                    0   \n",
       "649                  0                    0                    0   \n",
       "\n",
       "     def_summary_total_pressures  def_summary_touchdowns  def_summary_yards  \\\n",
       "645                            0                       0                  0   \n",
       "646                            0                       0                  0   \n",
       "647                            0                       0                  0   \n",
       "648                            0                       0                  0   \n",
       "649                            0                       0                  0   \n",
       "\n",
       "     def_summary_yards_after_catch  def_summary_yards_per_reception  \n",
       "645                              0                                0  \n",
       "646                              0                                0  \n",
       "647                              0                                0  \n",
       "648                              0                                0  \n",
       "649                              0                                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring the historic and new player pool data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0)\n",
    "\n",
    "\n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0)\n",
    "\n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0)\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0)\n",
    "\n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0)\n",
    "\n",
    "\n",
    "### after the concat cell ###\n",
    "passing_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_allowed_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "time_in_pocket.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "\n",
    "rec_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "rush_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "block_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_pass_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_run_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "def_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "pass_rush_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "run_defense_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "slot_coverage.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "st_kickers.drop_duplicates(subset='p_id', inplace=True)\n",
    "st_punters.drop_duplicates(subset='p_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj=pd.read_csv('./misc_files/pfr_injury.csv')\n",
    "\n",
    "rec = rec_summ_conc\n",
    "rec=rec[['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','rec_summary_grades_offense', 'rec_summary_pass_plays']]\n",
    "rec.columns= ['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pff_grade', 'plays']\n",
    "\n",
    "rush = rush_summ_conc\n",
    "rush=rush[['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','rush_summary_grades_offense', 'rush_summary_run_plays']]\n",
    "rush.columns= ['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pff_grade', 'plays']\n",
    "\n",
    "blk = block_summ_conc\n",
    "blk=blk[['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','block_summary_grades_offense', 'block_summary_snap_counts_block']]\n",
    "blk.columns= ['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pff_grade', 'plays']\n",
    "\n",
    "defns = def_summ_conc\n",
    "defns=defns[['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','def_summary_grades_defense', 'def_summary_snap_counts_defense']]\n",
    "defns.columns= ['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pff_grade', 'plays']\n",
    "\n",
    "passing = passing_summ_conc\n",
    "passing=passing[['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pass_summary_grades_offense', 'pass_summary_passing_snaps']]\n",
    "passing.columns= ['p_id','player_team_id','numeric_id', 'position', 'team_name', 'year', 'week','pff_grade', 'plays']\n",
    "\n",
    "comb = pd.concat([rec,rush,blk,defns,passing], axis=0)\n",
    "comb = comb.sort_values(by=[\"player_team_id\",\"team_name\",\"year\",\"week\",\"plays\"], ascending=[True, True, True, True,True])\n",
    "comb_grp=comb.groupby('p_id').agg({'pff_grade':'mean', 'plays':'sum'}).reset_index(drop=False)\n",
    "comb.drop(['pff_grade','plays'], axis=1, inplace=True)\n",
    "comb = pd.merge(comb_grp, comb, on='p_id', how='left')\n",
    "\n",
    "pos_dict={\n",
    "'di':'dl',\n",
    "'ed':'dl',\n",
    "'cb':'db',\n",
    "'s':'db',\n",
    "'t':'ol',\n",
    "'g':'ol',\n",
    "'fb':'hb'}\n",
    "\n",
    "comb['position'] = comb['position'].map(pos_dict).fillna(comb['position'])\n",
    "\n",
    "comb=comb.groupby(['player_team_id','position']).agg({'pff_grade':'mean', 'plays':'mean'}).reset_index(drop=False)\n",
    "\n",
    "comb=comb[['player_team_id','position','pff_grade','plays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>value</th>\n",
       "      <th>player_name</th>\n",
       "      <th>match_name</th>\n",
       "      <th>score</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>position</th>\n",
       "      <th>pff_grade</th>\n",
       "      <th>plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tyrannmathieu_ari_2014_1</td>\n",
       "      <td>tyrannmathieu_ari_2014</td>\n",
       "      <td>1</td>\n",
       "      <td>tyrannmathieu_ari_2014</td>\n",
       "      <td>tyrannmathieu_ari_2014</td>\n",
       "      <td>100.0</td>\n",
       "      <td>tyrannmathieu_ari_2014</td>\n",
       "      <td>db</td>\n",
       "      <td>62.730769</td>\n",
       "      <td>32.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexokafor_ari_2014_1</td>\n",
       "      <td>alexokafor_ari_2014</td>\n",
       "      <td>1</td>\n",
       "      <td>alexokafor_ari_2014</td>\n",
       "      <td>alexokafor_ari_2014</td>\n",
       "      <td>100.0</td>\n",
       "      <td>alexokafor_ari_2014</td>\n",
       "      <td>dl</td>\n",
       "      <td>57.807692</td>\n",
       "      <td>53.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mikeiupati_ari_2015_1</td>\n",
       "      <td>mikeiupati_ari_2015</td>\n",
       "      <td>1</td>\n",
       "      <td>mikeiupati_ari_2015</td>\n",
       "      <td>mikeiupati_ari_2015</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mikeiupati_ari_2015</td>\n",
       "      <td>ol</td>\n",
       "      <td>70.600000</td>\n",
       "      <td>62.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kareemmartin_ari_2016_1</td>\n",
       "      <td>kareemmartin_ari_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>kareemmartin_ari_2016</td>\n",
       "      <td>kareemmartin_ari_2016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>kareemmartin_ari_2016</td>\n",
       "      <td>dl</td>\n",
       "      <td>60.628571</td>\n",
       "      <td>4.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>siomoore_ari_2016_1</td>\n",
       "      <td>siomoore_ari_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>siomoore_ari_2016</td>\n",
       "      <td>siomoore_ari_2016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>siomoore_ari_2016</td>\n",
       "      <td>lb</td>\n",
       "      <td>70.300000</td>\n",
       "      <td>60.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  unique_id               player_id  value  \\\n",
       "0  tyrannmathieu_ari_2014_1  tyrannmathieu_ari_2014      1   \n",
       "1     alexokafor_ari_2014_1     alexokafor_ari_2014      1   \n",
       "2     mikeiupati_ari_2015_1     mikeiupati_ari_2015      1   \n",
       "3   kareemmartin_ari_2016_1   kareemmartin_ari_2016      1   \n",
       "4       siomoore_ari_2016_1       siomoore_ari_2016      1   \n",
       "\n",
       "              player_name              match_name  score  \\\n",
       "0  tyrannmathieu_ari_2014  tyrannmathieu_ari_2014  100.0   \n",
       "1     alexokafor_ari_2014     alexokafor_ari_2014  100.0   \n",
       "2     mikeiupati_ari_2015     mikeiupati_ari_2015  100.0   \n",
       "3   kareemmartin_ari_2016   kareemmartin_ari_2016  100.0   \n",
       "4       siomoore_ari_2016       siomoore_ari_2016  100.0   \n",
       "\n",
       "           player_team_id position  pff_grade      plays  \n",
       "0  tyrannmathieu_ari_2014       db  62.730769  32.923077  \n",
       "1     alexokafor_ari_2014       dl  57.807692  53.923077  \n",
       "2     mikeiupati_ari_2015       ol  70.600000  62.692308  \n",
       "3   kareemmartin_ari_2016       dl  60.628571   4.714286  \n",
       "4       siomoore_ari_2016       lb  70.300000  60.500000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj = pd.merge(inj, comb, left_on='player_id', right_on='player_team_id', how='left')\n",
    "inj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp=[]\n",
    "\n",
    "for i in inj['unique_id']:\n",
    "    t = i.split('_', 1)[1]\n",
    "    tmp.append(t)\n",
    "new = pd.DataFrame(tmp, columns=['team_id'])\n",
    "inj.reset_index(drop=True, inplace=True)\n",
    "inj = pd.concat([new, inj], axis=1)\n",
    "\n",
    "inj = inj.loc[inj['position'].notnull()]\n",
    "g = inj.groupby(['team_id','position']).mean().reset_index(drop=False)\n",
    "d = {'score':'inj_count', 'pff_grade':'inj_grade','plays':'inj_plays'}\n",
    "g=inj.groupby(['team_id','position']).agg({'score':'count', 'pff_grade':'mean','plays':'mean'}).rename(columns=d).reset_index(drop=False)\n",
    "\n",
    "inj_final = g.pivot_table(['inj_count', 'inj_plays','inj_grade'], ['team_id'], 'position')\n",
    "\n",
    "inj_final.columns = ['_'.join(col) for col in inj_final.columns]\n",
    "inj_final=inj_final.fillna(0).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>inj_count_db</th>\n",
       "      <th>inj_count_dl</th>\n",
       "      <th>inj_count_hb</th>\n",
       "      <th>inj_count_lb</th>\n",
       "      <th>inj_count_ol</th>\n",
       "      <th>inj_count_qb</th>\n",
       "      <th>inj_count_te</th>\n",
       "      <th>inj_count_wr</th>\n",
       "      <th>inj_grade_db</th>\n",
       "      <th>...</th>\n",
       "      <th>inj_grade_te</th>\n",
       "      <th>inj_grade_wr</th>\n",
       "      <th>inj_plays_db</th>\n",
       "      <th>inj_plays_dl</th>\n",
       "      <th>inj_plays_hb</th>\n",
       "      <th>inj_plays_lb</th>\n",
       "      <th>inj_plays_ol</th>\n",
       "      <th>inj_plays_qb</th>\n",
       "      <th>inj_plays_te</th>\n",
       "      <th>inj_plays_wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>phi_2022_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>ten_2022_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>gb_2022_7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>min_2022_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>atl_2022_12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id  inj_count_db  inj_count_dl  inj_count_hb  inj_count_lb  \\\n",
       "4817     phi_2022_3           0.0           0.0           0.0           0.0   \n",
       "4818     ten_2022_5           0.0           0.0           0.0           0.0   \n",
       "4819      gb_2022_7           0.0           0.0           0.0           0.0   \n",
       "4820     min_2022_9           0.0           0.0           0.0           0.0   \n",
       "4821    atl_2022_12           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      inj_count_ol  inj_count_qb  inj_count_te  inj_count_wr  inj_grade_db  \\\n",
       "4817           0.0           0.0           0.0           0.0           0.0   \n",
       "4818           0.0           0.0           0.0           0.0           0.0   \n",
       "4819           0.0           0.0           0.0           0.0           0.0   \n",
       "4820           0.0           0.0           0.0           0.0           0.0   \n",
       "4821           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      ...  inj_grade_te  inj_grade_wr  inj_plays_db  inj_plays_dl  \\\n",
       "4817  ...           0.0           0.0           0.0           0.0   \n",
       "4818  ...           0.0           0.0           0.0           0.0   \n",
       "4819  ...           0.0           0.0           0.0           0.0   \n",
       "4820  ...           0.0           0.0           0.0           0.0   \n",
       "4821  ...           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      inj_plays_hb  inj_plays_lb  inj_plays_ol  inj_plays_qb  inj_plays_te  \\\n",
       "4817           0.0           0.0           0.0           0.0           0.0   \n",
       "4818           0.0           0.0           0.0           0.0           0.0   \n",
       "4819           0.0           0.0           0.0           0.0           0.0   \n",
       "4820           0.0           0.0           0.0           0.0           0.0   \n",
       "4821           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      inj_plays_wr  \n",
       "4817           0.0  \n",
       "4818           0.0  \n",
       "4819           0.0  \n",
       "4820           0.0  \n",
       "4821           0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_final=inj_final.rename(columns={\"team_id\": \"unique_team_id\"})\n",
    "spread_id = spread_comb[['team_id']]\n",
    "spread_id.columns = ['unique_team_id']\n",
    "inj_final = pd.concat([inj_final, spread_id], axis=0)\n",
    "inj_final.drop_duplicates(subset='unique_team_id', keep=\"first\")\n",
    "inj_final=inj_final.fillna(0)\n",
    "inj_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>inj_count_db</th>\n",
       "      <th>inj_count_dl</th>\n",
       "      <th>inj_count_hb</th>\n",
       "      <th>inj_count_lb</th>\n",
       "      <th>inj_count_ol</th>\n",
       "      <th>inj_count_qb</th>\n",
       "      <th>inj_count_te</th>\n",
       "      <th>inj_count_wr</th>\n",
       "      <th>inj_grade_db</th>\n",
       "      <th>...</th>\n",
       "      <th>inj_grade_te</th>\n",
       "      <th>inj_grade_wr</th>\n",
       "      <th>inj_plays_db</th>\n",
       "      <th>inj_plays_dl</th>\n",
       "      <th>inj_plays_hb</th>\n",
       "      <th>inj_plays_lb</th>\n",
       "      <th>inj_plays_ol</th>\n",
       "      <th>inj_plays_qb</th>\n",
       "      <th>inj_plays_te</th>\n",
       "      <th>inj_plays_wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.730769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.923077</td>\n",
       "      <td>53.923077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>17.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.133333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.2324</td>\n",
       "      <td>68.264286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.133333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.3</td>\n",
       "      <td>29.672682</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.2324</td>\n",
       "      <td>68.264286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.133333</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.3</td>\n",
       "      <td>29.672682</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  inj_count_db  inj_count_dl  inj_count_hb  inj_count_lb  \\\n",
       "0     ari_2014_1           1.0           1.0           0.0           0.0   \n",
       "1    ari_2014_10           0.0           2.0           2.0           0.0   \n",
       "2    ari_2014_11           0.0           3.0           1.0           0.0   \n",
       "3    ari_2014_12           0.0           3.0           1.0           0.0   \n",
       "4    ari_2014_13           0.0           3.0           1.0           0.0   \n",
       "\n",
       "   inj_count_ol  inj_count_qb  inj_count_te  inj_count_wr  inj_grade_db  ...  \\\n",
       "0           0.0           0.0           0.0           0.0     62.730769  ...   \n",
       "1           0.0           0.0           0.0           0.0      0.000000  ...   \n",
       "2           0.0           1.0           0.0           0.0      0.000000  ...   \n",
       "3           0.0           1.0           1.0           1.0      0.000000  ...   \n",
       "4           0.0           1.0           1.0           1.0      0.000000  ...   \n",
       "\n",
       "   inj_grade_te  inj_grade_wr  inj_plays_db  inj_plays_dl  inj_plays_hb  \\\n",
       "0        0.0000      0.000000     32.923077     53.923077      0.000000   \n",
       "1        0.0000      0.000000      0.000000     39.500000     17.736842   \n",
       "2        0.0000      0.000000      0.000000     33.133333     20.000000   \n",
       "3       61.2324     68.264286      0.000000     33.133333     20.000000   \n",
       "4       61.2324     68.264286      0.000000     33.133333     20.000000   \n",
       "\n",
       "   inj_plays_lb  inj_plays_ol  inj_plays_qb  inj_plays_te  inj_plays_wr  \n",
       "0           0.0           0.0           0.0      0.000000           0.0  \n",
       "1           0.0           0.0           0.0      0.000000           0.0  \n",
       "2           0.0           0.0          61.3      0.000000           0.0  \n",
       "3           0.0           0.0          61.3     29.672682          39.5  \n",
       "4           0.0           0.0          61.3     29.672682          39.5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rolling function and pass pff datasets through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 13s, sys: 699 ms, total: 9min 13s\n",
      "Wall time: 9min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def rolling(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"player\",\"team_name\",\"year\",\"week\"], ascending=[True, True, True, True])\n",
    "    data['week']=data['week'].apply(str)\n",
    "    data['year']=data['year'].apply(str)\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        #roll5 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        #roll4 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll3 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "   \n",
    "passing_depth_roll = rolling(data=passing_depth, roll_value=3, roll_type='mean')\n",
    "passing_allowed_pressure_roll = rolling(data=passing_allowed_pressure, roll_value=3, roll_type='mean')\n",
    "passing_pressure_roll = rolling(data=passing_pressure, roll_value=3, roll_type='mean')\n",
    "passing_concept_roll = rolling(data=passing_concept, roll_value=3, roll_type='mean')\n",
    "time_in_pocket_roll = rolling(data=time_in_pocket, roll_value=3, roll_type='mean')\n",
    "passing_summ_conc_roll = rolling(data=passing_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "\n",
    "rec_summ_conc_roll = rolling(data=rec_summ_conc, roll_value=3, roll_type='mean')\n",
    "receiving_concept_roll =rolling(data=receiving_concept, roll_value=3, roll_type='mean')\n",
    "receiving_depth_roll = rolling(data=receiving_depth, roll_value=3, roll_type='mean')\n",
    "receiving_scheme_roll = rolling(data=receiving_scheme, roll_value=3, roll_type='mean')\n",
    "\n",
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "block_summ_conc_roll = rolling(data=block_summ_conc, roll_value=3, roll_type='mean')\n",
    "offense_pass_blocking_roll = rolling(data=offense_pass_blocking, roll_value=3, roll_type='mean')\n",
    "offense_run_blocking_roll = rolling(data=offense_run_blocking, roll_value=3, roll_type='mean')\n",
    "\n",
    "def_summ_conc_roll = rolling(data=def_summ_conc, roll_value=3, roll_type='mean')\n",
    "pass_rush_summary_roll = rolling(data=pass_rush_summary, roll_value=3, roll_type='mean')\n",
    "run_defense_summary_roll = rolling(data=run_defense_summary, roll_value=3, roll_type='mean')\n",
    "defense_coverage_scheme_roll = rolling(data=defense_coverage_scheme, roll_value=3, roll_type='mean')\n",
    "defense_coverage_summary_roll = rolling(data=defense_coverage_summary, roll_value=3, roll_type='mean')\n",
    "slot_coverage_roll = rolling(data=slot_coverage, roll_value=3, roll_type='mean')\n",
    "\n",
    "st_kickers_roll = rolling(data=st_kickers, roll_value=3, roll_type='mean')\n",
    "st_punters_roll = rolling(data=st_punters, roll_value=3, roll_type='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Create better imputation function before weighting team_position_group functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter_fillna(df=None, position=None, min_Var=None):\n",
    "    sub= df[df['position'].str.match(position)]\n",
    "    sub_limit = sub[(sub[min_Var] <=5) & (sub[min_Var] >=1)]\n",
    "    buckup_df = pd.DataFrame(sub_limit.median()).T\n",
    "    num_cols = sub.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    msk = sub.isnull()\n",
    "    tmp = sub[num_cols].mask(msk, buckup_df[num_cols])\n",
    "    tmp = np.where(msk[num_cols], buckup_df[num_cols], tmp[num_cols])\n",
    "    tmp = pd.DataFrame(tmp, columns=buckup_df.columns)\n",
    "    ids = pd.DataFrame(sub.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "    mrg = pd.concat([ids, tmp], axis=1)\n",
    "    return mrg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.1 s, sys: 156 ms, total: 56.2 s\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.median()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth_roll = impute(passing_depth_roll)\n",
    "passing_allowed_pressure_roll = impute(passing_allowed_pressure_roll)\n",
    "passing_pressure_roll = impute(passing_pressure_roll)\n",
    "passing_concept_roll = impute(passing_concept_roll)\n",
    "time_in_pocket_roll = impute(time_in_pocket_roll)\n",
    "passing_summ_conc_roll = impute(passing_summ_conc_roll)\n",
    "\n",
    "rec_summ_conc_roll = impute(rec_summ_conc_roll)\n",
    "receiving_concept_roll = impute(receiving_concept_roll)\n",
    "receiving_depth_roll = impute(receiving_depth_roll)\n",
    "receiving_scheme_roll = impute(receiving_scheme_roll)\n",
    "\n",
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)\n",
    "\n",
    "block_summ_conc_roll = impute(block_summ_conc_roll)\n",
    "offense_pass_blocking_roll = impute(offense_pass_blocking_roll)\n",
    "offense_run_blocking_roll = impute(offense_run_blocking_roll)\n",
    "\n",
    "def_summ_conc_roll = impute(def_summ_conc_roll)\n",
    "pass_rush_summary_roll = impute(pass_rush_summary_roll)\n",
    "run_defense_summary_roll = impute(run_defense_summary_roll)\n",
    "defense_coverage_scheme_roll = impute(defense_coverage_scheme_roll)\n",
    "defense_coverage_summary_roll = impute(defense_coverage_summary_roll)\n",
    "slot_coverage_roll = impute(slot_coverage_roll)\n",
    "\n",
    "st_kickers_roll = impute(st_kickers_roll)\n",
    "st_punters_roll = impute(st_punters_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "biometrics = pd.read_csv('./other_data/2022_imputed_combine.csv')\n",
    "biometrics=biometrics[['player_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "biometrics['position']=biometrics['position'].apply(str)\n",
    "\n",
    "\n",
    "qb_bio = biometrics[biometrics['position'].isin(['qb'])]\n",
    "rb_bio = biometrics[biometrics['position'].isin(['hb','qb','fb','wr'])]\n",
    "rec_bio = biometrics[biometrics['position'].isin(['wr','te','hb'])]\n",
    "ol_bio = biometrics[biometrics['position'].isin(['ol','te'])]\n",
    "def_bio_dl = biometrics[biometrics['position'].isin(['dl'])]\n",
    "def_bio_db = biometrics[biometrics['position'].isin(['db'])]\n",
    "def_bio_lb = biometrics[biometrics['position'].isin(['lb'])]\n",
    "st_bio = biometrics[biometrics['position'].isin(['st'])]\n",
    "\n",
    "qb_median = qb_bio.groupby(['position']).median().reset_index()\n",
    "rb_median = rb_bio.groupby(['position']).median().reset_index()\n",
    "rec_median = rec_bio.groupby(['position']).median().reset_index()\n",
    "ol_median = ol_bio.groupby(['position']).median().reset_index()\n",
    "dl_median = def_bio_dl.groupby(['position']).median().reset_index()\n",
    "db_median = def_bio_db.groupby(['position']).median().reset_index()\n",
    "lb_median = def_bio_lb.groupby(['position']).median().reset_index()\n",
    "st_median = st_bio.groupby(['position']).median().reset_index()\n",
    "\n",
    "\n",
    "qb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rec_bio.drop(['position'], axis=1, inplace=True)\n",
    "ol_bio.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_dl.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_db.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_lb.drop(['position'], axis=1, inplace=True)\n",
    "st_bio.drop(['position'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position ##\n",
    "rush_summ_conc_roll['position'] = rush_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "temp_fillna_df = pd.merge(rush_summ_conc_roll, rb_median, on='position', how='left')\n",
    "rush_summ_conc_roll = pd.merge(rush_summ_conc_roll, rb_bio, on='player_team_id', how='left')\n",
    "rush_summ_conc_roll = rush_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- qb ##\n",
    "temp_fillna_df = pd.merge(passing_summ_conc_roll, qb_median, on='position', how='left')\n",
    "passing_summ_conc_roll = pd.merge(passing_summ_conc_roll, qb_bio, on='player_team_id', how='left')\n",
    "passing_summ_conc_roll = passing_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "rec_summ_conc_roll['position'] = rec_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "temp_fillna_df = pd.merge(rec_summ_conc_roll, rec_median, on='position', how='left')\n",
    "rec_summ_conc_roll = pd.merge(rec_summ_conc_roll, rec_bio, on='player_team_id', how='left')\n",
    "rec_summ_conc_roll = rec_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "block_summ_conc_roll=block_summ_conc_roll[block_summ_conc_roll['position'] != 'cb']\n",
    "block_summ_conc_roll['position'] = block_summ_conc_roll['position'].str.replace('t','ol')\n",
    "block_summ_conc_roll['position'] = block_summ_conc_roll['position'].str.replace('g','ol')\n",
    "temp_fillna_df = pd.merge(block_summ_conc_roll , ol_median, on='position', how='left')\n",
    "block_summ_conc_roll = pd.merge(block_summ_conc_roll, ol_bio, on='player_team_id', how='left')\n",
    "block_summ_conc_roll = block_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "\n",
    "def_line = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['ed','di'])]\n",
    "def_line['position'] = def_line['position'].str.replace('ed','dl')\n",
    "def_line['position'] = def_line['position'].str.replace('di','dl')\n",
    "temp_fillna_df = pd.merge(def_line, dl_median , on='position', how='left')\n",
    "def_line = pd.merge(def_line, def_bio_dl, on='player_team_id', how='left')\n",
    "def_line = def_line.combine_first(temp_fillna_df)\n",
    "\n",
    "def_line=def_line[['unique_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "def_line = def_line.rename(columns={c: c+'_dls_bio' for c in def_line.columns if c not in ['unique_team_id']})\n",
    "def_line = def_line.groupby('unique_team_id').mean().reset_index(drop=False)\n",
    "\n",
    "def_lbs = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb'])]\n",
    "temp_fillna_df = pd.merge(def_lbs, lb_median , on='position', how='left')\n",
    "def_lbs = pd.merge(def_lbs, def_bio_lb, on='player_team_id', how='left')\n",
    "def_lbs = def_lbs.combine_first(temp_fillna_df)\n",
    "def_lbs=def_lbs[['unique_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "def_lbs = def_lbs.rename(columns={c: c+'_lbs_bio' for c in def_lbs.columns if c not in ['unique_team_id']})\n",
    "def_lbs = def_lbs.groupby('unique_team_id').mean().reset_index(drop=False)\n",
    "\n",
    "def_db = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['cb','s'])]\n",
    "def_db['position'] = def_db['position'].str.replace('cb','db')\n",
    "def_db['position'] = def_db['position'].str.replace('s','db')\n",
    "temp_fillna_df = pd.merge(def_db, lb_median , on='position', how='left')\n",
    "def_db = pd.merge(def_db, def_bio_db, on='player_team_id', how='left')\n",
    "def_db = def_db.combine_first(temp_fillna_df)\n",
    "def_db=def_db[['unique_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "def_db = def_db.rename(columns={c: c+'_dbs_bio' for c in def_db.columns if c not in ['player_team_id','unique_team_id']})\n",
    "def_db = def_db.groupby('unique_team_id').mean().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine players for each dataset into team_year_week groupings\n",
    "\n",
    "### These next few cells will compute weighted averages based on average snaps played.  The first function will default snaps to 1 if snap value is 0.  The rest of the functions are dataset specific and will compute the weighted averages based on rollup aaverages and snaps played.\n",
    "\n",
    "#### For example: Washington had 5 rbs player in the last 3 games.  It doesn't make sense to weight all the players stats into a single average if 3 of those backs only averaged 2 snaps and rushed for 2 yards whereas B. Robinson averages 18 snaps and rushes for 65 yards and Gibson averages 10 snaps for 40 yards.  Therefore we weight each players rolling average based on their rolling snaps played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rushing weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rush_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rush_summ_conc_roll['rush_summary_attempts'] = rush_summ_conc_roll.apply(lambda df: rush_att(df, var='rush_summary_attempts'), axis=1)   \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rush_summary_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "\n",
    "rb_stats = rush_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "rb_stats.tail(n=10)\n",
    "rb_stats = rb_stats.rename(columns={c: c+'_rush' for c in rb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_id', 'player_team_id', 'unique_team_id', 'team_id_impute', 'player',\n",
       "       'position', 'team_name', 'year', 'week', 'numeric_id',\n",
       "       'pass_concept_player_game_count', 'pass_concept_comp_pct_diff',\n",
       "       'pass_concept_declined_penalties', 'pass_concept_dropbacks',\n",
       "       'pass_concept_franchise_id', 'pass_concept_no_screen_accuracy_percent',\n",
       "       'pass_concept_no_screen_aimed_passes',\n",
       "       'pass_concept_no_screen_attempts',\n",
       "       'pass_concept_no_screen_avg_depth_of_target',\n",
       "       'pass_concept_no_screen_avg_time_to_throw',\n",
       "       'pass_concept_no_screen_bats', 'pass_concept_no_screen_big_time_throws',\n",
       "       'pass_concept_no_screen_btt_rate',\n",
       "       'pass_concept_no_screen_completion_percent',\n",
       "       'pass_concept_no_screen_completions',\n",
       "       'pass_concept_no_screen_def_gen_pressures',\n",
       "       'pass_concept_no_screen_drop_rate', 'pass_concept_no_screen_dropbacks',\n",
       "       'pass_concept_no_screen_dropbacks_percent',\n",
       "       'pass_concept_no_screen_drops', 'pass_concept_no_screen_first_downs',\n",
       "       'pass_concept_no_screen_grades_coverage_defense',\n",
       "       'pass_concept_no_screen_grades_defense',\n",
       "       'pass_concept_no_screen_grades_defense_penalty',\n",
       "       'pass_concept_no_screen_grades_hands_drop',\n",
       "       'pass_concept_no_screen_grades_hands_fumble',\n",
       "       'pass_concept_no_screen_grades_offense',\n",
       "       'pass_concept_no_screen_grades_offense_penalty',\n",
       "       'pass_concept_no_screen_grades_pass',\n",
       "       'pass_concept_no_screen_grades_pass_route',\n",
       "       'pass_concept_no_screen_grades_run',\n",
       "       'pass_concept_no_screen_grades_run_defense',\n",
       "       'pass_concept_no_screen_hit_as_threw',\n",
       "       'pass_concept_no_screen_interceptions',\n",
       "       'pass_concept_no_screen_passing_snaps',\n",
       "       'pass_concept_no_screen_pressure_to_sack_rate',\n",
       "       'pass_concept_no_screen_qb_rating',\n",
       "       'pass_concept_no_screen_sack_percent', 'pass_concept_no_screen_sacks',\n",
       "       'pass_concept_no_screen_scrambles'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_concept_roll.columns[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Passing weight average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def pass_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "passing_summ_conc_roll['pass_summary_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_summary_dropbacks'), axis=1)\n",
    "passing_depth_roll['pass_depth_base_dropbacks'] = passing_depth_roll.apply(lambda df: pass_att(df, var='pass_depth_base_dropbacks'), axis=1)  \n",
    "passing_pressure_roll['pass_under_pressure_base_dropbacks'] = passing_pressure_roll.apply(lambda df: pass_att(df, var='pass_under_pressure_base_dropbacks'), axis=1)  \n",
    "passing_allowed_pressure_roll['pressure_source_allowed_pressure_dropbacks'] = passing_allowed_pressure_roll.apply(lambda df: pass_att(df, var='pressure_source_allowed_pressure_dropbacks'), axis=1)  \n",
    "passing_concept_roll['pass_concept_dropbacks'] = passing_concept_roll.apply(lambda df: pass_att(df, var='pass_concept_dropbacks'), axis=1)  \n",
    "time_in_pocket_roll['pass_time_dropbacks'] = time_in_pocket_roll.apply(lambda df: pass_att(df, var='pass_time_dropbacks'), axis=1)     \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_summary_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "qb_stats = passing_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_depth_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_depth_stats = passing_depth_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "pass_depth_stats = pass_depth_stats.rename(columns={c: c+'_passdepth' for c in pass_depth_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pressure_source_allowed_pressure_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_allowed_pressure_stats = passing_allowed_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "passing_allowed_pressure_stats = passing_allowed_pressure_stats.rename(columns={c: c+'_pass_allow_pressure' for c in passing_allowed_pressure_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='pass_under_pressure_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_pressure_stats = passing_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "passing_pressure_stats = passing_pressure_stats.rename(columns={c: c+'_pass_pressure' for c in passing_pressure_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_concept_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_concept_stats = passing_concept_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "passing_concept_stats = passing_concept_stats.rename(columns={c: c+'_pass_conc' for c in passing_concept_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_time_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "time_in_pocket_stats = time_in_pocket_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "time_in_pocket_stats = time_in_pocket_stats.rename(columns={c: c+'_time_pocket' for c in time_in_pocket_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "qb_stats = qb_stats.rename(columns={c: c+'_passing' for c in qb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_passing</th>\n",
       "      <th>pass_summary_accuracy_percent_passing</th>\n",
       "      <th>pass_summary_aimed_passes_passing</th>\n",
       "      <th>pass_summary_attempts_passing</th>\n",
       "      <th>pass_summary_avg_depth_of_target_passing</th>\n",
       "      <th>pass_summary_avg_time_to_throw_passing</th>\n",
       "      <th>pass_summary_bats_passing</th>\n",
       "      <th>pass_summary_big_time_throws_passing</th>\n",
       "      <th>pass_summary_btt_rate_passing</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_passing</th>\n",
       "      <th>vertical_passing</th>\n",
       "      <th>broad_jump_passing</th>\n",
       "      <th>shuttle_passing</th>\n",
       "      <th>3cone_passing</th>\n",
       "      <th>explosive_passing</th>\n",
       "      <th>size_speed_passing</th>\n",
       "      <th>draft_yr_passing</th>\n",
       "      <th>round_passing</th>\n",
       "      <th>selection_passing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>7102.000000</td>\n",
       "      <td>74.766667</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>33.215461</td>\n",
       "      <td>122.827482</td>\n",
       "      <td>4.168103</td>\n",
       "      <td>6.896206</td>\n",
       "      <td>22.696851</td>\n",
       "      <td>0.266665</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>2402.317073</td>\n",
       "      <td>69.817886</td>\n",
       "      <td>29.861789</td>\n",
       "      <td>32.731707</td>\n",
       "      <td>10.781301</td>\n",
       "      <td>2.512520</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>2.227642</td>\n",
       "      <td>5.682927</td>\n",
       "      <td>...</td>\n",
       "      <td>23.536585</td>\n",
       "      <td>31.957077</td>\n",
       "      <td>115.956210</td>\n",
       "      <td>4.280201</td>\n",
       "      <td>6.837720</td>\n",
       "      <td>21.078042</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>2004.853659</td>\n",
       "      <td>1.463415</td>\n",
       "      <td>20.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>65.733333</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>15.266667</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>67.866667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>72.566667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>2.696667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_passing  pass_summary_accuracy_percent_passing  \\\n",
       "0     ari_2014_1         7102.000000                              74.766667   \n",
       "1    ari_2014_10         2402.317073                              69.817886   \n",
       "2    ari_2014_11         3659.000000                              65.733333   \n",
       "3    ari_2014_12         3659.000000                              67.866667   \n",
       "4    ari_2014_13         3659.000000                              72.566667   \n",
       "\n",
       "   pass_summary_aimed_passes_passing  pass_summary_attempts_passing  \\\n",
       "0                          30.666667                      33.000000   \n",
       "1                          29.861789                      32.731707   \n",
       "2                          19.333333                      21.333333   \n",
       "3                          19.333333                      21.000000   \n",
       "4                          19.666667                      21.000000   \n",
       "\n",
       "   pass_summary_avg_depth_of_target_passing  \\\n",
       "0                                  8.500000   \n",
       "1                                 10.781301   \n",
       "2                                 15.266667   \n",
       "3                                 13.466667   \n",
       "4                                 13.466667   \n",
       "\n",
       "   pass_summary_avg_time_to_throw_passing  pass_summary_bats_passing  \\\n",
       "0                                2.660000                   0.333333   \n",
       "1                                2.512520                   0.821138   \n",
       "2                                2.570000                   0.666667   \n",
       "3                                2.520000                   0.333333   \n",
       "4                                2.696667                   0.666667   \n",
       "\n",
       "   pass_summary_big_time_throws_passing  pass_summary_btt_rate_passing  ...  \\\n",
       "0                              1.333333                       3.800000  ...   \n",
       "1                              2.227642                       5.682927  ...   \n",
       "2                              1.333333                       9.433333  ...   \n",
       "3                              0.333333                       6.666667  ...   \n",
       "4                              0.333333                       6.666667  ...   \n",
       "\n",
       "   bench_passing  vertical_passing  broad_jump_passing  shuttle_passing  \\\n",
       "0      23.999999         33.215461          122.827482         4.168103   \n",
       "1      23.536585         31.957077          115.956210         4.280201   \n",
       "2      23.000000         30.500000          108.000000         4.410000   \n",
       "3      23.000000         30.500000          108.000000         4.410000   \n",
       "4      23.000000         30.500000          108.000000         4.410000   \n",
       "\n",
       "   3cone_passing  explosive_passing  size_speed_passing  draft_yr_passing  \\\n",
       "0       6.896206          22.696851            0.266665       2003.000000   \n",
       "1       6.837720          21.078042            0.282569       2004.853659   \n",
       "2       6.770000          19.203633            0.300984       2007.000000   \n",
       "3       6.770000          19.203633            0.300984       2007.000000   \n",
       "4       6.770000          19.203633            0.300984       2007.000000   \n",
       "\n",
       "   round_passing  selection_passing  \n",
       "0       1.000000           1.000000  \n",
       "1       1.463415          20.463415  \n",
       "2       2.000000          43.000000  \n",
       "3       2.000000          43.000000  \n",
       "4       2.000000          43.000000  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute receiver weighted average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rec_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rec_summ_conc_roll['rec_summary_targets'] = rec_summ_conc_roll.apply(lambda df: rec_att(df, var='rec_summary_targets'), axis=1)   \n",
    "receiving_concept_roll['rec_concept_base_targets'] = receiving_concept_roll.apply(lambda df: rec_att(df, var='rec_concept_base_targets'), axis=1) \n",
    "receiving_depth_roll['rec_depth_base_targets'] = receiving_depth_roll.apply(lambda df: rec_att(df, var='rec_depth_base_targets'), axis=1) \n",
    "receiving_scheme_roll['rec_scheme_base_targets'] = receiving_scheme_roll.apply(lambda df: rec_att(df, var='rec_scheme_base_targets'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_summary_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "rec_stats = rec_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_concept_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_concept = receiving_concept_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "receiving_concept = receiving_concept.rename(columns={c: c+'_rec_concept' for c in receiving_concept.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_depth_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_depth = receiving_depth_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "receiving_depth = receiving_depth.rename(columns={c: c+'_rec_depth' for c in receiving_depth.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_scheme_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_scheme = receiving_scheme_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "receiving_scheme = receiving_scheme.rename(columns={c: c+'_rec_schem' for c in receiving_scheme.columns if c not in ['unique_team_id']})\n",
    "\n",
    "rec_stats = rec_stats.rename(columns={c: c+'_rec' for c in rec_stats.columns if c not in ['unique_team_id']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute OL weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def snap_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "block_summ_conc_roll['block_summary_snap_counts_offense'] = block_summ_conc_roll.apply(lambda df: snap_fix(df, var='block_summary_snap_counts_offense'), axis=1)\n",
    "offense_pass_blocking_roll['pass_block_snap_counts_pass_block'] = offense_pass_blocking_roll.apply(lambda df: snap_fix(df, var='pass_block_snap_counts_pass_block'), axis=1) \n",
    "offense_run_blocking_roll['run_block_snap_counts_run_block'] = offense_run_blocking_roll.apply(lambda df: snap_fix(df, var='run_block_snap_counts_run_block'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='block_summary_snap_counts_offense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "ol_stats = block_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_block_snap_counts_pass_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_pass_blocking_stats = offense_pass_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "offense_pass_blocking_stats = offense_pass_blocking_stats.rename(columns={c: c+'_pass_block' for c in offense_pass_blocking_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='run_block_snap_counts_run_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_run_blocking_stats = offense_run_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "offense_run_blocking_stats = offense_run_blocking_stats.rename(columns={c: c+'_run_block' for c in offense_run_blocking_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "ol_stats = ol_stats.rename(columns={c: c+'_block' for c in ol_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute defensive weighted averages datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_team_id', 'height_clean_dls_bio', 'weight_clean_dls_bio',\n",
       "       'speed_clean_dls_bio', 'hand_size_dls_bio', 'arm_length_dls_bio',\n",
       "       'bench_dls_bio', 'vertical_dls_bio', 'broad_jump_dls_bio',\n",
       "       'shuttle_dls_bio', '3cone_dls_bio', 'explosive_dls_bio',\n",
       "       'size_speed_dls_bio', 'draft_yr_dls_bio', 'round_dls_bio',\n",
       "       'selection_dls_bio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_line.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_def_stats</th>\n",
       "      <th>def_summary_assists_def_stats</th>\n",
       "      <th>def_summary_batted_passes_def_stats</th>\n",
       "      <th>def_summary_catch_rate_def_stats</th>\n",
       "      <th>def_summary_declined_penalties_def_stats</th>\n",
       "      <th>def_summary_forced_fumbles_def_stats</th>\n",
       "      <th>def_summary_franchise_id_def_stats</th>\n",
       "      <th>def_summary_grades_coverage_defense_def_stats</th>\n",
       "      <th>def_summary_grades_defense_def_stats</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_dbs_bio</th>\n",
       "      <th>vertical_dbs_bio</th>\n",
       "      <th>broad_jump_dbs_bio</th>\n",
       "      <th>shuttle_dbs_bio</th>\n",
       "      <th>3cone_dbs_bio</th>\n",
       "      <th>explosive_dbs_bio</th>\n",
       "      <th>size_speed_dbs_bio</th>\n",
       "      <th>draft_yr_dbs_bio</th>\n",
       "      <th>round_dbs_bio</th>\n",
       "      <th>selection_dbs_bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9332.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.267674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.578057</td>\n",
       "      <td>61.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>16.714286</td>\n",
       "      <td>36.821308</td>\n",
       "      <td>125.685346</td>\n",
       "      <td>4.165714</td>\n",
       "      <td>6.922857</td>\n",
       "      <td>23.413113</td>\n",
       "      <td>0.235813</td>\n",
       "      <td>2010.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>102.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>5453.149401</td>\n",
       "      <td>0.380565</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>73.252612</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.769346</td>\n",
       "      <td>64.293564</td>\n",
       "      <td>...</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>36.468645</td>\n",
       "      <td>124.599678</td>\n",
       "      <td>4.162500</td>\n",
       "      <td>6.916250</td>\n",
       "      <td>23.041625</td>\n",
       "      <td>0.238101</td>\n",
       "      <td>2010.875000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>5259.055969</td>\n",
       "      <td>0.356216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.648521</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.690532</td>\n",
       "      <td>64.336686</td>\n",
       "      <td>...</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>36.035594</td>\n",
       "      <td>123.685346</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>22.847540</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>2010.714286</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>86.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>5391.694209</td>\n",
       "      <td>0.350820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.276986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030531</td>\n",
       "      <td>1.857766</td>\n",
       "      <td>63.716701</td>\n",
       "      <td>66.109632</td>\n",
       "      <td>...</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>36.035594</td>\n",
       "      <td>123.685346</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>22.847540</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>2010.714286</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>86.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>5519.730250</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>72.647001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>1.852601</td>\n",
       "      <td>62.196285</td>\n",
       "      <td>65.107514</td>\n",
       "      <td>...</td>\n",
       "      <td>14.571429</td>\n",
       "      <td>36.035594</td>\n",
       "      <td>123.685346</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>6.934286</td>\n",
       "      <td>22.847540</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>2010.714286</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>86.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_def_stats  def_summary_assists_def_stats  \\\n",
       "0     ari_2014_1           9332.000000                       0.333333   \n",
       "1    ari_2014_10           5453.149401                       0.380565   \n",
       "2    ari_2014_11           5259.055969                       0.356216   \n",
       "3    ari_2014_12           5391.694209                       0.350820   \n",
       "4    ari_2014_13           5519.730250                       0.474310   \n",
       "\n",
       "   def_summary_batted_passes_def_stats  def_summary_catch_rate_def_stats  \\\n",
       "0                             0.000000                         70.267674   \n",
       "1                             0.021261                         73.252612   \n",
       "2                             0.000000                         70.648521   \n",
       "3                             0.000000                         69.276986   \n",
       "4                             0.056840                         72.647001   \n",
       "\n",
       "   def_summary_declined_penalties_def_stats  \\\n",
       "0                                  0.000000   \n",
       "1                                  0.040382   \n",
       "2                                  0.022154   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   def_summary_forced_fumbles_def_stats  def_summary_franchise_id_def_stats  \\\n",
       "0                              0.000000                           16.000000   \n",
       "1                              0.012700                            1.000000   \n",
       "2                              0.019968                            1.000000   \n",
       "3                              0.030531                            1.857766   \n",
       "4                              0.029383                            1.852601   \n",
       "\n",
       "   def_summary_grades_coverage_defense_def_stats  \\\n",
       "0                                      60.578057   \n",
       "1                                      63.769346   \n",
       "2                                      63.690532   \n",
       "3                                      63.716701   \n",
       "4                                      62.196285   \n",
       "\n",
       "   def_summary_grades_defense_def_stats  ...  bench_dbs_bio  vertical_dbs_bio  \\\n",
       "0                             61.833333  ...      16.714286         36.821308   \n",
       "1                             64.293564  ...      15.125000         36.468645   \n",
       "2                             64.336686  ...      14.571429         36.035594   \n",
       "3                             66.109632  ...      14.571429         36.035594   \n",
       "4                             65.107514  ...      14.571429         36.035594   \n",
       "\n",
       "   broad_jump_dbs_bio  shuttle_dbs_bio  3cone_dbs_bio  explosive_dbs_bio  \\\n",
       "0          125.685346         4.165714       6.922857          23.413113   \n",
       "1          124.599678         4.162500       6.916250          23.041625   \n",
       "2          123.685346         4.142857       6.934286          22.847540   \n",
       "3          123.685346         4.142857       6.934286          22.847540   \n",
       "4          123.685346         4.142857       6.934286          22.847540   \n",
       "\n",
       "   size_speed_dbs_bio  draft_yr_dbs_bio  round_dbs_bio  selection_dbs_bio  \n",
       "0            0.235813       2010.571429       3.571429         102.142857  \n",
       "1            0.238101       2010.875000       3.500000          98.000000  \n",
       "2            0.240217       2010.714286       3.142857          86.714286  \n",
       "3            0.240217       2010.714286       3.142857          86.714286  \n",
       "4            0.240217       2010.714286       3.142857          86.714286  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def snap_fixs(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "def_summ_conc_roll['def_summary_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_run_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_run_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_pass_rush'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_pass_rush'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_coverage'), axis=1) \n",
    "\n",
    "\n",
    "pass_rush_summary_roll['pass_rush_snap_counts_pass_play'] = pass_rush_summary_roll.apply(lambda df: snap_fixs(df, var='pass_rush_snap_counts_pass_play'), axis=1)\n",
    "run_defense_summary_roll['run_defense_snap_counts_run'] = run_defense_summary_roll.apply(lambda df: snap_fixs(df, var='run_defense_snap_counts_run'), axis=1)\n",
    "defense_coverage_scheme_roll['def_coverage_scheme_base_snap_counts_coverage'] = defense_coverage_scheme_roll.apply(lambda df: snap_fixs(df, var='def_coverage_scheme_base_snap_counts_coverage'), axis=1)\n",
    "defense_coverage_summary_roll['def_coverage_summary_coverage_snaps_per_target'] = defense_coverage_summary_roll.apply(lambda df: snap_fixs(df, var='def_coverage_summary_coverage_snaps_per_target'), axis=1)\n",
    "slot_coverage_roll['def_slot_coverage_coverage_snaps'] = slot_coverage_roll.apply(lambda df: snap_fixs(df, var='def_slot_coverage_coverage_snaps'), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Subset into defense positional groups ##\n",
    "def_rundef = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['ed','di','lb'])]\n",
    "def_passrush = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','ed','di'])]\n",
    "def_cov = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','cb','s'])]\n",
    "\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('di','dl')\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_rundef , dl_median, on='position', how='left')\n",
    "# def_rundef = pd.merge(def_rundef, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_rundef = def_rundef.combine_first(temp_fillna_df); def_rundef.head()\n",
    "\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('di','dl')\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_passrush , dl_median, on='position', how='left')\n",
    "# def_passrush = pd.merge(def_passrush, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_passrush = def_passrush.combine_first(temp_fillna_df); def_passrush.head()\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_stats = def_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_stats = def_stats.rename(columns={c: c+'_def_stats' for c in def_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_run_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_rundef = def_rundef.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_rundef = def_rundef.rename(columns={c: c+'_run_def' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_pass_rush'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_passrush = def_passrush.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_passrush = def_passrush.rename(columns={c: c+'_passrush' for c in def_passrush.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_cov = def_cov.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_cov = def_cov.rename(columns={c: c+'_def_cov' for c in def_cov.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_rush_snap_counts_pass_play'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_rush_stats = pass_rush_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "pass_rush_stats = pass_rush_stats.rename(columns={c: c+'_pass_rush_summ' for c in pass_rush_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='run_defense_snap_counts_run'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "run_defense_stats = run_defense_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "run_defense_stats = run_defense_stats.rename(columns={c: c+'_run_def_summ' for c in run_defense_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_coverage_summary_coverage_snaps_per_target'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "defense_coverage_summary_stats = defense_coverage_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "defense_coverage_summary_stats = defense_coverage_summary_stats.rename(columns={c: c+'_def_cov_summ' for c in defense_coverage_summary_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_coverage_scheme_base_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "defense_coverage_scheme_stats = defense_coverage_scheme_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "defense_coverage_scheme_stats = defense_coverage_scheme_stats.rename(columns={c: c+'_def_cov_schem' for c in defense_coverage_scheme_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_slot_coverage_coverage_snaps'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "slot_coverage_stats = slot_coverage_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "slot_coverage_stats = slot_coverage_stats.rename(columns={c: c+'_slot_cov' for c in slot_coverage_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "#def_stats = pd.merge(def_stats, def_rundef, on='unique_team_id', how='inner').merge(def_passrush, on='unique_team_id', how='inner').merge(def_cov, on='unique_team_id', how='inner')\n",
    "# def_rundef = def_rundef.rename(columns={c: c+'_rundef' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def_stats = pd.merge(def_stats, def_line, on='unique_team_id', how='left').merge(def_lbs, on='unique_team_id', how='left').merge(def_db, on='unique_team_id', how='left')\n",
    "def_stats.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute special teams weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_bio.columns = [str(col) + '_st' for col in st_bio.columns]\n",
    "# st_kickers_roll = pd.merge(st_kickers_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_kickers_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def kicks_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_kickers_roll['kicks'] = st_kickers_roll['kicking_pat_attempts']+st_kickers_roll['kicking_total_attempts']\n",
    "st_kickers_roll ['kicks'] = st_kickers_roll .apply(lambda df: snap_fixs(df, var='kicks'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='kicks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_kickers = st_kickers_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_punters_roll = pd.merge(st_punters_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_punters_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def punts_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_punters_roll['punting_attempts'] = st_punters_roll.apply(lambda df: snap_fixs(df, var='punting_attempts'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='punting_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_punters = st_punters_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_vars = spread_comb[spread_comb['schedule_week'] != '1']\n",
    "\n",
    "spread_variables = spread_vars[['team_id',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"days_last_played\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "spread_variables.rename(columns={'team_id': 'unique_team_id'}, inplace=True)\n",
    "\n",
    "spread_variables.drop_duplicates(subset='unique_team_id',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread_variables.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling File and write out to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_vars = spread_comb[spread_comb['schedule_week'] != '1']\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id','score_home','score_away']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id','score_home','score_away']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'score_home',\n",
    "'score_away',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result']]\n",
    "\n",
    "\n",
    "\n",
    "dfs_list = [spread_ids,\n",
    "            spread_variables,\n",
    "            inj_final,\n",
    "            tgs_roll,\n",
    "            fo_roll,\n",
    "            qb_stats,\n",
    "            passing_concept_stats,\n",
    "            passing_pressure_stats,\n",
    "            time_in_pocket_stats,\n",
    "            passing_allowed_pressure_stats,\n",
    "            pass_depth_stats,\n",
    "            rb_stats,\n",
    "            rec_stats,\n",
    "            receiving_scheme,\n",
    "            receiving_depth,\n",
    "            receiving_concept,\n",
    "            ol_stats,\n",
    "            offense_run_blocking_stats,\n",
    "            offense_pass_blocking_stats,\n",
    "           def_stats,\n",
    "           def_rundef,\n",
    "           def_cov,\n",
    "           def_passrush,\n",
    "            pass_rush_stats,\n",
    "            run_defense_stats,\n",
    "            defense_coverage_summary_stats,\n",
    "            defense_coverage_scheme_stats,\n",
    "            slot_coverage_stats,\n",
    "           st_punters,\n",
    "           st_kickers]\n",
    "\n",
    "dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'],\n",
    "                                            how='left'), dfs_list)\n",
    "\n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "\n",
    "\n",
    "favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "dfs_team = dfs_team.rename(columns={c: c+'_fav' for c in dfs_team.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','home_score','away_score','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "not_fav_df = not_fav_df.rename(columns={c: c+'_dog' for c in not_fav_df.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "\n",
    "not_fav_df.drop(['unique_team_id','wl','score_away_dog','score_home_dog'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover',\n",
    "             \n",
    "            'over_under_result']]\n",
    "#not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.14 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 43.38 Mb (72.2% reduction)\n",
      "Mem. usage decreased to 21.45 Mb (72.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "favs = reduce_mem_usage(favs)\n",
    "dfs_team = reduce_mem_usage(dfs_team)\n",
    "not_fav_df = reduce_mem_usage(not_fav_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "favs=favs.round(2)\n",
    "favs.drop_duplicates(subset='team_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df=fin_df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge files and write to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>schedule_week</th>\n",
       "      <th>schedule_season</th>\n",
       "      <th>spread_favorite</th>\n",
       "      <th>over_under_line</th>\n",
       "      <th>fav_cover</th>\n",
       "      <th>over_under_result</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>score_home_fav</th>\n",
       "      <th>...</th>\n",
       "      <th>kicking_thirty_attempts_dog</th>\n",
       "      <th>kicking_thirty_made_dog</th>\n",
       "      <th>kicking_thirty_percent_dog</th>\n",
       "      <th>kicking_total_attempts_dog</th>\n",
       "      <th>kicking_total_made_dog</th>\n",
       "      <th>kicking_total_percent_dog</th>\n",
       "      <th>kicking_twenty_attempts_dog</th>\n",
       "      <th>kicking_twenty_made_dog</th>\n",
       "      <th>kicking_twenty_percent_dog</th>\n",
       "      <th>kicks_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14714</th>\n",
       "      <td>no_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>no_2021_9</td>\n",
       "      <td>novsatl_2021_9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>97.1875</td>\n",
       "      <td>2.660156</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>88.8750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16878</th>\n",
       "      <td>pit_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>pit_2021_9</td>\n",
       "      <td>pitvschi_2021_9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>94.3125</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>94.7500</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>2.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17638</th>\n",
       "      <td>sf_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>sf_2021_9</td>\n",
       "      <td>sfvsari_2021_9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.1875</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>94.7500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>ne_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>41.5</td>\n",
       "      <td>cover</td>\n",
       "      <td>under</td>\n",
       "      <td>ne_2021_9</td>\n",
       "      <td>carvsne_2021_9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>3.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>buf_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>48.5</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>buf_2021_9</td>\n",
       "      <td>jaxvsbuf_2021_9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.3750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26564</th>\n",
       "      <td>lv_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>lv_2021_9</td>\n",
       "      <td>nygvslv_2021_9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28022</th>\n",
       "      <td>lac_2021_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>cover</td>\n",
       "      <td>over</td>\n",
       "      <td>lac_2021_9</td>\n",
       "      <td>phivslac_2021_9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.3750</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>98.3750</td>\n",
       "      <td>4.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>ari_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>ari_2022_9</td>\n",
       "      <td>arivssea_2022_9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>98.3750</td>\n",
       "      <td>5.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>cin_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>cover</td>\n",
       "      <td>over</td>\n",
       "      <td>cin_2022_9</td>\n",
       "      <td>cinvscar_2022_9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>77.6875</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.6250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>3.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>kc_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>kc_2022_9</td>\n",
       "      <td>kcvsten_2022_9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>94.3125</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14522</th>\n",
       "      <td>ne_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>cover</td>\n",
       "      <td>under</td>\n",
       "      <td>ne_2022_9</td>\n",
       "      <td>nevsind_2022_9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>94.3125</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>3.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18624</th>\n",
       "      <td>tb_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>push</td>\n",
       "      <td>under</td>\n",
       "      <td>tb_2022_9</td>\n",
       "      <td>tbvslar_2022_9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>lac_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>cover</td>\n",
       "      <td>under</td>\n",
       "      <td>lac_2022_9</td>\n",
       "      <td>atlvslac_2022_9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>94.3125</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>1.330078</td>\n",
       "      <td>94.7500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>4.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21422</th>\n",
       "      <td>mia_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>mia_2022_9</td>\n",
       "      <td>chivsmia_2022_9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>97.1875</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>94.7500</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>98.3750</td>\n",
       "      <td>3.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23170</th>\n",
       "      <td>gb_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>gb_2022_9</td>\n",
       "      <td>detvsgb_2022_9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.5000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>98.8125</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24110</th>\n",
       "      <td>phi_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>no cover</td>\n",
       "      <td>over</td>\n",
       "      <td>phi_2022_9</td>\n",
       "      <td>houvsphi_2022_9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>77.6875</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>88.8750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.6875</td>\n",
       "      <td>3.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25058</th>\n",
       "      <td>lv_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>lv_2022_9</td>\n",
       "      <td>jaxvslv_2022_9</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>94.3125</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>94.7500</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>98.3750</td>\n",
       "      <td>2.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26428</th>\n",
       "      <td>bal_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>cover</td>\n",
       "      <td>under</td>\n",
       "      <td>bal_2022_9</td>\n",
       "      <td>novsbal_2022_9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>80.5000</td>\n",
       "      <td>2.660156</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>83.2500</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>98.3750</td>\n",
       "      <td>5.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27560</th>\n",
       "      <td>buf_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>no cover</td>\n",
       "      <td>under</td>\n",
       "      <td>buf_2022_9</td>\n",
       "      <td>nyjvsbuf_2022_9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>97.1875</td>\n",
       "      <td>2.660156</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.2500</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>99.2500</td>\n",
       "      <td>4.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29376</th>\n",
       "      <td>min_2022_9</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>push</td>\n",
       "      <td>under</td>\n",
       "      <td>min_2022_9</td>\n",
       "      <td>wasvsmin_2022_9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>0.669922</td>\n",
       "      <td>97.1875</td>\n",
       "      <td>2.660156</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.5625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 3860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          team_id schedule_week schedule_season spread_favorite  \\\n",
       "14714   no_2021_9             9            2021            -6.5   \n",
       "16878  pit_2021_9             9            2021            -7.0   \n",
       "17638   sf_2021_9             9            2021            -5.5   \n",
       "20466   ne_2021_9             9            2021            -3.5   \n",
       "24722  buf_2021_9             9            2021           -14.5   \n",
       "26564   lv_2021_9             9            2021            -3.0   \n",
       "28022  lac_2021_9             9            2021            -1.0   \n",
       "536    ari_2022_9             9            2022            -2.0   \n",
       "3940   cin_2022_9             9            2022            -7.0   \n",
       "10330   kc_2022_9             9            2022           -14.0   \n",
       "14522   ne_2022_9             9            2022            -5.0   \n",
       "18624   tb_2022_9             9            2022            -3.0   \n",
       "19862  lac_2022_9             9            2022            -2.5   \n",
       "21422  mia_2022_9             9            2022            -4.0   \n",
       "23170   gb_2022_9             9            2022            -4.0   \n",
       "24110  phi_2022_9             9            2022           -14.0   \n",
       "25058   lv_2022_9             9            2022            -2.5   \n",
       "26428  bal_2022_9             9            2022            -1.5   \n",
       "27560  buf_2022_9             9            2022           -10.5   \n",
       "29376  min_2022_9             9            2022            -3.0   \n",
       "\n",
       "      over_under_line fav_cover over_under_result unique_team_id  \\\n",
       "14714            43.0  no cover              over      no_2021_9   \n",
       "16878            40.0  no cover              over     pit_2021_9   \n",
       "17638            44.5  no cover              over      sf_2021_9   \n",
       "20466            41.5     cover             under      ne_2021_9   \n",
       "24722            48.5  no cover             under     buf_2021_9   \n",
       "26564            47.0  no cover             under      lv_2021_9   \n",
       "28022            49.5     cover              over     lac_2021_9   \n",
       "536              49.0  no cover              over     ari_2022_9   \n",
       "3940             42.5     cover              over     cin_2022_9   \n",
       "10330            45.0  no cover             under      kc_2022_9   \n",
       "14522            40.0     cover             under      ne_2022_9   \n",
       "18624            42.5      push             under      tb_2022_9   \n",
       "19862            49.5     cover             under     lac_2022_9   \n",
       "21422            46.0  no cover              over     mia_2022_9   \n",
       "23170            49.5  no cover             under      gb_2022_9   \n",
       "24110            45.5  no cover              over     phi_2022_9   \n",
       "25058            48.0  no cover             under      lv_2022_9   \n",
       "26428            46.0     cover             under     bal_2022_9   \n",
       "27560            46.0  no cover             under     buf_2022_9   \n",
       "29376            43.5      push             under     min_2022_9   \n",
       "\n",
       "       home_matchup_id score_home_fav  ... kicking_thirty_attempts_dog  \\\n",
       "14714   novsatl_2021_9           25.0  ...                    1.330078   \n",
       "16878  pitvschi_2021_9           29.0  ...                    0.330078   \n",
       "17638   sfvsari_2021_9           17.0  ...                    1.000000   \n",
       "20466   carvsne_2021_9            6.0  ...                    0.000000   \n",
       "24722  jaxvsbuf_2021_9            9.0  ...                    0.000000   \n",
       "26564   nygvslv_2021_9           23.0  ...                    0.000000   \n",
       "28022  phivslac_2021_9           24.0  ...                    0.000000   \n",
       "536    arivssea_2022_9           21.0  ...                    1.669922   \n",
       "3940   cinvscar_2022_9           42.0  ...                    0.669922   \n",
       "10330   kcvsten_2022_9           20.0  ...                    0.330078   \n",
       "14522   nevsind_2022_9           26.0  ...                    0.330078   \n",
       "18624   tbvslar_2022_9           16.0  ...                    0.000000   \n",
       "19862  atlvslac_2022_9           17.0  ...                    0.669922   \n",
       "21422  chivsmia_2022_9           32.0  ...                    0.669922   \n",
       "23170   detvsgb_2022_9           15.0  ...                    0.000000   \n",
       "24110  houvsphi_2022_9           17.0  ...                    0.669922   \n",
       "25058   jaxvslv_2022_9           27.0  ...                    0.330078   \n",
       "26428   novsbal_2022_9           13.0  ...                    2.000000   \n",
       "27560  nyjvsbuf_2022_9           20.0  ...                    0.669922   \n",
       "29376  wasvsmin_2022_9           17.0  ...                    0.669922   \n",
       "\n",
       "       kicking_thirty_made_dog kicking_thirty_percent_dog  \\\n",
       "14714                 1.330078                    97.1875   \n",
       "16878                 0.330078                    94.3125   \n",
       "17638                 1.000000                    97.1875   \n",
       "20466                 0.000000                    91.5000   \n",
       "24722                 0.000000                    91.5000   \n",
       "26564                 0.000000                    91.5000   \n",
       "28022                 0.000000                    91.5000   \n",
       "536                   1.669922                   100.0000   \n",
       "3940                  0.330078                    77.6875   \n",
       "10330                 0.330078                    94.3125   \n",
       "14522                 0.330078                    94.3125   \n",
       "18624                 0.000000                    91.5000   \n",
       "19862                 0.669922                    94.3125   \n",
       "21422                 0.669922                    97.1875   \n",
       "23170                 0.000000                    91.5000   \n",
       "24110                 0.330078                    77.6875   \n",
       "25058                 0.330078                    94.3125   \n",
       "26428                 1.669922                    80.5000   \n",
       "27560                 0.669922                    97.1875   \n",
       "29376                 0.669922                    97.1875   \n",
       "\n",
       "      kicking_total_attempts_dog kicking_total_made_dog  \\\n",
       "14714                   2.660156               2.330078   \n",
       "16878                   1.330078               1.330078   \n",
       "17638                   1.330078               1.330078   \n",
       "20466                   2.330078               2.330078   \n",
       "24722                   1.330078               1.000000   \n",
       "26564                   1.669922               1.669922   \n",
       "28022                   1.330078               1.000000   \n",
       "536                     3.000000               3.000000   \n",
       "3940                    1.330078               1.000000   \n",
       "10330                   2.000000               1.669922   \n",
       "14522                   2.000000               2.000000   \n",
       "18624                   1.000000               0.669922   \n",
       "19862                   1.330078               1.330078   \n",
       "21422                   1.669922               1.669922   \n",
       "23170                   2.000000               2.000000   \n",
       "24110                   2.000000               1.669922   \n",
       "25058                   0.669922               0.669922   \n",
       "26428                   2.660156               2.330078   \n",
       "27560                   2.660156               2.000000   \n",
       "29376                   2.660156               2.000000   \n",
       "\n",
       "      kicking_total_percent_dog kicking_twenty_attempts_dog  \\\n",
       "14714                   88.8750                    0.000000   \n",
       "16878                   94.7500                    0.669922   \n",
       "17638                   94.7500                    0.000000   \n",
       "20466                  100.0000                    1.000000   \n",
       "24722                   61.3750                    0.000000   \n",
       "26564                  100.0000                    0.669922   \n",
       "28022                   61.3750                    0.330078   \n",
       "536                    100.0000                    0.330078   \n",
       "3940                    83.6250                    0.000000   \n",
       "10330                   78.0000                    1.000000   \n",
       "14522                  100.0000                    0.669922   \n",
       "18624                   78.0000                    0.669922   \n",
       "19862                   94.7500                    0.000000   \n",
       "21422                   94.7500                    0.330078   \n",
       "23170                  100.0000                    0.500000   \n",
       "24110                   88.8750                    0.000000   \n",
       "25058                   94.7500                    0.330078   \n",
       "26428                   83.2500                    0.330078   \n",
       "27560                   72.2500                    0.669922   \n",
       "29376                   80.5625                    1.000000   \n",
       "\n",
       "       kicking_twenty_made_dog  kicking_twenty_percent_dog  kicks_dog  \n",
       "14714                 0.000000                     97.6875   5.000000  \n",
       "16878                 0.669922                     99.2500   2.660156  \n",
       "17638                 0.000000                     97.6875   5.000000  \n",
       "20466                 1.000000                     99.2500   3.339844  \n",
       "24722                 0.000000                     97.6875   3.000000  \n",
       "26564                 0.669922                     99.2500   3.000000  \n",
       "28022                 0.330078                     98.3750   4.328125  \n",
       "536                   0.330078                     98.3750   5.671875  \n",
       "3940                  0.000000                     97.6875   3.660156  \n",
       "10330                 1.000000                     99.2500   4.000000  \n",
       "14522                 0.669922                     99.2500   3.339844  \n",
       "18624                 0.669922                     99.2500   3.000000  \n",
       "19862                 0.000000                     97.6875   4.671875  \n",
       "21422                 0.330078                     98.3750   3.660156  \n",
       "23170                 0.500000                     98.8125   3.500000  \n",
       "24110                 0.000000                     97.6875   3.339844  \n",
       "25058                 0.330078                     98.3750   2.660156  \n",
       "26428                 0.330078                     98.3750   5.671875  \n",
       "27560                 0.669922                     99.2500   4.671875  \n",
       "29376                 1.000000                    100.0000   4.000000  \n",
       "\n",
       "[20 rows x 3860 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df[\"days_last_played_fav\"] = fin_df[\"days_last_played_fav\"].astype(float)\n",
    "fin_df[\"days_last_played_dog\"] = fin_df[\"days_last_played_dog\"].astype(float)\n",
    "\n",
    "fin_df[\"days_last_played_fav\"].fillna((fin_df[\"days_last_played_fav\"].mean()), inplace=True)\n",
    "fin_df[\"days_last_played_dog\"].fillna((fin_df[\"days_last_played_dog\"].mean()), inplace=True)\n",
    "\n",
    "fin_df = fin_df.sort_values(by=[\"schedule_week\",\"schedule_season\"], ascending=[True, True])\n",
    "fin_df.tail(n=20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df[\"overall_performance_tgs_fav_vs_overall_performance_tgs_dog\"] = fin_df[\"overall_performance_tgs_fav\"]/fin_df[\"overall_performance_tgs_dog\"]\n",
    "fin_df[\"offense_tgs_fav_vs_offense_tgs_dog\"] = fin_df[\"offense_tgs_fav\"]/fin_df[\"offense_tgs_dog\"]\n",
    "fin_df[\"pass_tgs_fav_vs_pass_tgs_dog\"] = fin_df[\"pass_tgs_fav\"]/fin_df[\"pass_tgs_dog\"]\n",
    "fin_df[\"pass_blocking_tgs_fav_vs_pass_blocking_tgs_dog\"] = fin_df[\"pass_blocking_tgs_fav\"]/fin_df[\"pass_blocking_tgs_dog\"]\n",
    "fin_df[\"receiving_tgs_fav_vs_receiving_tgs_dog\"] = fin_df[\"receiving_tgs_fav\"]/fin_df[\"receiving_tgs_dog\"]\n",
    "fin_df[\"rushing_tgs_fav_vs_rushing_tgs_dog\"] = fin_df[\"rushing_tgs_fav\"]/fin_df[\"rushing_tgs_dog\"]\n",
    "fin_df[\"run_blocking_tgs_fav_vs_run_blocking_tgs_dog\"] = fin_df[\"run_blocking_tgs_fav\"]/fin_df[\"run_blocking_tgs_dog\"]\n",
    "fin_df[\"defense_tgs_fav_vs_defense_tgs_dog\"] = fin_df[\"defense_tgs_fav\"]/fin_df[\"defense_tgs_dog\"]\n",
    "fin_df[\"rush_defense_tgs_fav_vs_rush_defense_tgs_dog\"] = fin_df[\"rush_defense_tgs_fav\"]/fin_df[\"rush_defense_tgs_dog\"]\n",
    "fin_df[\"tackling_tgs_fav_vs_tackling_tgs_dog\"] = fin_df[\"tackling_tgs_fav\"]/fin_df[\"tackling_tgs_dog\"]\n",
    "fin_df[\"pass_rush_tgs_fav_vs_pass_rush_tgs_dog\"] = fin_df[\"pass_rush_tgs_fav\"]/fin_df[\"pass_rush_tgs_dog\"]\n",
    "fin_df[\"coverage_tgs_fav_vs_coverage_tgs_dog\"] = fin_df[\"coverage_tgs_fav\"]/fin_df[\"coverage_tgs_dog\"]\n",
    "fin_df[\"special_teams_tgs_fav_vs_special_teams_tgs_dog\"] = fin_df[\"special_teams_tgs_fav\"]/fin_df[\"special_teams_tgs_dog\"]\n",
    "fin_df[\"total_dvoa_fav_vs_total_dvoa_dog\"] = fin_df[\"total_dvoa_fav\"]/fin_df[\"total_dvoa_dog\"]\n",
    "fin_df[\"off_dvoa_fav_vs_off_dvoa_dog\"] = fin_df[\"off_dvoa_fav\"]/fin_df[\"off_dvoa_dog\"]\n",
    "fin_df[\"off_pass_dvoa_fav_vs_off_pass_dvoa_dog\"] = fin_df[\"off_pass_dvoa_fav\"]/fin_df[\"off_pass_dvoa_dog\"]\n",
    "fin_df[\"off_rush_dvoa_fav_vs_off_rush_dvoa_dog\"] = fin_df[\"off_rush_dvoa_fav\"]/fin_df[\"off_rush_dvoa_dog\"]\n",
    "fin_df[\"def_dvoa_fav_vs_def_dvoa_dog\"] = fin_df[\"def_dvoa_fav\"]/fin_df[\"def_dvoa_dog\"]\n",
    "fin_df[\"def_pass_dvoa_fav_vs_def_pass_dvoa_dog\"] = fin_df[\"def_pass_dvoa_fav\"]/fin_df[\"def_pass_dvoa_dog\"]\n",
    "fin_df[\"def_rush_dvoa_fav_vs_def_rush_dvoa_dog\"] = fin_df[\"def_rush_dvoa_fav\"]/fin_df[\"def_rush_dvoa_dog\"]\n",
    "fin_df[\"special_teams_dvoa_fav_vs_special_teams_dvoa_dog\"] = fin_df[\"special_teams_dvoa_fav\"]/fin_df[\"special_teams_dvoa_dog\"]\n",
    "\t\t\n",
    "fin_df[\"offense_tgs_fav_vs_defense_tgs_dog\"] = fin_df[\"offense_tgs_fav\"]/fin_df[\"defense_tgs_dog\"]\n",
    "fin_df[\"pass_tgs_fav_vs_coverage_tgs_dog\"] = fin_df[\"pass_tgs_fav\"]/fin_df[\"coverage_tgs_dog\"]\n",
    "fin_df[\"pass_tgs_fav_vs_pass_rush_tgs_dog\"] = fin_df[\"pass_tgs_fav\"]/fin_df[\"pass_rush_tgs_dog\"]\n",
    "fin_df[\"pass_blocking_tgs_fav_vs_pass_rush_tgs_dog\"] = fin_df[\"pass_blocking_tgs_fav\"]/fin_df[\"pass_rush_tgs_dog\"]\n",
    "fin_df[\"receiving_tgs_fav_vs_coverage_tgs_dog\"] = fin_df[\"receiving_tgs_fav\"]/fin_df[\"coverage_tgs_dog\"]\n",
    "fin_df[\"rushing_tgs_fav_vs_rush_defense_tgs_dog\"] = fin_df[\"rushing_tgs_fav\"]/fin_df[\"rush_defense_tgs_dog\"]\n",
    "fin_df[\"rushing_tgs_fav_vs_tackling_tgs_dog\"] = fin_df[\"rushing_tgs_fav\"]/fin_df[\"tackling_tgs_dog\"]\n",
    "fin_df[\"run_blocking_tgs_fav_vs_rush_defense_tgs_dog\"] = fin_df[\"run_blocking_tgs_fav\"]/fin_df[\"rush_defense_tgs_dog\"]\n",
    "\t\t\n",
    "fin_df[\"defense_tgs_fav_vs_offense_tgs_dog\"] = fin_df[\"defense_tgs_fav\"]/fin_df[\"offense_tgs_dog\"]\n",
    "fin_df[\"rush_defense_tgs_fav_vs_rushing_tgs_dog\"] = fin_df[\"rush_defense_tgs_fav\"]/fin_df[\"rushing_tgs_dog\"]\n",
    "fin_df[\"tackling_tgs_fav_vs_offense_tgs_dog\"] = fin_df[\"tackling_tgs_fav\"]/fin_df[\"offense_tgs_dog\"]\n",
    "fin_df[\"pass_rush_tgs_fav_vs_pass_blocking_tgs_dog\"] = fin_df[\"pass_rush_tgs_fav\"]/fin_df[\"pass_blocking_tgs_dog\"]\n",
    "fin_df[\"coverage_tgs_fav_vs_receiving_tgs_dog\"] = fin_df[\"coverage_tgs_fav\"]/fin_df[\"receiving_tgs_dog\"]\n",
    "\t\t\n",
    "fin_df[\"off_dvoa_fav_vs_def_dvoa_dog\"] = fin_df[\"off_dvoa_fav\"]/fin_df[\"def_dvoa_dog\"]\n",
    "fin_df[\"off_pass_dvoa_fav_vs_def_pass_dvoa_dog\"] = fin_df[\"off_pass_dvoa_fav\"]/fin_df[\"def_pass_dvoa_dog\"]\n",
    "fin_df[\"off_rush_dvoa_fav_vs_def_rush_dvoa_dog\"] = fin_df[\"off_rush_dvoa_fav\"]/fin_df[\"def_rush_dvoa_dog\"]\n",
    "\t\t\n",
    "fin_df[\"def_dvoa_fav_vs_off_dvoa_dog\"] = fin_df[\"def_dvoa_fav\"]/fin_df[\"off_dvoa_dog\"]\n",
    "fin_df[\"def_pass_dvoa_fav_vs_off_pass_dvoa_dog\"] = fin_df[\"def_pass_dvoa_fav\"]/fin_df[\"off_pass_dvoa_dog\"]\n",
    "fin_df[\"def_rush_dvoa_fav_vs_off_rush_dvoa_dog\"] = fin_df[\"def_rush_dvoa_fav\"]/fin_df[\"off_rush_dvoa_dog\"]\n",
    "\t\t\n",
    "\t\t\n",
    "fin_df[\"offense_tgs_dog_vs_defense_tgs_fav\"] = fin_df[\"offense_tgs_dog\"]/fin_df[\"defense_tgs_fav\"]\n",
    "fin_df[\"pass_tgs_dog_vs_coverage_tgs_fav\"] = fin_df[\"pass_tgs_dog\"]/fin_df[\"coverage_tgs_fav\"]\n",
    "fin_df[\"pass_tgs_dog_vs_pass_rush_tgs_fav\"] = fin_df[\"pass_tgs_dog\"]/fin_df[\"pass_rush_tgs_fav\"]\n",
    "fin_df[\"pass_blocking_tgs_dog_vs_pass_rush_tgs_fav\"] = fin_df[\"pass_blocking_tgs_dog\"]/fin_df[\"pass_rush_tgs_fav\"]\n",
    "fin_df[\"receiving_tgs_dog_vs_coverage_tgs_fav\"] = fin_df[\"receiving_tgs_dog\"]/fin_df[\"coverage_tgs_fav\"]\n",
    "fin_df[\"rushing_tgs_dog_vs_rush_defense_tgs_fav\"] = fin_df[\"rushing_tgs_dog\"]/fin_df[\"rush_defense_tgs_fav\"]\n",
    "fin_df[\"rushing_tgs_dog_vs_tackling_tgs_fav\"] = fin_df[\"rushing_tgs_dog\"]/fin_df[\"tackling_tgs_fav\"]\n",
    "fin_df[\"run_blocking_tgs_dog_vs_rush_defense_tgs_fav\"] = fin_df[\"run_blocking_tgs_dog\"]/fin_df[\"rush_defense_tgs_fav\"]\n",
    "\t\t\n",
    "fin_df[\"defense_tgs_dog_vs_offense_tgs_fav\"] = fin_df[\"defense_tgs_dog\"]/fin_df[\"offense_tgs_fav\"]\n",
    "fin_df[\"rush_defense_tgs_dog_vs_rushing_tgs_fav\"] = fin_df[\"rush_defense_tgs_dog\"]/fin_df[\"rushing_tgs_fav\"]\n",
    "fin_df[\"tackling_tgs_dog_vs_offense_tgs_fav\"] = fin_df[\"tackling_tgs_dog\"]/fin_df[\"offense_tgs_fav\"]\n",
    "fin_df[\"pass_rush_tgs_dog_vs_pass_blocking_tgs_fav\"] = fin_df[\"pass_rush_tgs_dog\"]/fin_df[\"pass_blocking_tgs_fav\"]\n",
    "fin_df[\"coverage_tgs_dog_vs_receiving_tgs_fav\"] = fin_df[\"coverage_tgs_dog\"]/fin_df[\"receiving_tgs_fav\"]\n",
    "\t\t\n",
    "fin_df[\"off_dvoa_dog_vs_def_dvoa_fav\"] = fin_df[\"off_dvoa_dog\"]/fin_df[\"def_dvoa_fav\"]\n",
    "fin_df[\"off_pass_dvoa_dog_vs_def_pass_dvoa_fav\"] = fin_df[\"off_pass_dvoa_dog\"]/fin_df[\"def_pass_dvoa_fav\"]\n",
    "fin_df[\"off_rush_dvoa_dog_vs_def_rush_dvoa_fav\"] = fin_df[\"off_rush_dvoa_dog\"]/fin_df[\"def_rush_dvoa_fav\"]\n",
    "\t\t\n",
    "fin_df[\"def_dvoa_dog_vs_off_dvoa_fav\"] = fin_df[\"def_dvoa_dog\"]/fin_df[\"off_dvoa_fav\"]\n",
    "fin_df[\"def_pass_dvoa_dog_vs_off_pass_dvoa_fav\"] = fin_df[\"def_pass_dvoa_dog\"]/fin_df[\"off_pass_dvoa_fav\"]\n",
    "fin_df[\"def_rush_dvoa_dog_vs_off_rush_dvoa_fav\"] = fin_df[\"def_rush_dvoa_dog\"]/fin_df[\"off_rush_dvoa_fav\"]\n",
    "\t\t\n",
    "\t\t\n",
    "fin_df[\"off_tgs_vs_def_tgs_matchup\"] = fin_df[\"offense_tgs_fav_vs_defense_tgs_dog\"]/fin_df[\"offense_tgs_dog_vs_defense_tgs_fav\"]\n",
    "fin_df[\"pass_tgs_vs_def_cov_tgs_matchup\"] = fin_df[\"pass_tgs_fav_vs_coverage_tgs_dog\"]/fin_df[\"pass_tgs_dog_vs_coverage_tgs_fav\"]\n",
    "fin_df[\"pass_tgs_vs_def_passrush_tgs_matchup\"] = fin_df[\"pass_tgs_fav_vs_pass_rush_tgs_dog\"]/fin_df[\"pass_tgs_dog_vs_pass_rush_tgs_fav\"]\n",
    "fin_df[\"passblock_tgs_vs_def_passrush_tgs_matchup\"] = fin_df[\"pass_blocking_tgs_fav_vs_pass_rush_tgs_dog\"]/fin_df[\"pass_blocking_tgs_dog_vs_pass_rush_tgs_fav\"]\n",
    "fin_df[\"rec_tgs_vs_def_cov_tgs_matchup\"] = fin_df[\"receiving_tgs_fav_vs_coverage_tgs_dog\"]/fin_df[\"receiving_tgs_dog_vs_coverage_tgs_fav\"]\n",
    "fin_df[\"rush_tgs_vs_def_rundef_tgs_matchup\"] = fin_df[\"rushing_tgs_fav_vs_rush_defense_tgs_dog\"]/fin_df[\"rushing_tgs_dog_vs_rush_defense_tgs_fav\"]\n",
    "fin_df[\"rush_tgs_vs_def_tackle_tgs_matchup\"] = fin_df[\"rushing_tgs_fav_vs_tackling_tgs_dog\"]/fin_df[\"rushing_tgs_dog_vs_tackling_tgs_fav\"]\n",
    "fin_df[\"runblock_tgs_vs_def_rundef_tgs_matchup\"] = fin_df[\"run_blocking_tgs_fav_vs_rush_defense_tgs_dog\"]/fin_df[\"run_blocking_tgs_dog_vs_rush_defense_tgs_fav\"]\n",
    "fin_df[\"defense_tgs_vs_offense_tgs_matchup\"] = fin_df[\"defense_tgs_fav_vs_offense_tgs_dog\"]/fin_df[\"defense_tgs_dog_vs_offense_tgs_fav\"]\n",
    "fin_df[\"rush_defense_tgs_vs_rushing_tgs_matchup\"] = fin_df[\"rush_defense_tgs_fav_vs_rushing_tgs_dog\"]/fin_df[\"rush_defense_tgs_dog_vs_rushing_tgs_fav\"]\n",
    "fin_df[\"tackling_tgs_vs_offense_tgs_matchup\"] = fin_df[\"tackling_tgs_fav_vs_offense_tgs_dog\"]/fin_df[\"tackling_tgs_dog_vs_offense_tgs_fav\"]\n",
    "fin_df[\"pass_rush_tgs_vs_pass_blocking_tgs_matchup\"] = fin_df[\"pass_rush_tgs_fav_vs_pass_blocking_tgs_dog\"]/fin_df[\"pass_rush_tgs_dog_vs_pass_blocking_tgs_fav\"]\n",
    "fin_df[\"coverage_tgs_vs_receiving_tgs_matchup\"] = fin_df[\"coverage_tgs_fav_vs_receiving_tgs_dog\"]/fin_df[\"coverage_tgs_dog_vs_receiving_tgs_fav\"]\n",
    "\n",
    "fin_df[\"off_dvoa_vs_def_dvoa_matchup\"] = fin_df[\"off_dvoa_fav_vs_def_dvoa_dog\"]/fin_df[\"off_dvoa_dog_vs_def_dvoa_fav\"]\n",
    "fin_df[\"off_pass_dvoa_vs_def_pass_dvoa_matchup\"] = fin_df[\"off_pass_dvoa_fav_vs_def_pass_dvoa_dog\"]/fin_df[\"off_pass_dvoa_dog_vs_def_pass_dvoa_fav\"]\n",
    "fin_df[\"off_rush_dvoa_vs_def_rush_dvoa_matchup\"] = fin_df[\"off_rush_dvoa_fav_vs_def_rush_dvoa_dog\"]/fin_df[\"off_rush_dvoa_dog_vs_def_rush_dvoa_fav\"]\n",
    "\n",
    "fin_df[\"def_dvoa_vs_off_dvoa_matchup\"] = fin_df[\"def_dvoa_fav_vs_off_dvoa_dog\"]/fin_df[\"def_dvoa_dog_vs_off_dvoa_fav\"]\n",
    "fin_df[\"def_pass_dvoa_vs_off_pass_dvoa_matchup\"] = fin_df[\"def_pass_dvoa_fav_vs_off_pass_dvoa_dog\"]/fin_df[\"def_pass_dvoa_dog_vs_off_pass_dvoa_fav\"]\n",
    "fin_df[\"def_rush_dvoa_vs_off_rush_dvoa_matchup\"] = fin_df[\"def_rush_dvoa_fav_vs_off_rush_dvoa_dog\"]/fin_df[\"def_rush_dvoa_dog_vs_off_rush_dvoa_fav\"]\n",
    "\n",
    "fin_df[\"pf_x_vs_pa_y\"] = fin_df[\"pf_x\"]/fin_df[\"pa_y\"]\n",
    "fin_df[\"pa_x_vs_pf_y\"] = fin_df[\"pa_x\"]/fin_df[\"pf_y\"]\n",
    "fin_df[\"pf_y_vs_pa_x\"] = fin_df[\"pf_y\"]/fin_df[\"pa_x\"]\n",
    "fin_df[\"pa_y_vs_pf_x\"] = fin_df[\"pa_y\"]/fin_df[\"pf_x\"]\n",
    "fin_df[\"pf_x_minus_pa_x\"] = fin_df[\"pf_x\"]-fin_df[\"pa_x\"]\n",
    "fin_df[\"pf_y_minus_pa_y\"] = fin_df[\"pf_y\"]-fin_df[\"pa_y\"]\n",
    "fin_df[\"pf_x_vs_pa_y_v2\"] = (fin_df[\"pf_x\"]-fin_df[\"pa_y\"])*fin_df['pf_x']\n",
    "fin_df[\"pf_y_vs_pa_x_v2\"] = (fin_df[\"pf_y\"]-fin_df[\"pa_x\"])*fin_df['pf_y']\n",
    "\n",
    "\n",
    "fin_df[\"days_matchup\"] = fin_df[\"days_last_played_fav\"]/fin_df[\"days_last_played_dog\"]\n",
    "\n",
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDER CONSTRUCTION: Creating function to create modeling file by user selected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
